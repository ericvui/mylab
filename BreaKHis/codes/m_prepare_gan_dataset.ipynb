{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "dirs =\"/tf/dataset/classes\" \n",
    "sizes = ['40','100','200','400']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create B/M csv file to stores a images list for BreaKhis\n",
    "for size in sizes:\n",
    "    B_arr = []\n",
    "    M_arr = []\n",
    "    dir_size = os.path.join(dirs,size)\n",
    "    for dirpath, dirnames, filenames in os.walk(dir_size,topdown=False):\n",
    "        for fn in filenames:\n",
    "            parts = fn.split(\"_\")\n",
    "            if parts[1] == \"B\":\n",
    "                B_arr.append(os.path.join(dirpath,fn))\n",
    "            else:\n",
    "                M_arr.append(os.path.join(dirpath,fn))\n",
    "    B_file = os.path.join(dirs , \"B_{}_files.csv\" . format(size))\n",
    "    M_file = os.path.join(dirs , \"M_{}_files.csv\" . format(size))\n",
    "    with open(B_file, 'w') as writer:\n",
    "        for line in B_arr:\n",
    "            writer.write(line + \"\\n\")\n",
    "    with open(M_file, 'w') as writer:\n",
    "        for line in M_arr:\n",
    "            writer.write(line + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create training data file for BreaKhis\n",
    "import random \n",
    "\n",
    "epoches = 5\n",
    "cancer_type = \"B\"\n",
    "generated_size = \"40\"\n",
    "sizes = ['40','100','200','400']\n",
    "dirs = \"/tf/dataset/classes\"\n",
    "for epoch in range(epoches):\n",
    "    cond_images = []\n",
    "    orgi_images = []\n",
    "    for size in sizes:\n",
    "        data_file = \"{}_{}_files.csv\" . format(cancer_type,size)\n",
    "        if size != generated_size:\n",
    "            with open(os.path.join(dirs,data_file), \"r\") as f:\n",
    "                lines = f.readlines()\n",
    "            for ln in lines:\n",
    "                cond_images.append(ln)\n",
    "        else:\n",
    "            with open(os.path.join(dirs,data_file), \"r\") as f:\n",
    "                lines = f.readlines()\n",
    "            for ln in lines:\n",
    "                orgi_images.append(ln)\n",
    "    result_images = []\n",
    "    random.shuffle(cond_images)\n",
    "    for fn_org in orgi_images:\n",
    "        idx = random.randint(1,len(cond_images)-1)\n",
    "        gen_line =  cond_images[idx] +\",\" + fn_org\n",
    "        \n",
    "        result_images.append(gen_line)\n",
    "    \n",
    "    output_file = os.path.join(dirs,\"gan_epoch_{}.csv\".format(epoch))\n",
    "    with open(output_file, 'w') as writer:\n",
    "        for line in result_images:\n",
    "            writer.write(line + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is091.tif\n",
      "is075.tif\n",
      "is050.tif\n",
      "is096.tif\n",
      "is084.tif\n",
      "is017.tif\n",
      "is059.tif\n",
      "is058.tif\n",
      "is056.tif\n",
      "is049.tif\n",
      "is099.tif\n",
      "is074.tif\n",
      "is090.tif\n",
      "is007.tif\n",
      "is071.tif\n",
      "is036.tif\n",
      "is029.tif\n",
      "is031.tif\n",
      "is033.tif\n",
      "is098.tif\n",
      "is089.tif\n",
      "is022.tif\n",
      "is009.tif\n",
      "is046.tif\n",
      "is076.tif\n",
      "is053.tif\n",
      "is025.tif\n",
      "is042.tif\n",
      "is052.tif\n",
      "is079.tif\n",
      "is014.tif\n",
      "is087.tif\n",
      "is043.tif\n",
      "is062.tif\n",
      "is092.tif\n",
      "is012.tif\n",
      "is094.tif\n",
      "is008.tif\n",
      "is038.tif\n",
      "is083.tif\n",
      "is067.tif\n",
      "is080.tif\n",
      "is020.tif\n",
      "is093.tif\n",
      "is051.tif\n",
      "is021.tif\n",
      "is032.tif\n",
      "is065.tif\n",
      "is085.tif\n",
      "is060.tif\n",
      "is069.tif\n",
      "is030.tif\n",
      "is061.tif\n",
      "is028.tif\n",
      "is097.tif\n",
      "is072.tif\n",
      "is006.tif\n",
      "is026.tif\n",
      "is015.tif\n",
      "is013.tif\n",
      "is010.tif\n",
      "is035.tif\n",
      "is077.tif\n",
      "is023.tif\n",
      "is044.tif\n",
      "is039.tif\n",
      "is086.tif\n",
      "is088.tif\n",
      "is018.tif\n",
      "is005.tif\n",
      "is024.tif\n",
      "is037.tif\n",
      "is041.tif\n",
      "is002.tif\n",
      "is078.tif\n",
      "is055.tif\n",
      "is001.tif\n",
      "is100.tif\n",
      "is070.tif\n",
      "is027.tif\n",
      "is048.tif\n",
      "is011.tif\n",
      "is034.tif\n",
      "is082.tif\n",
      "is057.tif\n",
      "is003.tif\n",
      "is073.tif\n",
      "is068.tif\n",
      "is066.tif\n",
      "is040.tif\n",
      "is054.tif\n",
      "is016.tif\n",
      "is019.tif\n",
      "is095.tif\n",
      "is081.tif\n",
      "is004.tif\n",
      "is063.tif\n",
      "is045.tif\n",
      "is064.tif\n",
      "is047.tif\n",
      "iv085.tif\n",
      "iv037.tif\n",
      "iv046.tif\n",
      "iv011.tif\n",
      "iv095.tif\n",
      "iv090.tif\n",
      "iv039.tif\n",
      "iv096.tif\n",
      "iv007.tif\n",
      "iv020.tif\n",
      "iv049.tif\n",
      "iv033.tif\n",
      "iv006.tif\n",
      "iv073.tif\n",
      "iv019.tif\n",
      "iv087.tif\n",
      "iv018.tif\n",
      "iv045.tif\n",
      "iv009.tif\n",
      "iv040.tif\n",
      "iv038.tif\n",
      "iv003.tif\n",
      "iv080.tif\n",
      "iv002.tif\n",
      "iv076.tif\n",
      "iv088.tif\n",
      "iv028.tif\n",
      "iv058.tif\n",
      "iv048.tif\n",
      "iv025.tif\n",
      "iv056.tif\n",
      "iv029.tif\n",
      "iv043.tif\n",
      "iv059.tif\n",
      "iv026.tif\n",
      "iv042.tif\n",
      "iv016.tif\n",
      "iv072.tif\n",
      "iv081.tif\n",
      "iv050.tif\n",
      "iv035.tif\n",
      "iv061.tif\n",
      "iv024.tif\n",
      "iv052.tif\n",
      "iv070.tif\n",
      "iv060.tif\n",
      "iv044.tif\n",
      "iv065.tif\n",
      "iv034.tif\n",
      "iv014.tif\n",
      "iv093.tif\n",
      "iv004.tif\n",
      "iv098.tif\n",
      "iv068.tif\n",
      "iv036.tif\n",
      "iv017.tif\n",
      "iv057.tif\n",
      "iv066.tif\n",
      "iv005.tif\n",
      "iv084.tif\n",
      "iv099.tif\n",
      "iv064.tif\n",
      "iv055.tif\n",
      "iv082.tif\n",
      "iv094.tif\n",
      "iv078.tif\n",
      "iv022.tif\n",
      "iv075.tif\n",
      "iv031.tif\n",
      "iv069.tif\n",
      "iv013.tif\n",
      "iv097.tif\n",
      "iv086.tif\n",
      "iv008.tif\n",
      "iv021.tif\n",
      "iv023.tif\n",
      "iv032.tif\n",
      "iv012.tif\n",
      "iv063.tif\n",
      "iv089.tif\n",
      "iv074.tif\n",
      "iv100.tif\n",
      "iv001.tif\n",
      "iv030.tif\n",
      "iv054.tif\n",
      "iv062.tif\n",
      "iv083.tif\n",
      "iv010.tif\n",
      "iv053.tif\n",
      "iv091.tif\n",
      "iv071.tif\n",
      "iv051.tif\n",
      "iv092.tif\n",
      "iv047.tif\n",
      "iv027.tif\n",
      "iv015.tif\n",
      "iv067.tif\n",
      "iv077.tif\n",
      "iv041.tif\n",
      "iv079.tif\n",
      "n078.tif\n",
      "n002.tif\n",
      "n084.tif\n",
      "n021.tif\n",
      "n059.tif\n",
      "n006.tif\n",
      "n083.tif\n",
      "n045.tif\n",
      "n093.tif\n",
      "n020.tif\n",
      "n058.tif\n",
      "n080.tif\n",
      "n072.tif\n",
      "n044.tif\n",
      "n062.tif\n",
      "n082.tif\n",
      "n007.tif\n",
      "n051.tif\n",
      "n013.tif\n",
      "n028.tif\n",
      "n036.tif\n",
      "n047.tif\n",
      "n019.tif\n",
      "n035.tif\n",
      "n068.tif\n",
      "n091.tif\n",
      "n050.tif\n",
      "n018.tif\n",
      "n053.tif\n",
      "n005.tif\n",
      "n011.tif\n",
      "n009.tif\n",
      "n100.tif\n",
      "n015.tif\n",
      "n089.tif\n",
      "n094.tif\n",
      "n060.tif\n",
      "n010.tif\n",
      "n054.tif\n",
      "n066.tif\n",
      "n039.tif\n",
      "n098.tif\n",
      "n079.tif\n",
      "n067.tif\n",
      "n017.tif\n",
      "n085.tif\n",
      "n014.tif\n",
      "n087.tif\n",
      "n069.tif\n",
      "n008.tif\n",
      "n031.tif\n",
      "n063.tif\n",
      "n065.tif\n",
      "n095.tif\n",
      "n027.tif\n",
      "n097.tif\n",
      "n049.tif\n",
      "n033.tif\n",
      "n070.tif\n",
      "n022.tif\n",
      "n090.tif\n",
      "n003.tif\n",
      "n042.tif\n",
      "n043.tif\n",
      "n052.tif\n",
      "n038.tif\n",
      "n037.tif\n",
      "n040.tif\n",
      "n026.tif\n",
      "n056.tif\n",
      "n064.tif\n",
      "n096.tif\n",
      "n012.tif\n",
      "n029.tif\n",
      "n024.tif\n",
      "n061.tif\n",
      "n077.tif\n",
      "n048.tif\n",
      "n034.tif\n",
      "n032.tif\n",
      "n016.tif\n",
      "n004.tif\n",
      "n073.tif\n",
      "n075.tif\n",
      "n025.tif\n",
      "n055.tif\n",
      "n046.tif\n",
      "n041.tif\n",
      "n001.tif\n",
      "n071.tif\n",
      "n057.tif\n",
      "n099.tif\n",
      "n081.tif\n",
      "n023.tif\n",
      "n086.tif\n",
      "n088.tif\n",
      "n092.tif\n",
      "n030.tif\n",
      "n074.tif\n",
      "n076.tif\n"
     ]
    }
   ],
   "source": [
    "## BACH dataset\n",
    "\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "bach_root = \"/tf/dataset/BACH\"\n",
    "bach_root_sub = [\"InSitu\",\"Invasive\",\"Normal\"]\n",
    "\n",
    "bach_patch_img_root = \"/tf/dataset/classes\"\n",
    "\n",
    "photo_size = (1536,2048)\n",
    "division = 2\n",
    "size_rows = np.int(photo_size[0]/division)\n",
    "size_cols = np.int(photo_size[1]/division)\n",
    "for sub_root in bach_root_sub:\n",
    "    for path,_,files_list in os.walk(os.path.join(bach_root,sub_root)):\n",
    "        for filename in files_list:\n",
    "            if filename.endswith('.tif'):\n",
    "                print(filename)\n",
    "                if filename[0] == 'n' or filename[0] == 'b':\n",
    "                    sub_folder = 'BACH_B'\n",
    "                else:\n",
    "                    sub_folder = 'BACH_M'\n",
    "                in_im = Image.open(os.path.join(path,filename))\n",
    "                imarray = np.array(in_im)\n",
    "                for i in range(division):\n",
    "                    for j in range(division):\n",
    "                        sub_imarray = imarray[i*size_rows:i*size_rows+size_rows,j*size_cols:j*size_cols+size_cols,:]\n",
    "                        ou_im = Image.fromarray(sub_imarray)\n",
    "                        ou_im.save(os.path.join(bach_patch_img_root,sub_folder,\"{}_{}_{}.png\" \n",
    "                                                . format(filename.split('.')[0],i,j)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## BACH dataset, generate csv file\n",
    "bach_patch_img_root = \"/tf/dataset/classes\"\n",
    "sub_root = [\"BACH_B\",\"BACH_M\"]\n",
    "for sub in sub_root:\n",
    "    img_arr = []\n",
    "    dir_size = os.path.join(bach_patch_img_root,sub)\n",
    "    for dirpath, dirnames, filenames in os.walk(dir_size,topdown=False):\n",
    "        for fn in filenames:\n",
    "            img_arr.append(os.path.join(dirpath,fn))\n",
    "            \n",
    "    out_file = os.path.join(bach_patch_img_root , \"{}_data_files.csv\" . format(sub))\n",
    "    with open(out_file, 'w') as writer:\n",
    "        for line in img_arr:\n",
    "            writer.write(line + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
