{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from codes.model.pix2pix_network import Pix2Pix\n",
    "from codes.data.load_data import load_files_for_gan\n",
    "\n",
    "\n",
    "dic_text_file = \"C:\\\\train_data.csv\"\n",
    "batch_size = 5\n",
    "\n",
    "train_org,test_org = load_files_for_gan(dic_text_file,587)\n",
    "\n",
    "train = train_org.shuffle(batch_size * 100)\n",
    "train = train.batch(batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x,y in train:\n",
    "    print(x.shape)\n",
    "    print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0501 00:56:05.722618  2396 training.py:2131] Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "W0501 00:56:07.845150  2396 training.py:2131] Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0/5] [Batch 1/587] [D loss: 10.928168, acc:  39%] [G loss: 70.164619] time: 0:00:24.041105\n",
      "[Epoch 0/5] [Batch 2/587] [D loss: 4.535206, acc:  53%] [G loss: 72.218666] time: 0:00:33.351478\n",
      "[Epoch 0/5] [Batch 3/587] [D loss: 2.713523, acc:  47%] [G loss: 64.574394] time: 0:00:42.848762\n",
      "[Epoch 0/5] [Batch 4/587] [D loss: 2.281439, acc:  52%] [G loss: 63.116932] time: 0:00:52.344993\n",
      "[Epoch 0/5] [Batch 5/587] [D loss: 5.054874, acc:  50%] [G loss: 63.831272] time: 0:01:01.909640\n",
      "[Epoch 0/5] [Batch 6/587] [D loss: 9.308306, acc:  54%] [G loss: 54.845730] time: 0:01:11.538037\n",
      "[Epoch 0/5] [Batch 7/587] [D loss: 1.919769, acc:  50%] [G loss: 50.494801] time: 0:01:21.171404\n",
      "[Epoch 0/5] [Batch 8/587] [D loss: 1.462365, acc:  49%] [G loss: 42.828121] time: 0:01:30.749486\n",
      "[Epoch 0/5] [Batch 9/587] [D loss: 1.228478, acc:  50%] [G loss: 41.003735] time: 0:01:40.254251\n",
      "[Epoch 0/5] [Batch 10/587] [D loss: 1.289001, acc:  50%] [G loss: 39.715641] time: 0:01:49.733964\n",
      "[Epoch 0/5] [Batch 11/587] [D loss: 1.275890, acc:  51%] [G loss: 28.017183] time: 0:01:59.297555\n",
      "[Epoch 0/5] [Batch 12/587] [D loss: 1.363781, acc:  47%] [G loss: 31.178522] time: 0:02:08.769892\n",
      "[Epoch 0/5] [Batch 13/587] [D loss: 1.270091, acc:  51%] [G loss: 25.590900] time: 0:02:18.317185\n",
      "[Epoch 0/5] [Batch 14/587] [D loss: 1.000646, acc:  48%] [G loss: 25.226572] time: 0:02:27.932700\n",
      "[Epoch 0/5] [Batch 15/587] [D loss: 1.139838, acc:  50%] [G loss: 27.128405] time: 0:02:37.497759\n",
      "[Epoch 0/5] [Batch 16/587] [D loss: 0.905615, acc:  48%] [G loss: 18.926907] time: 0:02:46.965344\n",
      "[Epoch 0/5] [Batch 17/587] [D loss: 0.917361, acc:  54%] [G loss: 20.865578] time: 0:02:56.427627\n",
      "[Epoch 0/5] [Batch 18/587] [D loss: 0.969760, acc:  47%] [G loss: 22.136429] time: 0:03:06.067967\n",
      "[Epoch 0/5] [Batch 19/587] [D loss: 1.101895, acc:  54%] [G loss: 28.211462] time: 0:03:15.567427\n",
      "[Epoch 0/5] [Batch 20/587] [D loss: 0.836480, acc:  45%] [G loss: 22.821716] time: 0:03:25.005031\n",
      "[Epoch 0/5] [Batch 21/587] [D loss: 1.054420, acc:  49%] [G loss: 27.434748] time: 0:03:34.538566\n",
      "[Epoch 0/5] [Batch 22/587] [D loss: 0.882633, acc:  49%] [G loss: 21.919884] time: 0:03:44.024776\n",
      "[Epoch 0/5] [Batch 23/587] [D loss: 0.828133, acc:  48%] [G loss: 17.006155] time: 0:03:53.527100\n",
      "[Epoch 0/5] [Batch 24/587] [D loss: 0.720059, acc:  51%] [G loss: 21.465336] time: 0:04:03.147464\n",
      "[Epoch 0/5] [Batch 25/587] [D loss: 0.790367, acc:  48%] [G loss: 20.397539] time: 0:04:12.715424\n",
      "[Epoch 0/5] [Batch 26/587] [D loss: 0.739510, acc:  48%] [G loss: 25.281042] time: 0:04:22.178756\n",
      "[Epoch 0/5] [Batch 27/587] [D loss: 0.775125, acc:  46%] [G loss: 26.670536] time: 0:04:31.694978\n",
      "[Epoch 0/5] [Batch 28/587] [D loss: 0.779806, acc:  48%] [G loss: 25.241447] time: 0:04:41.183437\n",
      "[Epoch 0/5] [Batch 29/587] [D loss: 0.683146, acc:  49%] [G loss: 19.289568] time: 0:04:51.934610\n",
      "[Epoch 0/5] [Batch 30/587] [D loss: 0.751248, acc:  48%] [G loss: 23.430902] time: 0:05:01.418530\n",
      "[Epoch 0/5] [Batch 31/587] [D loss: 0.712551, acc:  49%] [G loss: 24.186012] time: 0:05:10.974726\n",
      "[Epoch 0/5] [Batch 32/587] [D loss: 0.689216, acc:  51%] [G loss: 23.966106] time: 0:05:20.537263\n",
      "[Epoch 0/5] [Batch 33/587] [D loss: 2.513334, acc:  47%] [G loss: 30.201323] time: 0:05:30.097872\n",
      "[Epoch 0/5] [Batch 34/587] [D loss: 1.914616, acc:  45%] [G loss: 28.753567] time: 0:05:39.633387\n",
      "[Epoch 0/5] [Batch 35/587] [D loss: 0.913326, acc:  52%] [G loss: 20.995541] time: 0:05:49.101719\n",
      "[Epoch 0/5] [Batch 36/587] [D loss: 0.745449, acc:  48%] [G loss: 20.890026] time: 0:05:58.571648\n",
      "[Epoch 0/5] [Batch 37/587] [D loss: 0.759015, acc:  49%] [G loss: 23.426138] time: 0:06:08.068857\n",
      "[Epoch 0/5] [Batch 38/587] [D loss: 0.613619, acc:  47%] [G loss: 15.729385] time: 0:06:17.544238\n",
      "[Epoch 0/5] [Batch 39/587] [D loss: 0.584644, acc:  51%] [G loss: 16.314968] time: 0:06:27.073945\n",
      "[Epoch 0/5] [Batch 40/587] [D loss: 0.656008, acc:  51%] [G loss: 20.626837] time: 0:06:36.651526\n",
      "[Epoch 0/5] [Batch 41/587] [D loss: 0.752165, acc:  45%] [G loss: 22.128305] time: 0:06:46.152009\n",
      "[Epoch 0/5] [Batch 42/587] [D loss: 0.834301, acc:  50%] [G loss: 25.044720] time: 0:06:55.641217\n",
      "[Epoch 0/5] [Batch 43/587] [D loss: 0.650951, acc:  45%] [G loss: 18.550901] time: 0:07:05.119171\n",
      "[Epoch 0/5] [Batch 44/587] [D loss: 0.636769, acc:  48%] [G loss: 16.200684] time: 0:07:14.610717\n",
      "[Epoch 0/5] [Batch 45/587] [D loss: 0.864708, acc:  46%] [G loss: 19.287024] time: 0:07:24.103953\n",
      "[Epoch 0/5] [Batch 46/587] [D loss: 0.723241, acc:  45%] [G loss: 20.711197] time: 0:07:33.590342\n",
      "[Epoch 0/5] [Batch 47/587] [D loss: 0.538258, acc:  48%] [G loss: 15.625467] time: 0:07:43.108992\n",
      "[Epoch 0/5] [Batch 48/587] [D loss: 0.535332, acc:  47%] [G loss: 25.066746] time: 0:07:52.635637\n",
      "[Epoch 0/5] [Batch 49/587] [D loss: 0.531233, acc:  47%] [G loss: 24.592815] time: 0:08:02.170293\n",
      "[Epoch 0/5] [Batch 50/587] [D loss: 0.580354, acc:  48%] [G loss: 24.857843] time: 0:08:11.641150\n",
      "[Epoch 0/5] [Batch 51/587] [D loss: 0.447444, acc:  50%] [G loss: 22.306725] time: 0:08:21.099296\n",
      "[Epoch 0/5] [Batch 52/587] [D loss: 0.470251, acc:  48%] [G loss: 22.430477] time: 0:08:30.542689\n",
      "[Epoch 0/5] [Batch 53/587] [D loss: 0.538018, acc:  48%] [G loss: 16.537920] time: 0:08:40.148037\n",
      "[Epoch 0/5] [Batch 54/587] [D loss: 0.504179, acc:  45%] [G loss: 26.178974] time: 0:08:49.716624\n",
      "[Epoch 0/5] [Batch 55/587] [D loss: 0.449166, acc:  48%] [G loss: 22.897285] time: 0:08:59.203644\n",
      "[Epoch 0/5] [Batch 56/587] [D loss: 0.495455, acc:  50%] [G loss: 19.870184] time: 0:09:08.666472\n",
      "[Epoch 0/5] [Batch 57/587] [D loss: 0.435493, acc:  49%] [G loss: 22.440632] time: 0:09:19.491123\n",
      "[Epoch 0/5] [Batch 58/587] [D loss: 0.448211, acc:  47%] [G loss: 24.389315] time: 0:09:29.047849\n",
      "[Epoch 0/5] [Batch 59/587] [D loss: 0.413123, acc:  48%] [G loss: 15.396465] time: 0:09:38.613804\n",
      "[Epoch 0/5] [Batch 60/587] [D loss: 0.392848, acc:  52%] [G loss: 19.235580] time: 0:09:48.189241\n",
      "[Epoch 0/5] [Batch 61/587] [D loss: 0.408594, acc:  54%] [G loss: 17.857271] time: 0:09:57.668760\n",
      "[Epoch 0/5] [Batch 62/587] [D loss: 0.445107, acc:  55%] [G loss: 22.716988] time: 0:10:07.149170\n",
      "[Epoch 0/5] [Batch 63/587] [D loss: 0.513757, acc:  42%] [G loss: 20.802546] time: 0:10:16.707864\n",
      "[Epoch 0/5] [Batch 64/587] [D loss: 0.496518, acc:  45%] [G loss: 19.532696] time: 0:10:26.240977\n",
      "[Epoch 0/5] [Batch 65/587] [D loss: 0.403719, acc:  51%] [G loss: 20.664686] time: 0:10:35.657406\n",
      "[Epoch 0/5] [Batch 66/587] [D loss: 0.365119, acc:  47%] [G loss: 19.535065] time: 0:10:45.221746\n",
      "[Epoch 0/5] [Batch 67/587] [D loss: 0.395274, acc:  49%] [G loss: 20.277067] time: 0:10:54.669365\n",
      "[Epoch 0/5] [Batch 68/587] [D loss: 0.399019, acc:  47%] [G loss: 19.454222] time: 0:11:04.115886\n",
      "[Epoch 0/5] [Batch 69/587] [D loss: 0.394814, acc:  46%] [G loss: 19.746153] time: 0:11:13.672695\n",
      "[Epoch 0/5] [Batch 70/587] [D loss: 0.408568, acc:  52%] [G loss: 23.757475] time: 0:11:23.160455\n",
      "[Epoch 0/5] [Batch 71/587] [D loss: 0.377847, acc:  47%] [G loss: 15.297542] time: 0:11:32.623709\n",
      "[Epoch 0/5] [Batch 72/587] [D loss: 0.405271, acc:  48%] [G loss: 19.792276] time: 0:11:42.014171\n",
      "[Epoch 0/5] [Batch 73/587] [D loss: 0.448084, acc:  46%] [G loss: 17.907742] time: 0:11:51.470528\n",
      "[Epoch 0/5] [Batch 74/587] [D loss: 0.428011, acc:  50%] [G loss: 18.553717] time: 0:12:00.896636\n",
      "[Epoch 0/5] [Batch 75/587] [D loss: 0.384571, acc:  46%] [G loss: 17.199064] time: 0:12:10.374452\n",
      "[Epoch 0/5] [Batch 76/587] [D loss: 0.353021, acc:  47%] [G loss: 20.133648] time: 0:12:19.932526\n",
      "[Epoch 0/5] [Batch 77/587] [D loss: 0.344225, acc:  50%] [G loss: 22.554642] time: 0:12:29.340957\n",
      "[Epoch 0/5] [Batch 78/587] [D loss: 0.342474, acc:  51%] [G loss: 21.615427] time: 0:12:38.779159\n",
      "[Epoch 0/5] [Batch 79/587] [D loss: 0.404829, acc:  50%] [G loss: 21.558895] time: 0:12:48.215818\n",
      "[Epoch 0/5] [Batch 80/587] [D loss: 0.361628, acc:  46%] [G loss: 16.929844] time: 0:12:57.691869\n",
      "[Epoch 0/5] [Batch 81/587] [D loss: 0.373383, acc:  45%] [G loss: 21.604973] time: 0:13:07.254392\n",
      "[Epoch 0/5] [Batch 82/587] [D loss: 0.344720, acc:  48%] [G loss: 23.429157] time: 0:13:16.775194\n",
      "[Epoch 0/5] [Batch 83/587] [D loss: 0.378162, acc:  49%] [G loss: 20.700590] time: 0:13:26.333939\n",
      "[Epoch 0/5] [Batch 84/587] [D loss: 0.352225, acc:  48%] [G loss: 20.430317] time: 0:13:35.789812\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0/5] [Batch 85/587] [D loss: 0.340243, acc:  48%] [G loss: 21.552378] time: 0:13:46.469794\n",
      "[Epoch 0/5] [Batch 86/587] [D loss: 0.333278, acc:  49%] [G loss: 18.519011] time: 0:13:56.002913\n",
      "[Epoch 0/5] [Batch 87/587] [D loss: 0.366310, acc:  43%] [G loss: 19.867908] time: 0:14:05.498596\n",
      "[Epoch 0/5] [Batch 88/587] [D loss: 0.339759, acc:  49%] [G loss: 17.836504] time: 0:14:15.008826\n",
      "[Epoch 0/5] [Batch 89/587] [D loss: 0.373736, acc:  46%] [G loss: 20.132431] time: 0:14:24.393225\n",
      "[Epoch 0/5] [Batch 90/587] [D loss: 0.503169, acc:  41%] [G loss: 20.023148] time: 0:14:33.852915\n",
      "[Epoch 0/5] [Batch 91/587] [D loss: 0.781389, acc:  43%] [G loss: 26.943731] time: 0:14:43.285458\n",
      "[Epoch 0/5] [Batch 92/587] [D loss: 0.423705, acc:  47%] [G loss: 20.668781] time: 0:14:52.788193\n",
      "[Epoch 0/5] [Batch 93/587] [D loss: 0.420272, acc:  49%] [G loss: 20.233501] time: 0:15:02.210869\n",
      "[Epoch 0/5] [Batch 94/587] [D loss: 0.561904, acc:  40%] [G loss: 22.920065] time: 0:15:11.675057\n",
      "[Epoch 1/5] [Batch 95/587] [D loss: 0.392897, acc:  46%] [G loss: 26.081833] time: 0:15:26.945908\n",
      "[Epoch 1/5] [Batch 96/587] [D loss: 0.313596, acc:  50%] [G loss: 20.346104] time: 0:15:36.392239\n",
      "[Epoch 1/5] [Batch 97/587] [D loss: 0.335373, acc:  51%] [G loss: 18.730745] time: 0:15:45.879630\n",
      "[Epoch 1/5] [Batch 98/587] [D loss: 0.376952, acc:  47%] [G loss: 18.207430] time: 0:15:55.415538\n",
      "[Epoch 1/5] [Batch 99/587] [D loss: 0.330981, acc:  48%] [G loss: 14.728572] time: 0:16:04.989312\n",
      "[Epoch 1/5] [Batch 100/587] [D loss: 0.314760, acc:  45%] [G loss: 19.891245] time: 0:16:14.556056\n",
      "[Epoch 1/5] [Batch 101/587] [D loss: 0.311938, acc:  48%] [G loss: 23.493124] time: 0:16:24.096342\n",
      "[Epoch 1/5] [Batch 102/587] [D loss: 0.426721, acc:  38%] [G loss: 21.097300] time: 0:16:33.612684\n",
      "[Epoch 1/5] [Batch 103/587] [D loss: 0.352801, acc:  49%] [G loss: 17.581774] time: 0:16:43.192795\n",
      "[Epoch 1/5] [Batch 104/587] [D loss: 0.332289, acc:  50%] [G loss: 22.608906] time: 0:16:52.766320\n",
      "[Epoch 1/5] [Batch 105/587] [D loss: 0.562013, acc:  55%] [G loss: 19.921993] time: 0:17:02.266755\n",
      "[Epoch 1/5] [Batch 106/587] [D loss: 0.310331, acc:  52%] [G loss: 22.876719] time: 0:17:11.713986\n",
      "[Epoch 1/5] [Batch 107/587] [D loss: 0.294988, acc:  48%] [G loss: 19.370239] time: 0:17:21.263470\n",
      "[Epoch 1/5] [Batch 108/587] [D loss: 0.324201, acc:  49%] [G loss: 28.329340] time: 0:17:30.700567\n",
      "[Epoch 1/5] [Batch 109/587] [D loss: 0.353700, acc:  50%] [G loss: 24.137516] time: 0:17:40.186209\n",
      "[Epoch 1/5] [Batch 110/587] [D loss: 0.318733, acc:  55%] [G loss: 17.956842] time: 0:17:49.688790\n",
      "[Epoch 1/5] [Batch 111/587] [D loss: 0.425374, acc:  48%] [G loss: 21.884068] time: 0:17:59.225687\n",
      "[Epoch 1/5] [Batch 112/587] [D loss: 0.368200, acc:  53%] [G loss: 15.505798] time: 0:18:08.637526\n",
      "[Epoch 1/5] [Batch 113/587] [D loss: 0.312092, acc:  51%] [G loss: 24.450863] time: 0:18:19.475762\n",
      "[Epoch 1/5] [Batch 114/587] [D loss: 0.337476, acc:  52%] [G loss: 22.220831] time: 0:18:29.016503\n",
      "[Epoch 1/5] [Batch 115/587] [D loss: 0.320329, acc:  53%] [G loss: 15.283035] time: 0:18:38.559873\n",
      "[Epoch 1/5] [Batch 116/587] [D loss: 0.325171, acc:  45%] [G loss: 19.231129] time: 0:18:48.100254\n",
      "[Epoch 1/5] [Batch 117/587] [D loss: 0.358367, acc:  49%] [G loss: 14.317736] time: 0:18:57.653170\n",
      "[Epoch 1/5] [Batch 118/587] [D loss: 0.330810, acc:  53%] [G loss: 21.518835] time: 0:19:07.247983\n",
      "[Epoch 1/5] [Batch 119/587] [D loss: 0.296901, acc:  49%] [G loss: 18.627857] time: 0:19:16.857199\n",
      "[Epoch 1/5] [Batch 120/587] [D loss: 0.282283, acc:  50%] [G loss: 19.988329] time: 0:19:26.367281\n",
      "[Epoch 1/5] [Batch 121/587] [D loss: 0.303910, acc:  53%] [G loss: 21.385359] time: 0:19:35.866554\n",
      "[Epoch 1/5] [Batch 122/587] [D loss: 0.342593, acc:  46%] [G loss: 18.505133] time: 0:19:45.539080\n",
      "[Epoch 1/5] [Batch 123/587] [D loss: 0.352857, acc:  46%] [G loss: 26.496290] time: 0:19:55.137245\n",
      "[Epoch 1/5] [Batch 124/587] [D loss: 0.302410, acc:  51%] [G loss: 23.609385] time: 0:20:04.721790\n",
      "[Epoch 1/5] [Batch 125/587] [D loss: 0.374788, acc:  53%] [G loss: 24.728439] time: 0:20:14.306347\n",
      "[Epoch 1/5] [Batch 126/587] [D loss: 0.393435, acc:  51%] [G loss: 19.624636] time: 0:20:23.775496\n",
      "[Epoch 1/5] [Batch 127/587] [D loss: 0.297767, acc:  50%] [G loss: 20.211378] time: 0:20:33.188519\n",
      "[Epoch 1/5] [Batch 128/587] [D loss: 0.280932, acc:  52%] [G loss: 21.169786] time: 0:20:42.686709\n",
      "[Epoch 1/5] [Batch 129/587] [D loss: 0.289223, acc:  48%] [G loss: 22.241812] time: 0:20:52.235848\n",
      "[Epoch 1/5] [Batch 130/587] [D loss: 0.321492, acc:  47%] [G loss: 23.973188] time: 0:21:01.744677\n",
      "[Epoch 1/5] [Batch 131/587] [D loss: 0.323872, acc:  45%] [G loss: 21.682419] time: 0:21:11.218039\n",
      "[Epoch 1/5] [Batch 132/587] [D loss: 0.332788, acc:  44%] [G loss: 15.581120] time: 0:21:20.789750\n",
      "[Epoch 1/5] [Batch 133/587] [D loss: 0.362258, acc:  49%] [G loss: 17.531937] time: 0:21:30.293210\n",
      "[Epoch 1/5] [Batch 134/587] [D loss: 0.302015, acc:  53%] [G loss: 17.428455] time: 0:21:39.848165\n",
      "[Epoch 1/5] [Batch 135/587] [D loss: 0.307911, acc:  46%] [G loss: 20.190155] time: 0:21:49.403869\n",
      "[Epoch 1/5] [Batch 136/587] [D loss: 0.302958, acc:  47%] [G loss: 22.393850] time: 0:21:59.056631\n",
      "[Epoch 1/5] [Batch 137/587] [D loss: 0.319410, acc:  49%] [G loss: 18.426104] time: 0:22:08.595676\n",
      "[Epoch 1/5] [Batch 138/587] [D loss: 0.301082, acc:  49%] [G loss: 20.762001] time: 0:22:18.245765\n",
      "[Epoch 1/5] [Batch 139/587] [D loss: 0.287020, acc:  49%] [G loss: 20.134748] time: 0:22:27.867598\n",
      "[Epoch 1/5] [Batch 140/587] [D loss: 0.285951, acc:  53%] [G loss: 23.067270] time: 0:22:37.387057\n",
      "[Epoch 1/5] [Batch 141/587] [D loss: 0.279173, acc:  57%] [G loss: 17.652130] time: 0:22:48.145730\n",
      "[Epoch 1/5] [Batch 142/587] [D loss: 0.266758, acc:  54%] [G loss: 17.630409] time: 0:22:57.684034\n",
      "[Epoch 1/5] [Batch 143/587] [D loss: 0.290773, acc:  51%] [G loss: 20.256548] time: 0:23:07.264218\n",
      "[Epoch 1/5] [Batch 144/587] [D loss: 0.279728, acc:  52%] [G loss: 14.993765] time: 0:23:16.846116\n",
      "[Epoch 1/5] [Batch 145/587] [D loss: 0.272221, acc:  53%] [G loss: 14.076164] time: 0:23:26.449262\n",
      "[Epoch 1/5] [Batch 146/587] [D loss: 0.296378, acc:  57%] [G loss: 19.883825] time: 0:23:35.994586\n",
      "[Epoch 1/5] [Batch 147/587] [D loss: 0.352915, acc:  46%] [G loss: 20.151987] time: 0:23:45.484750\n",
      "[Epoch 1/5] [Batch 148/587] [D loss: 0.284676, acc:  54%] [G loss: 21.157280] time: 0:23:55.092038\n",
      "[Epoch 1/5] [Batch 149/587] [D loss: 0.325362, acc:  55%] [G loss: 23.475248] time: 0:24:04.672188\n",
      "[Epoch 1/5] [Batch 150/587] [D loss: 0.491472, acc:  45%] [G loss: 18.679392] time: 0:24:14.187215\n",
      "[Epoch 1/5] [Batch 151/587] [D loss: 0.907258, acc:  43%] [G loss: 19.552723] time: 0:24:23.813619\n",
      "[Epoch 1/5] [Batch 152/587] [D loss: 0.612017, acc:  63%] [G loss: 21.982790] time: 0:24:33.409231\n",
      "[Epoch 1/5] [Batch 153/587] [D loss: 0.301683, acc:  56%] [G loss: 19.636549] time: 0:24:43.090156\n",
      "[Epoch 1/5] [Batch 154/587] [D loss: 0.317098, acc:  50%] [G loss: 24.215675] time: 0:24:52.666893\n",
      "[Epoch 1/5] [Batch 155/587] [D loss: 0.348674, acc:  41%] [G loss: 20.121460] time: 0:25:02.094563\n",
      "[Epoch 1/5] [Batch 156/587] [D loss: 0.456507, acc:  49%] [G loss: 19.311371] time: 0:25:11.625979\n",
      "[Epoch 1/5] [Batch 157/587] [D loss: 0.713925, acc:  38%] [G loss: 18.956148] time: 0:25:21.017378\n",
      "[Epoch 1/5] [Batch 158/587] [D loss: 0.706242, acc:  40%] [G loss: 22.243372] time: 0:25:30.622684\n",
      "[Epoch 1/5] [Batch 159/587] [D loss: 0.370706, acc:  50%] [G loss: 20.225876] time: 0:25:40.216948\n",
      "[Epoch 1/5] [Batch 160/587] [D loss: 0.322137, acc:  49%] [G loss: 17.450176] time: 0:25:49.660560\n",
      "[Epoch 1/5] [Batch 161/587] [D loss: 0.263518, acc:  60%] [G loss: 25.716394] time: 0:25:59.394298\n",
      "[Epoch 1/5] [Batch 162/587] [D loss: 0.292023, acc:  51%] [G loss: 15.771546] time: 0:26:08.955351\n",
      "[Epoch 1/5] [Batch 163/587] [D loss: 0.305847, acc:  47%] [G loss: 21.397005] time: 0:26:19.201409\n",
      "[Epoch 1/5] [Batch 164/587] [D loss: 0.303228, acc:  49%] [G loss: 19.145782] time: 0:26:28.922220\n",
      "[Epoch 1/5] [Batch 165/587] [D loss: 0.291552, acc:  51%] [G loss: 18.213869] time: 0:26:38.452661\n",
      "[Epoch 1/5] [Batch 166/587] [D loss: 0.283137, acc:  53%] [G loss: 20.488928] time: 0:26:47.908582\n",
      "[Epoch 1/5] [Batch 167/587] [D loss: 0.294966, acc:  50%] [G loss: 20.461065] time: 0:26:57.419981\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/5] [Batch 168/587] [D loss: 0.260946, acc:  57%] [G loss: 21.976452] time: 0:27:06.941032\n",
      "[Epoch 1/5] [Batch 169/587] [D loss: 0.271302, acc:  52%] [G loss: 18.239765] time: 0:27:17.640594\n",
      "[Epoch 1/5] [Batch 170/587] [D loss: 0.256667, acc:  58%] [G loss: 22.167997] time: 0:27:27.130368\n",
      "[Epoch 1/5] [Batch 171/587] [D loss: 0.291607, acc:  53%] [G loss: 17.354776] time: 0:27:36.683449\n",
      "[Epoch 1/5] [Batch 172/587] [D loss: 0.315002, acc:  44%] [G loss: 18.940954] time: 0:27:46.156278\n",
      "[Epoch 1/5] [Batch 173/587] [D loss: 0.392415, acc:  49%] [G loss: 15.587750] time: 0:27:55.717145\n",
      "[Epoch 1/5] [Batch 174/587] [D loss: 0.266656, acc:  56%] [G loss: 20.673615] time: 0:28:05.267548\n",
      "[Epoch 1/5] [Batch 175/587] [D loss: 0.322657, acc:  55%] [G loss: 15.056843] time: 0:28:14.723505\n",
      "[Epoch 1/5] [Batch 176/587] [D loss: 0.258174, acc:  58%] [G loss: 18.738062] time: 0:28:24.171651\n",
      "[Epoch 1/5] [Batch 177/587] [D loss: 0.311995, acc:  57%] [G loss: 22.043734] time: 0:28:33.626224\n",
      "[Epoch 1/5] [Batch 178/587] [D loss: 0.338298, acc:  59%] [G loss: 21.080118] time: 0:28:43.190142\n",
      "[Epoch 1/5] [Batch 179/587] [D loss: 0.297356, acc:  56%] [G loss: 21.065948] time: 0:28:52.797288\n",
      "[Epoch 1/5] [Batch 180/587] [D loss: 0.275015, acc:  61%] [G loss: 22.376282] time: 0:29:02.305693\n",
      "[Epoch 1/5] [Batch 181/587] [D loss: 0.284159, acc:  58%] [G loss: 21.537092] time: 0:29:11.936120\n",
      "[Epoch 1/5] [Batch 182/587] [D loss: 0.246941, acc:  60%] [G loss: 17.809540] time: 0:29:21.464146\n",
      "[Epoch 1/5] [Batch 183/587] [D loss: 0.250154, acc:  59%] [G loss: 20.732328] time: 0:29:30.985838\n",
      "[Epoch 1/5] [Batch 184/587] [D loss: 0.272942, acc:  58%] [G loss: 15.347971] time: 0:29:40.440752\n",
      "[Epoch 1/5] [Batch 185/587] [D loss: 0.266284, acc:  58%] [G loss: 23.867292] time: 0:29:49.973852\n",
      "[Epoch 1/5] [Batch 186/587] [D loss: 0.320767, acc:  54%] [G loss: 19.752804] time: 0:29:59.563266\n",
      "[Epoch 1/5] [Batch 187/587] [D loss: 0.386489, acc:  54%] [G loss: 20.413820] time: 0:30:09.031102\n",
      "[Epoch 1/5] [Batch 188/587] [D loss: 0.347081, acc:  53%] [G loss: 20.434017] time: 0:30:18.517251\n",
      "[Epoch 2/5] [Batch 189/587] [D loss: 0.256616, acc:  58%] [G loss: 20.996279] time: 0:30:33.814906\n",
      "[Epoch 2/5] [Batch 190/587] [D loss: 0.245642, acc:  61%] [G loss: 23.985172] time: 0:30:43.274540\n",
      "[Epoch 2/5] [Batch 191/587] [D loss: 0.316124, acc:  44%] [G loss: 15.487214] time: 0:30:52.845473\n",
      "[Epoch 2/5] [Batch 192/587] [D loss: 0.253962, acc:  63%] [G loss: 22.380638] time: 0:31:02.497806\n",
      "[Epoch 2/5] [Batch 193/587] [D loss: 0.272402, acc:  57%] [G loss: 20.633432] time: 0:31:12.072955\n",
      "[Epoch 2/5] [Batch 194/587] [D loss: 0.264857, acc:  59%] [G loss: 14.432422] time: 0:31:21.472937\n",
      "[Epoch 2/5] [Batch 195/587] [D loss: 0.306958, acc:  51%] [G loss: 24.451403] time: 0:31:30.973954\n",
      "[Epoch 2/5] [Batch 196/587] [D loss: 0.325508, acc:  48%] [G loss: 19.719494] time: 0:31:40.490372\n",
      "[Epoch 2/5] [Batch 197/587] [D loss: 0.281518, acc:  53%] [G loss: 17.739122] time: 0:31:51.253507\n",
      "[Epoch 2/5] [Batch 198/587] [D loss: 0.339428, acc:  57%] [G loss: 21.632679] time: 0:32:00.861731\n",
      "[Epoch 2/5] [Batch 199/587] [D loss: 0.461332, acc:  64%] [G loss: 18.819241] time: 0:32:10.564747\n",
      "[Epoch 2/5] [Batch 200/587] [D loss: 0.420269, acc:  55%] [G loss: 20.650091] time: 0:32:20.177248\n",
      "[Epoch 2/5] [Batch 201/587] [D loss: 0.227911, acc:  62%] [G loss: 18.016026] time: 0:32:29.757149\n",
      "[Epoch 2/5] [Batch 202/587] [D loss: 0.290365, acc:  57%] [G loss: 13.694477] time: 0:32:39.297548\n",
      "[Epoch 2/5] [Batch 203/587] [D loss: 0.379744, acc:  55%] [G loss: 18.060339] time: 0:32:48.852949\n",
      "[Epoch 2/5] [Batch 204/587] [D loss: 0.265570, acc:  58%] [G loss: 23.891319] time: 0:32:58.425463\n",
      "[Epoch 2/5] [Batch 205/587] [D loss: 0.221795, acc:  64%] [G loss: 13.884456] time: 0:33:08.008142\n",
      "[Epoch 2/5] [Batch 206/587] [D loss: 0.251243, acc:  64%] [G loss: 23.238092] time: 0:33:17.600576\n",
      "[Epoch 2/5] [Batch 207/587] [D loss: 0.262487, acc:  62%] [G loss: 21.753281] time: 0:33:27.055254\n",
      "[Epoch 2/5] [Batch 208/587] [D loss: 0.280916, acc:  57%] [G loss: 21.715134] time: 0:33:36.644781\n",
      "[Epoch 2/5] [Batch 209/587] [D loss: 0.291608, acc:  56%] [G loss: 19.702801] time: 0:33:46.196847\n",
      "[Epoch 2/5] [Batch 210/587] [D loss: 0.224454, acc:  65%] [G loss: 25.727535] time: 0:33:55.874275\n",
      "[Epoch 2/5] [Batch 211/587] [D loss: 0.221113, acc:  62%] [G loss: 19.977530] time: 0:34:05.401715\n",
      "[Epoch 2/5] [Batch 212/587] [D loss: 0.240029, acc:  62%] [G loss: 20.433012] time: 0:34:15.009141\n",
      "[Epoch 2/5] [Batch 213/587] [D loss: 0.205893, acc:  68%] [G loss: 15.206382] time: 0:34:24.651168\n",
      "[Epoch 2/5] [Batch 214/587] [D loss: 0.219604, acc:  65%] [G loss: 17.584286] time: 0:34:34.182745\n",
      "[Epoch 2/5] [Batch 215/587] [D loss: 0.228598, acc:  67%] [G loss: 16.503180] time: 0:34:43.822819\n",
      "[Epoch 2/5] [Batch 216/587] [D loss: 0.219612, acc:  65%] [G loss: 18.088112] time: 0:34:53.386850\n",
      "[Epoch 2/5] [Batch 217/587] [D loss: 0.181726, acc:  73%] [G loss: 13.727620] time: 0:35:02.965777\n",
      "[Epoch 2/5] [Batch 218/587] [D loss: 0.260409, acc:  56%] [G loss: 15.073296] time: 0:35:12.476422\n",
      "[Epoch 2/5] [Batch 219/587] [D loss: 0.218526, acc:  69%] [G loss: 22.166882] time: 0:35:22.118594\n",
      "[Epoch 2/5] [Batch 220/587] [D loss: 0.246827, acc:  60%] [G loss: 20.078434] time: 0:35:31.627112\n",
      "[Epoch 2/5] [Batch 221/587] [D loss: 0.277092, acc:  53%] [G loss: 21.301640] time: 0:35:41.086684\n",
      "[Epoch 2/5] [Batch 222/587] [D loss: 0.326071, acc:  52%] [G loss: 19.095396] time: 0:35:50.654013\n",
      "[Epoch 2/5] [Batch 223/587] [D loss: 0.360632, acc:  54%] [G loss: 20.801029] time: 0:36:00.157184\n",
      "[Epoch 2/5] [Batch 224/587] [D loss: 0.505402, acc:  72%] [G loss: 18.279629] time: 0:36:09.819459\n",
      "[Epoch 2/5] [Batch 225/587] [D loss: 0.655682, acc:  59%] [G loss: 21.926918] time: 0:36:20.694508\n",
      "[Epoch 2/5] [Batch 226/587] [D loss: 0.286031, acc:  65%] [G loss: 18.536003] time: 0:36:30.204073\n",
      "[Epoch 2/5] [Batch 227/587] [D loss: 0.287270, acc:  59%] [G loss: 23.775164] time: 0:36:39.803296\n",
      "[Epoch 2/5] [Batch 228/587] [D loss: 0.341784, acc:  55%] [G loss: 15.497851] time: 0:36:49.322744\n",
      "[Epoch 2/5] [Batch 229/587] [D loss: 0.337038, acc:  61%] [G loss: 20.461151] time: 0:36:58.857708\n",
      "[Epoch 2/5] [Batch 230/587] [D loss: 0.458937, acc:  56%] [G loss: 23.057571] time: 0:37:08.446236\n",
      "[Epoch 2/5] [Batch 231/587] [D loss: 0.298195, acc:  55%] [G loss: 18.215946] time: 0:37:17.944538\n",
      "[Epoch 2/5] [Batch 232/587] [D loss: 0.281632, acc:  59%] [G loss: 12.879415] time: 0:37:27.484560\n",
      "[Epoch 2/5] [Batch 233/587] [D loss: 0.221229, acc:  66%] [G loss: 17.696671] time: 0:37:36.960585\n",
      "[Epoch 2/5] [Batch 234/587] [D loss: 0.239772, acc:  68%] [G loss: 19.107637] time: 0:37:46.517884\n",
      "[Epoch 2/5] [Batch 235/587] [D loss: 0.287956, acc:  66%] [G loss: 20.010454] time: 0:37:56.101877\n",
      "[Epoch 2/5] [Batch 236/587] [D loss: 0.442762, acc:  64%] [G loss: 19.241762] time: 0:38:05.589670\n",
      "[Epoch 2/5] [Batch 237/587] [D loss: 0.286553, acc:  71%] [G loss: 19.527498] time: 0:38:15.200692\n",
      "[Epoch 2/5] [Batch 238/587] [D loss: 0.267453, acc:  61%] [G loss: 19.068869] time: 0:38:24.727180\n",
      "[Epoch 2/5] [Batch 239/587] [D loss: 0.267837, acc:  61%] [G loss: 15.705585] time: 0:38:34.312701\n",
      "[Epoch 2/5] [Batch 240/587] [D loss: 0.217447, acc:  68%] [G loss: 22.508591] time: 0:38:43.869760\n",
      "[Epoch 2/5] [Batch 241/587] [D loss: 0.233751, acc:  70%] [G loss: 20.000916] time: 0:38:53.323685\n",
      "[Epoch 2/5] [Batch 242/587] [D loss: 0.229030, acc:  71%] [G loss: 16.936205] time: 0:39:02.819938\n",
      "[Epoch 2/5] [Batch 243/587] [D loss: 0.226976, acc:  69%] [G loss: 21.485558] time: 0:39:12.367786\n",
      "[Epoch 2/5] [Batch 244/587] [D loss: 0.196112, acc:  71%] [G loss: 20.760368] time: 0:39:21.896584\n",
      "[Epoch 2/5] [Batch 245/587] [D loss: 0.207203, acc:  70%] [G loss: 20.735294] time: 0:39:31.508148\n",
      "[Epoch 2/5] [Batch 246/587] [D loss: 0.291994, acc:  53%] [G loss: 18.541817] time: 0:39:41.010695\n",
      "[Epoch 2/5] [Batch 247/587] [D loss: 0.191145, acc:  73%] [G loss: 22.700762] time: 0:39:50.547010\n",
      "[Epoch 2/5] [Batch 248/587] [D loss: 0.164886, acc:  76%] [G loss: 26.563444] time: 0:40:00.020398\n",
      "[Epoch 2/5] [Batch 249/587] [D loss: 0.322886, acc:  55%] [G loss: 18.411663] time: 0:40:09.534207\n",
      "[Epoch 2/5] [Batch 250/587] [D loss: 0.212540, acc:  70%] [G loss: 20.873978] time: 0:40:19.087884\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2/5] [Batch 251/587] [D loss: 0.222147, acc:  69%] [G loss: 21.818806] time: 0:40:28.596309\n",
      "[Epoch 2/5] [Batch 252/587] [D loss: 0.208123, acc:  73%] [G loss: 18.063103] time: 0:40:38.107206\n",
      "[Epoch 2/5] [Batch 253/587] [D loss: 0.339019, acc:  63%] [G loss: 20.144867] time: 0:40:48.743871\n",
      "[Epoch 2/5] [Batch 254/587] [D loss: 0.148198, acc:  83%] [G loss: 20.523773] time: 0:40:58.431405\n",
      "[Epoch 2/5] [Batch 255/587] [D loss: 0.142079, acc:  82%] [G loss: 24.074368] time: 0:41:07.916655\n",
      "[Epoch 2/5] [Batch 256/587] [D loss: 0.155421, acc:  83%] [G loss: 17.320587] time: 0:41:17.448301\n",
      "[Epoch 2/5] [Batch 257/587] [D loss: 0.269697, acc:  65%] [G loss: 17.308556] time: 0:41:26.958148\n",
      "[Epoch 2/5] [Batch 258/587] [D loss: 0.362657, acc:  58%] [G loss: 16.636868] time: 0:41:36.399444\n",
      "[Epoch 2/5] [Batch 259/587] [D loss: 0.374614, acc:  52%] [G loss: 21.074587] time: 0:41:45.898996\n",
      "[Epoch 2/5] [Batch 260/587] [D loss: 0.244894, acc:  62%] [G loss: 21.618881] time: 0:41:55.409271\n",
      "[Epoch 2/5] [Batch 261/587] [D loss: 0.262233, acc:  56%] [G loss: 21.847349] time: 0:42:04.860190\n",
      "[Epoch 2/5] [Batch 262/587] [D loss: 0.189138, acc:  75%] [G loss: 20.556259] time: 0:42:14.411834\n",
      "[Epoch 2/5] [Batch 263/587] [D loss: 0.210165, acc:  68%] [G loss: 18.241659] time: 0:42:23.871462\n",
      "[Epoch 2/5] [Batch 264/587] [D loss: 0.259070, acc:  59%] [G loss: 20.487753] time: 0:42:33.421141\n",
      "[Epoch 2/5] [Batch 265/587] [D loss: 0.235870, acc:  64%] [G loss: 19.237301] time: 0:42:42.888956\n",
      "[Epoch 2/5] [Batch 266/587] [D loss: 0.225960, acc:  61%] [G loss: 26.939199] time: 0:42:52.448459\n",
      "[Epoch 2/5] [Batch 267/587] [D loss: 0.750957, acc:  50%] [G loss: 19.977928] time: 0:43:01.972622\n",
      "[Epoch 2/5] [Batch 268/587] [D loss: 1.081579, acc:  53%] [G loss: 22.160618] time: 0:43:11.476468\n",
      "[Epoch 2/5] [Batch 269/587] [D loss: 0.831712, acc:  59%] [G loss: 30.630341] time: 0:43:21.036250\n",
      "[Epoch 2/5] [Batch 270/587] [D loss: 0.820429, acc:  63%] [G loss: 21.748615] time: 0:43:30.630467\n",
      "[Epoch 2/5] [Batch 271/587] [D loss: 1.179943, acc:  47%] [G loss: 21.447937] time: 0:43:40.147068\n",
      "[Epoch 2/5] [Batch 272/587] [D loss: 0.383680, acc:  56%] [G loss: 20.143141] time: 0:43:49.676716\n",
      "[Epoch 2/5] [Batch 273/587] [D loss: 0.213833, acc:  70%] [G loss: 21.678638] time: 0:43:59.216068\n",
      "[Epoch 2/5] [Batch 274/587] [D loss: 0.193493, acc:  73%] [G loss: 20.799337] time: 0:44:08.816906\n",
      "[Epoch 2/5] [Batch 275/587] [D loss: 0.289952, acc:  66%] [G loss: 23.296621] time: 0:44:18.222083\n",
      "[Epoch 2/5] [Batch 276/587] [D loss: 0.313769, acc:  60%] [G loss: 19.251463] time: 0:44:27.715355\n",
      "[Epoch 2/5] [Batch 277/587] [D loss: 0.291653, acc:  70%] [G loss: 23.908003] time: 0:44:37.365007\n",
      "[Epoch 2/5] [Batch 278/587] [D loss: 0.203841, acc:  73%] [G loss: 15.868423] time: 0:44:46.867056\n",
      "[Epoch 2/5] [Batch 279/587] [D loss: 0.315551, acc:  68%] [G loss: 23.691788] time: 0:44:56.411483\n",
      "[Epoch 2/5] [Batch 280/587] [D loss: 0.190760, acc:  82%] [G loss: 22.470888] time: 0:45:05.918798\n",
      "[Epoch 2/5] [Batch 281/587] [D loss: 0.144674, acc:  82%] [G loss: 19.566961] time: 0:45:16.686503\n",
      "[Epoch 2/5] [Batch 282/587] [D loss: 0.123563, acc:  85%] [G loss: 15.046567] time: 0:45:26.169931\n",
      "[Epoch 3/5] [Batch 283/587] [D loss: 0.140716, acc:  82%] [G loss: 14.378363] time: 0:45:41.499585\n",
      "[Epoch 3/5] [Batch 284/587] [D loss: 0.382864, acc:  74%] [G loss: 17.375181] time: 0:45:50.903050\n",
      "[Epoch 3/5] [Batch 285/587] [D loss: 0.206302, acc:  73%] [G loss: 20.574236] time: 0:46:00.389868\n",
      "[Epoch 3/5] [Batch 286/587] [D loss: 0.192167, acc:  78%] [G loss: 18.478275] time: 0:46:09.925795\n",
      "[Epoch 3/5] [Batch 287/587] [D loss: 0.086519, acc:  92%] [G loss: 20.708031] time: 0:46:19.431111\n",
      "[Epoch 3/5] [Batch 288/587] [D loss: 0.159097, acc:  78%] [G loss: 14.636145] time: 0:46:29.080179\n",
      "[Epoch 3/5] [Batch 289/587] [D loss: 0.363744, acc:  74%] [G loss: 19.195356] time: 0:46:38.582633\n",
      "[Epoch 3/5] [Batch 290/587] [D loss: 0.253423, acc:  73%] [G loss: 15.236371] time: 0:46:48.109284\n",
      "[Epoch 3/5] [Batch 291/587] [D loss: 0.255688, acc:  69%] [G loss: 20.980696] time: 0:46:57.633361\n",
      "[Epoch 3/5] [Batch 292/587] [D loss: 0.242386, acc:  71%] [G loss: 20.457373] time: 0:47:07.132241\n",
      "[Epoch 3/5] [Batch 293/587] [D loss: 0.141103, acc:  81%] [G loss: 21.031240] time: 0:47:16.898581\n",
      "[Epoch 3/5] [Batch 294/587] [D loss: 0.280279, acc:  50%] [G loss: 22.964193] time: 0:47:26.486743\n",
      "[Epoch 3/5] [Batch 295/587] [D loss: 0.208197, acc:  71%] [G loss: 20.013168] time: 0:47:36.051146\n",
      "[Epoch 3/5] [Batch 296/587] [D loss: 0.316389, acc:  55%] [G loss: 15.237479] time: 0:47:45.515102\n",
      "[Epoch 3/5] [Batch 297/587] [D loss: 0.281439, acc:  59%] [G loss: 16.941759] time: 0:47:55.031182\n",
      "[Epoch 3/5] [Batch 298/587] [D loss: 0.576743, acc:  61%] [G loss: 20.487898] time: 0:48:04.608265\n",
      "[Epoch 3/5] [Batch 299/587] [D loss: 0.276681, acc:  63%] [G loss: 20.744457] time: 0:48:14.155642\n",
      "[Epoch 3/5] [Batch 300/587] [D loss: 0.245376, acc:  61%] [G loss: 18.991314] time: 0:48:23.751854\n",
      "[Epoch 3/5] [Batch 301/587] [D loss: 0.305304, acc:  57%] [G loss: 21.960026] time: 0:48:33.290973\n",
      "[Epoch 3/5] [Batch 302/587] [D loss: 0.338397, acc:  66%] [G loss: 21.323696] time: 0:48:42.794064\n",
      "[Epoch 3/5] [Batch 303/587] [D loss: 0.228977, acc:  68%] [G loss: 19.005901] time: 0:48:52.379801\n",
      "[Epoch 3/5] [Batch 304/587] [D loss: 0.173670, acc:  75%] [G loss: 18.861441] time: 0:49:01.829767\n",
      "[Epoch 3/5] [Batch 305/587] [D loss: 0.329471, acc:  66%] [G loss: 19.600132] time: 0:49:11.354887\n",
      "[Epoch 3/5] [Batch 306/587] [D loss: 0.505877, acc:  56%] [G loss: 19.464472] time: 0:49:20.890418\n",
      "[Epoch 3/5] [Batch 307/587] [D loss: 0.126301, acc:  85%] [G loss: 17.721100] time: 0:49:30.483461\n",
      "[Epoch 3/5] [Batch 308/587] [D loss: 0.248313, acc:  70%] [G loss: 18.320675] time: 0:49:40.063049\n",
      "[Epoch 3/5] [Batch 309/587] [D loss: 0.591743, acc:  36%] [G loss: 15.594640] time: 0:49:50.909323\n",
      "[Epoch 3/5] [Batch 310/587] [D loss: 0.147050, acc:  84%] [G loss: 20.914333] time: 0:50:00.393960\n",
      "[Epoch 3/5] [Batch 311/587] [D loss: 0.148145, acc:  80%] [G loss: 21.569513] time: 0:50:09.999477\n",
      "[Epoch 3/5] [Batch 312/587] [D loss: 0.136742, acc:  82%] [G loss: 22.564817] time: 0:50:19.504336\n",
      "[Epoch 3/5] [Batch 313/587] [D loss: 0.216809, acc:  80%] [G loss: 17.456636] time: 0:50:29.002628\n",
      "[Epoch 3/5] [Batch 314/587] [D loss: 0.178269, acc:  78%] [G loss: 22.969814] time: 0:50:38.464430\n",
      "[Epoch 3/5] [Batch 315/587] [D loss: 0.166534, acc:  78%] [G loss: 17.202703] time: 0:50:48.031140\n",
      "[Epoch 3/5] [Batch 316/587] [D loss: 0.210261, acc:  71%] [G loss: 22.814791] time: 0:50:57.475258\n",
      "[Epoch 3/5] [Batch 317/587] [D loss: 0.335200, acc:  61%] [G loss: 19.890606] time: 0:51:06.956245\n",
      "[Epoch 3/5] [Batch 318/587] [D loss: 0.305919, acc:  65%] [G loss: 19.741837] time: 0:51:16.527931\n",
      "[Epoch 3/5] [Batch 319/587] [D loss: 0.075237, acc:  96%] [G loss: 25.530941] time: 0:51:25.949448\n",
      "[Epoch 3/5] [Batch 320/587] [D loss: 0.184257, acc:  74%] [G loss: 20.182068] time: 0:51:35.388806\n",
      "[Epoch 3/5] [Batch 321/587] [D loss: 0.447544, acc:  53%] [G loss: 24.945929] time: 0:51:44.940138\n",
      "[Epoch 3/5] [Batch 322/587] [D loss: 0.368925, acc:  75%] [G loss: 19.489695] time: 0:51:54.519492\n",
      "[Epoch 3/5] [Batch 323/587] [D loss: 0.241719, acc:  71%] [G loss: 23.638657] time: 0:52:04.035952\n",
      "[Epoch 3/5] [Batch 324/587] [D loss: 0.211965, acc:  71%] [G loss: 17.805286] time: 0:52:13.562455\n",
      "[Epoch 3/5] [Batch 325/587] [D loss: 0.305664, acc:  51%] [G loss: 19.862274] time: 0:52:23.035069\n",
      "[Epoch 3/5] [Batch 326/587] [D loss: 0.371338, acc:  43%] [G loss: 17.799541] time: 0:52:32.564205\n",
      "[Epoch 3/5] [Batch 327/587] [D loss: 0.101213, acc:  90%] [G loss: 21.933731] time: 0:52:42.068165\n",
      "[Epoch 3/5] [Batch 328/587] [D loss: 0.194925, acc:  71%] [G loss: 19.239872] time: 0:52:51.609847\n",
      "[Epoch 3/5] [Batch 329/587] [D loss: 0.153176, acc:  80%] [G loss: 21.749922] time: 0:53:01.073771\n",
      "[Epoch 3/5] [Batch 330/587] [D loss: 0.279784, acc:  67%] [G loss: 22.729433] time: 0:53:10.668079\n",
      "[Epoch 3/5] [Batch 331/587] [D loss: 0.464206, acc:  71%] [G loss: 21.508211] time: 0:53:20.214910\n",
      "[Epoch 3/5] [Batch 332/587] [D loss: 0.296528, acc:  79%] [G loss: 20.305275] time: 0:53:29.779725\n",
      "[Epoch 3/5] [Batch 333/587] [D loss: 0.138519, acc:  82%] [G loss: 18.660728] time: 0:53:39.312455\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 3/5] [Batch 334/587] [D loss: 0.275691, acc:  66%] [G loss: 16.111231] time: 0:53:48.758414\n",
      "[Epoch 3/5] [Batch 335/587] [D loss: 0.160101, acc:  79%] [G loss: 17.828913] time: 0:53:58.287968\n",
      "[Epoch 3/5] [Batch 336/587] [D loss: 0.139424, acc:  83%] [G loss: 20.306969] time: 0:54:07.778211\n",
      "[Epoch 3/5] [Batch 337/587] [D loss: 0.074677, acc:  93%] [G loss: 26.493240] time: 0:54:18.411936\n",
      "[Epoch 3/5] [Batch 338/587] [D loss: 0.101166, acc:  89%] [G loss: 20.161287] time: 0:54:27.997944\n",
      "[Epoch 3/5] [Batch 339/587] [D loss: 0.132253, acc:  86%] [G loss: 27.020330] time: 0:54:37.507655\n",
      "[Epoch 3/5] [Batch 340/587] [D loss: 0.176695, acc:  81%] [G loss: 22.193110] time: 0:54:47.018741\n",
      "[Epoch 3/5] [Batch 341/587] [D loss: 0.143283, acc:  82%] [G loss: 19.823267] time: 0:54:56.526118\n",
      "[Epoch 3/5] [Batch 342/587] [D loss: 0.169647, acc:  76%] [G loss: 18.150206] time: 0:55:06.019976\n",
      "[Epoch 3/5] [Batch 343/587] [D loss: 0.152187, acc:  85%] [G loss: 20.876219] time: 0:55:15.584362\n",
      "[Epoch 3/5] [Batch 344/587] [D loss: 0.152786, acc:  80%] [G loss: 21.081228] time: 0:55:25.235538\n",
      "[Epoch 3/5] [Batch 345/587] [D loss: 0.323763, acc:  76%] [G loss: 19.928814] time: 0:55:34.748002\n",
      "[Epoch 3/5] [Batch 346/587] [D loss: 0.203081, acc:  87%] [G loss: 24.202696] time: 0:55:44.309266\n",
      "[Epoch 3/5] [Batch 347/587] [D loss: 0.150589, acc:  81%] [G loss: 18.842937] time: 0:55:53.884119\n",
      "[Epoch 3/5] [Batch 348/587] [D loss: 0.177622, acc:  85%] [G loss: 24.934977] time: 0:56:03.400310\n",
      "[Epoch 3/5] [Batch 349/587] [D loss: 0.149558, acc:  81%] [G loss: 22.210304] time: 0:56:12.857047\n",
      "[Epoch 3/5] [Batch 350/587] [D loss: 0.144287, acc:  80%] [G loss: 19.311171] time: 0:56:22.259126\n",
      "[Epoch 3/5] [Batch 351/587] [D loss: 0.077538, acc:  93%] [G loss: 20.037874] time: 0:56:31.709087\n",
      "[Epoch 3/5] [Batch 352/587] [D loss: 0.198936, acc:  70%] [G loss: 17.919855] time: 0:56:41.229000\n",
      "[Epoch 3/5] [Batch 353/587] [D loss: 0.189368, acc:  82%] [G loss: 14.133161] time: 0:56:50.757220\n",
      "[Epoch 3/5] [Batch 354/587] [D loss: 0.197807, acc:  77%] [G loss: 21.064098] time: 0:57:00.339302\n",
      "[Epoch 3/5] [Batch 355/587] [D loss: 0.079185, acc:  95%] [G loss: 15.267267] time: 0:57:09.804208\n",
      "[Epoch 3/5] [Batch 356/587] [D loss: 0.099543, acc:  88%] [G loss: 22.081451] time: 0:57:19.252792\n",
      "[Epoch 3/5] [Batch 357/587] [D loss: 0.133442, acc:  82%] [G loss: 21.207769] time: 0:57:28.745725\n",
      "[Epoch 3/5] [Batch 358/587] [D loss: 0.224284, acc:  77%] [G loss: 22.945017] time: 0:57:38.285866\n",
      "[Epoch 3/5] [Batch 359/587] [D loss: 0.200305, acc:  74%] [G loss: 23.958694] time: 0:57:47.743495\n",
      "[Epoch 3/5] [Batch 360/587] [D loss: 0.070581, acc:  95%] [G loss: 22.490005] time: 0:57:57.245081\n",
      "[Epoch 3/5] [Batch 361/587] [D loss: 0.212285, acc:  69%] [G loss: 19.313496] time: 0:58:06.794042\n",
      "[Epoch 3/5] [Batch 362/587] [D loss: 0.138387, acc:  83%] [G loss: 23.050350] time: 0:58:16.305278\n",
      "[Epoch 3/5] [Batch 363/587] [D loss: 0.291700, acc:  61%] [G loss: 16.393476] time: 0:58:25.751369\n",
      "[Epoch 3/5] [Batch 364/587] [D loss: 0.102208, acc:  89%] [G loss: 20.635271] time: 0:58:35.233092\n",
      "[Epoch 3/5] [Batch 365/587] [D loss: 0.135414, acc:  88%] [G loss: 21.894829] time: 0:58:45.958804\n",
      "[Epoch 3/5] [Batch 366/587] [D loss: 0.100255, acc:  89%] [G loss: 23.890093] time: 0:58:55.514336\n",
      "[Epoch 3/5] [Batch 367/587] [D loss: 0.177556, acc:  76%] [G loss: 16.878613] time: 0:59:05.066660\n",
      "[Epoch 3/5] [Batch 368/587] [D loss: 0.098507, acc:  89%] [G loss: 20.993801] time: 0:59:14.607742\n",
      "[Epoch 3/5] [Batch 369/587] [D loss: 0.115713, acc:  85%] [G loss: 23.389523] time: 0:59:24.180913\n",
      "[Epoch 3/5] [Batch 370/587] [D loss: 0.181792, acc:  80%] [G loss: 18.808025] time: 0:59:33.700188\n",
      "[Epoch 3/5] [Batch 371/587] [D loss: 0.114979, acc:  88%] [G loss: 24.348402] time: 0:59:43.112485\n",
      "[Epoch 3/5] [Batch 372/587] [D loss: 0.642224, acc:  72%] [G loss: 29.246101] time: 0:59:52.606006\n",
      "[Epoch 3/5] [Batch 373/587] [D loss: 0.688481, acc:  71%] [G loss: 22.004177] time: 1:00:02.114098\n",
      "[Epoch 3/5] [Batch 374/587] [D loss: 0.387699, acc:  72%] [G loss: 21.304420] time: 1:00:11.663445\n",
      "[Epoch 3/5] [Batch 375/587] [D loss: 0.236573, acc:  77%] [G loss: 25.040545] time: 1:00:21.220648\n",
      "[Epoch 3/5] [Batch 376/587] [D loss: 0.128164, acc:  86%] [G loss: 16.497103] time: 1:00:30.660379\n",
      "[Epoch 4/5] [Batch 377/587] [D loss: 0.104103, acc:  90%] [G loss: 24.782310] time: 1:00:45.904975\n",
      "[Epoch 4/5] [Batch 378/587] [D loss: 0.096017, acc:  93%] [G loss: 18.446598] time: 1:00:55.311525\n",
      "[Epoch 4/5] [Batch 379/587] [D loss: 0.224991, acc:  72%] [G loss: 20.056835] time: 1:01:04.869375\n",
      "[Epoch 4/5] [Batch 380/587] [D loss: 0.234990, acc:  72%] [G loss: 21.913357] time: 1:01:14.471586\n",
      "[Epoch 4/5] [Batch 381/587] [D loss: 0.551880, acc:  76%] [G loss: 22.261652] time: 1:01:24.038562\n",
      "[Epoch 4/5] [Batch 382/587] [D loss: 0.129029, acc:  88%] [G loss: 26.719063] time: 1:01:33.544186\n",
      "[Epoch 4/5] [Batch 383/587] [D loss: 0.140122, acc:  83%] [G loss: 27.867708] time: 1:01:42.987582\n",
      "[Epoch 4/5] [Batch 384/587] [D loss: 0.267190, acc:  83%] [G loss: 19.826653] time: 1:01:52.514569\n",
      "[Epoch 4/5] [Batch 385/587] [D loss: 0.217464, acc:  67%] [G loss: 21.623665] time: 1:02:02.170934\n",
      "[Epoch 4/5] [Batch 386/587] [D loss: 0.217698, acc:  77%] [G loss: 21.396605] time: 1:02:11.844395\n",
      "[Epoch 4/5] [Batch 387/587] [D loss: 0.157693, acc:  81%] [G loss: 15.553333] time: 1:02:21.347910\n",
      "[Epoch 4/5] [Batch 388/587] [D loss: 0.084071, acc:  92%] [G loss: 23.412344] time: 1:02:30.888447\n",
      "[Epoch 4/5] [Batch 389/587] [D loss: 0.078707, acc:  94%] [G loss: 18.003872] time: 1:02:40.505254\n",
      "[Epoch 4/5] [Batch 390/587] [D loss: 0.044966, acc:  98%] [G loss: 20.883051] time: 1:02:50.101463\n",
      "[Epoch 4/5] [Batch 391/587] [D loss: 0.044570, acc:  98%] [G loss: 22.189796] time: 1:02:59.666805\n",
      "[Epoch 4/5] [Batch 392/587] [D loss: 0.229543, acc:  74%] [G loss: 17.991167] time: 1:03:09.211306\n",
      "[Epoch 4/5] [Batch 393/587] [D loss: 0.098180, acc:  95%] [G loss: 24.870842] time: 1:03:19.934941\n",
      "[Epoch 4/5] [Batch 394/587] [D loss: 0.307381, acc:  76%] [G loss: 18.101635] time: 1:03:29.496653\n",
      "[Epoch 4/5] [Batch 395/587] [D loss: 0.229393, acc:  64%] [G loss: 13.541175] time: 1:03:38.957979\n",
      "[Epoch 4/5] [Batch 396/587] [D loss: 0.127629, acc:  91%] [G loss: 20.804813] time: 1:03:48.536195\n",
      "[Epoch 4/5] [Batch 397/587] [D loss: 0.246213, acc:  75%] [G loss: 22.937248] time: 1:03:58.008069\n",
      "[Epoch 4/5] [Batch 398/587] [D loss: 0.153107, acc:  83%] [G loss: 17.929665] time: 1:04:07.636930\n",
      "[Epoch 4/5] [Batch 399/587] [D loss: 0.205082, acc:  65%] [G loss: 19.736849] time: 1:04:17.215516\n",
      "[Epoch 4/5] [Batch 400/587] [D loss: 0.215383, acc:  76%] [G loss: 14.983305] time: 1:04:26.821480\n",
      "[Epoch 4/5] [Batch 401/587] [D loss: 0.138920, acc:  86%] [G loss: 23.051142] time: 1:04:36.357915\n",
      "[Epoch 4/5] [Batch 402/587] [D loss: 0.217758, acc:  82%] [G loss: 22.675909] time: 1:04:45.814497\n",
      "[Epoch 4/5] [Batch 403/587] [D loss: 0.162505, acc:  82%] [G loss: 21.014025] time: 1:04:55.348709\n",
      "[Epoch 4/5] [Batch 404/587] [D loss: 0.075697, acc:  94%] [G loss: 20.314861] time: 1:05:04.810817\n",
      "[Epoch 4/5] [Batch 405/587] [D loss: 0.121333, acc:  89%] [G loss: 15.432208] time: 1:05:14.465441\n",
      "[Epoch 4/5] [Batch 406/587] [D loss: 0.537856, acc:  69%] [G loss: 19.303453] time: 1:05:24.097902\n",
      "[Epoch 4/5] [Batch 407/587] [D loss: 0.242003, acc:  75%] [G loss: 21.414154] time: 1:05:33.582742\n",
      "[Epoch 4/5] [Batch 408/587] [D loss: 0.179863, acc:  80%] [G loss: 22.409731] time: 1:05:43.118486\n",
      "[Epoch 4/5] [Batch 409/587] [D loss: 0.129068, acc:  84%] [G loss: 18.669847] time: 1:05:52.707363\n",
      "[Epoch 4/5] [Batch 410/587] [D loss: 0.145342, acc:  83%] [G loss: 23.673744] time: 1:06:02.303263\n",
      "[Epoch 4/5] [Batch 411/587] [D loss: 0.176782, acc:  85%] [G loss: 14.855738] time: 1:06:11.871059\n",
      "[Epoch 4/5] [Batch 412/587] [D loss: 0.116220, acc:  86%] [G loss: 17.778967] time: 1:06:21.395769\n",
      "[Epoch 4/5] [Batch 413/587] [D loss: 0.073859, acc:  95%] [G loss: 22.501350] time: 1:06:30.916983\n",
      "[Epoch 4/5] [Batch 414/587] [D loss: 0.099542, acc:  94%] [G loss: 23.514696] time: 1:06:40.670568\n",
      "[Epoch 4/5] [Batch 415/587] [D loss: 0.978638, acc:  75%] [G loss: 20.513723] time: 1:06:51.004205\n",
      "[Epoch 4/5] [Batch 416/587] [D loss: 0.595713, acc:  60%] [G loss: 19.619066] time: 1:07:00.990429\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 4/5] [Batch 417/587] [D loss: 0.310657, acc:  80%] [G loss: 19.999920] time: 1:07:11.016972\n",
      "[Epoch 4/5] [Batch 418/587] [D loss: 0.101507, acc:  88%] [G loss: 22.871288] time: 1:07:20.677418\n",
      "[Epoch 4/5] [Batch 419/587] [D loss: 0.284632, acc:  77%] [G loss: 19.582331] time: 1:07:30.407641\n",
      "[Epoch 4/5] [Batch 420/587] [D loss: 0.250109, acc:  78%] [G loss: 20.742018] time: 1:07:40.286689\n",
      "[Epoch 4/5] [Batch 421/587] [D loss: 0.395775, acc:  64%] [G loss: 17.028381] time: 1:07:51.903188\n",
      "[Epoch 4/5] [Batch 422/587] [D loss: 0.130211, acc:  90%] [G loss: 18.556999] time: 1:08:01.822078\n",
      "[Epoch 4/5] [Batch 423/587] [D loss: 0.075691, acc:  99%] [G loss: 25.526320] time: 1:08:11.763027\n",
      "[Epoch 4/5] [Batch 424/587] [D loss: 0.158308, acc:  79%] [G loss: 18.283648] time: 1:08:21.397783\n",
      "[Epoch 4/5] [Batch 425/587] [D loss: 0.061168, acc:  99%] [G loss: 20.520462] time: 1:08:30.881020\n",
      "[Epoch 4/5] [Batch 426/587] [D loss: 0.101610, acc:  92%] [G loss: 19.863832] time: 1:08:40.311353\n",
      "[Epoch 4/5] [Batch 427/587] [D loss: 0.187037, acc:  79%] [G loss: 23.390278] time: 1:08:49.669982\n",
      "[Epoch 4/5] [Batch 428/587] [D loss: 0.183519, acc:  77%] [G loss: 22.663950] time: 1:08:59.092518\n",
      "[Epoch 4/5] [Batch 429/587] [D loss: 0.085492, acc:  91%] [G loss: 22.039942] time: 1:09:08.690356\n",
      "[Epoch 4/5] [Batch 430/587] [D loss: 0.170988, acc:  72%] [G loss: 18.594036] time: 1:09:18.326646\n",
      "[Epoch 4/5] [Batch 431/587] [D loss: 0.172433, acc:  80%] [G loss: 23.774210] time: 1:09:27.929484\n",
      "[Epoch 4/5] [Batch 432/587] [D loss: 0.162045, acc:  86%] [G loss: 21.560448] time: 1:09:37.444943\n",
      "[Epoch 4/5] [Batch 433/587] [D loss: 0.165997, acc:  85%] [G loss: 18.718416] time: 1:09:46.938944\n",
      "[Epoch 4/5] [Batch 434/587] [D loss: 0.545814, acc:  69%] [G loss: 28.205450] time: 1:09:56.587212\n",
      "[Epoch 4/5] [Batch 435/587] [D loss: 0.320182, acc:  66%] [G loss: 21.811655] time: 1:10:06.197050\n",
      "[Epoch 4/5] [Batch 436/587] [D loss: 0.252514, acc:  59%] [G loss: 21.908331] time: 1:10:15.707319\n",
      "[Epoch 4/5] [Batch 437/587] [D loss: 0.147027, acc:  86%] [G loss: 18.097265] time: 1:10:25.133278\n",
      "[Epoch 4/5] [Batch 438/587] [D loss: 0.148633, acc:  83%] [G loss: 20.097303] time: 1:10:34.571865\n",
      "[Epoch 4/5] [Batch 439/587] [D loss: 0.142895, acc:  92%] [G loss: 14.449089] time: 1:10:44.117873\n",
      "[Epoch 4/5] [Batch 440/587] [D loss: 0.338624, acc:  72%] [G loss: 15.798780] time: 1:10:53.698482\n",
      "[Epoch 4/5] [Batch 441/587] [D loss: 0.153857, acc:  87%] [G loss: 17.346701] time: 1:11:03.168694\n",
      "[Epoch 4/5] [Batch 442/587] [D loss: 0.239335, acc:  81%] [G loss: 18.046780] time: 1:11:12.637829\n",
      "[Epoch 4/5] [Batch 443/587] [D loss: 0.100122, acc:  87%] [G loss: 15.517130] time: 1:11:22.175437\n",
      "[Epoch 4/5] [Batch 444/587] [D loss: 0.053475, acc:  98%] [G loss: 15.665503] time: 1:11:31.623266\n",
      "[Epoch 4/5] [Batch 445/587] [D loss: 0.337063, acc:  74%] [G loss: 22.136328] time: 1:11:41.106112\n",
      "[Epoch 4/5] [Batch 446/587] [D loss: 0.237885, acc:  80%] [G loss: 19.625546] time: 1:11:50.686588\n",
      "[Epoch 4/5] [Batch 447/587] [D loss: 0.246273, acc:  82%] [G loss: 19.041935] time: 1:12:00.167019\n",
      "[Epoch 4/5] [Batch 448/587] [D loss: 0.110411, acc:  92%] [G loss: 17.116247] time: 1:12:09.809256\n",
      "[Epoch 4/5] [Batch 449/587] [D loss: 0.094986, acc:  90%] [G loss: 21.847956] time: 1:12:20.668149\n",
      "[Epoch 4/5] [Batch 450/587] [D loss: 0.197344, acc:  82%] [G loss: 20.571127] time: 1:12:30.216483\n",
      "[Epoch 4/5] [Batch 451/587] [D loss: 0.058638, acc:  96%] [G loss: 19.474058] time: 1:12:39.793519\n",
      "[Epoch 4/5] [Batch 452/587] [D loss: 0.039208, acc:  98%] [G loss: 20.265045] time: 1:12:49.303600\n",
      "[Epoch 4/5] [Batch 453/587] [D loss: 0.037921, acc:  98%] [G loss: 21.729599] time: 1:12:58.846065\n",
      "[Epoch 4/5] [Batch 454/587] [D loss: 0.065845, acc:  95%] [G loss: 16.218212] time: 1:13:08.497727\n",
      "[Epoch 4/5] [Batch 455/587] [D loss: 0.063513, acc:  97%] [G loss: 14.457624] time: 1:13:18.058810\n",
      "[Epoch 4/5] [Batch 456/587] [D loss: 0.173604, acc:  77%] [G loss: 21.487860] time: 1:13:27.590864\n",
      "[Epoch 4/5] [Batch 457/587] [D loss: 0.144411, acc:  87%] [G loss: 20.743523] time: 1:13:37.109648\n",
      "[Epoch 4/5] [Batch 458/587] [D loss: 0.259506, acc:  57%] [G loss: 18.320881] time: 1:13:46.785722\n",
      "[Epoch 4/5] [Batch 459/587] [D loss: 0.072197, acc:  95%] [G loss: 21.332726] time: 1:13:56.293773\n",
      "[Epoch 4/5] [Batch 460/587] [D loss: 0.088726, acc:  91%] [G loss: 24.295448] time: 1:14:05.850388\n",
      "[Epoch 4/5] [Batch 461/587] [D loss: 0.090658, acc:  91%] [G loss: 19.270088] time: 1:14:15.357581\n",
      "[Epoch 4/5] [Batch 462/587] [D loss: 0.049087, acc:  98%] [G loss: 20.022949] time: 1:14:24.909955\n",
      "[Epoch 4/5] [Batch 463/587] [D loss: 0.098966, acc:  92%] [G loss: 20.131701] time: 1:14:34.462396\n",
      "[Epoch 4/5] [Batch 464/587] [D loss: 0.166348, acc:  86%] [G loss: 16.456553] time: 1:14:43.889291\n",
      "[Epoch 4/5] [Batch 465/587] [D loss: 0.103761, acc:  92%] [G loss: 21.342979] time: 1:14:53.443170\n",
      "[Epoch 4/5] [Batch 466/587] [D loss: 0.122775, acc:  88%] [G loss: 21.955715] time: 1:15:03.015443\n",
      "[Epoch 4/5] [Batch 467/587] [D loss: 0.079613, acc:  96%] [G loss: 18.963123] time: 1:15:12.563426\n",
      "[Epoch 4/5] [Batch 468/587] [D loss: 0.147259, acc:  81%] [G loss: 18.031580] time: 1:15:22.133760\n",
      "[Epoch 4/5] [Batch 469/587] [D loss: 0.071978, acc:  97%] [G loss: 25.770531] time: 1:15:31.677906\n",
      "[Epoch 4/5] [Batch 470/587] [D loss: 0.068142, acc:  93%] [G loss: 21.689190] time: 1:15:41.143112\n",
      "Model saved\n"
     ]
    }
   ],
   "source": [
    "model = Pix2Pix()\n",
    "#model.generator.summary()\n",
    "model.train(train, test, epochs=5, batch_size=batch_size, total_batch=587)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "Cannot batch tensors with different shapes in component 0. First element had shape [5,256,256,3] and element 3 had shape [2,256,256,3]. [Op:IteratorGetNextSync]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-93afed4fd98c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mm\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0md\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m256\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m256\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mnum\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mimg_b\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m     \u001b[1;31m#img_B = scipy.misc.imread(img, mode='RGB').astype(np.float)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;31m#m,n,d = img_B.shape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    554\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    555\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# For Python 3 compatibility\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 556\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    557\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    558\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_next_internal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py\u001b[0m in \u001b[0;36mnext\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    583\u001b[0m     \"\"\"\n\u001b[0;32m    584\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 585\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_internal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    586\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    587\u001b[0m       \u001b[1;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py\u001b[0m in \u001b[0;36m_next_internal\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    575\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_resource\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    576\u001b[0m             \u001b[0moutput_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_flat_output_types\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 577\u001b[1;33m             output_shapes=self._flat_output_shapes)\n\u001b[0m\u001b[0;32m    578\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    579\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_structure\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_from_compatible_tensor_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\ops\\gen_dataset_ops.py\u001b[0m in \u001b[0;36miterator_get_next_sync\u001b[1;34m(iterator, output_types, output_shapes, name)\u001b[0m\n\u001b[0;32m   1981\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1982\u001b[0m         \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1983\u001b[1;33m       \u001b[0m_six\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1984\u001b[0m   \u001b[1;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1985\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_types\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tf2\\lib\\site-packages\\six.py\u001b[0m in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Cannot batch tensors with different shapes in component 0. First element had shape [5,256,256,3] and element 3 had shape [2,256,256,3]. [Op:IteratorGetNextSync]"
     ]
    }
   ],
   "source": [
    "## use the trained model to generate data\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "test_model = model.generator\n",
    "test_model.load_weights(\"C:\\\\gen_model.h5\")\n",
    "m,n,d = 256,256,3\n",
    "num = 1\n",
    "for _,img_b in test:\n",
    "\n",
    "    img_show = np.zeros((m,2*n,d))\n",
    "\n",
    "    fake_A = 0.5* (test_model.predict(img_b))[0]+0.5\n",
    "    img_bb = np.array(img_b).reshape(256,256,3)\n",
    "    img_show[:,:n,:] = img_bb\n",
    "    img_show[:,n:2*n,:] = fake_A\n",
    "    plt.imsave(\"C:\\\\images\\\\pathology\\\\test_fake_%d.png\" % num,fake_A)\n",
    "    plt.imsave(\"C:\\\\images\\\\pathology\\\\test_%d.png\" % num,img_bb)\n",
    "    plt.imsave(\"C:\\\\images\\\\pathology\\\\test_both_%d.png\" % num,img_show)\n",
    "    num = num + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "Cannot batch tensors with different shapes in component 0. First element had shape [5,256,256,3] and element 3 had shape [2,256,256,3]. [Op:IteratorGetNextSync]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-e9f846f5c91d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mimg_a\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mimg_b\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_b\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    554\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    555\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# For Python 3 compatibility\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 556\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    557\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    558\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_next_internal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py\u001b[0m in \u001b[0;36mnext\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    583\u001b[0m     \"\"\"\n\u001b[0;32m    584\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 585\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_internal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    586\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    587\u001b[0m       \u001b[1;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py\u001b[0m in \u001b[0;36m_next_internal\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    575\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_resource\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    576\u001b[0m             \u001b[0moutput_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_flat_output_types\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 577\u001b[1;33m             output_shapes=self._flat_output_shapes)\n\u001b[0m\u001b[0;32m    578\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    579\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_structure\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_from_compatible_tensor_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\ops\\gen_dataset_ops.py\u001b[0m in \u001b[0;36miterator_get_next_sync\u001b[1;34m(iterator, output_types, output_shapes, name)\u001b[0m\n\u001b[0;32m   1981\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1982\u001b[0m         \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1983\u001b[1;33m       \u001b[0m_six\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1984\u001b[0m   \u001b[1;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1985\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_types\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tf2\\lib\\site-packages\\six.py\u001b[0m in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Cannot batch tensors with different shapes in component 0. First element had shape [5,256,256,3] and element 3 had shape [2,256,256,3]. [Op:IteratorGetNextSync]"
     ]
    }
   ],
   "source": [
    "for img_a,img_b in test:\n",
    "    print(img_b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
