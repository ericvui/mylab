{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 299, 299, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 149, 149, 32) 864         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1 (BatchNo (None, 149, 149, 32) 96          conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 149, 149, 32) 0           batch_normalization_v1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 147, 147, 32) 9216        activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_1 (Batch (None, 147, 147, 32) 96          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 147, 147, 32) 0           batch_normalization_v1_1[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 147, 147, 64) 18432       activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_2 (Batch (None, 147, 147, 64) 192         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 147, 147, 64) 0           batch_normalization_v1_2[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 73, 73, 64)   0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 73, 73, 80)   5120        max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_3 (Batch (None, 73, 73, 80)   240         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 73, 73, 80)   0           batch_normalization_v1_3[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 71, 71, 192)  138240      activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_4 (Batch (None, 71, 71, 192)  576         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 71, 71, 192)  0           batch_normalization_v1_4[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 35, 35, 192)  0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 35, 35, 64)   12288       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_8 (Batch (None, 35, 35, 64)   192         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 35, 35, 64)   0           batch_normalization_v1_8[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 35, 35, 48)   9216        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 35, 35, 96)   55296       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_6 (Batch (None, 35, 35, 48)   144         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_9 (Batch (None, 35, 35, 96)   288         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 35, 35, 48)   0           batch_normalization_v1_6[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 35, 35, 96)   0           batch_normalization_v1_9[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d (AveragePooli (None, 35, 35, 192)  0           max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 35, 35, 96)   18432       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 35, 35, 64)   76800       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 35, 35, 96)   82944       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 35, 35, 64)   12288       average_pooling2d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_5 (Batch (None, 35, 35, 96)   288         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_7 (Batch (None, 35, 35, 64)   192         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_10 (Batc (None, 35, 35, 96)   288         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_11 (Batc (None, 35, 35, 64)   192         conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 35, 35, 96)   0           batch_normalization_v1_5[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 35, 35, 64)   0           batch_normalization_v1_7[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 35, 35, 96)   0           batch_normalization_v1_10[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 35, 35, 64)   0           batch_normalization_v1_11[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "mixed_5b (Concatenate)          (None, 35, 35, 320)  0           activation_5[0][0]               \n",
      "                                                                 activation_7[0][0]               \n",
      "                                                                 activation_10[0][0]              \n",
      "                                                                 activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 35, 35, 32)   10240       mixed_5b[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_15 (Batc (None, 35, 35, 32)   96          conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 35, 35, 32)   0           batch_normalization_v1_15[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 35, 35, 32)   10240       mixed_5b[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 35, 35, 48)   13824       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_13 (Batc (None, 35, 35, 32)   96          conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_16 (Batc (None, 35, 35, 48)   144         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 35, 35, 32)   0           batch_normalization_v1_13[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 35, 35, 48)   0           batch_normalization_v1_16[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 35, 35, 32)   10240       mixed_5b[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 35, 35, 32)   9216        activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 35, 35, 64)   27648       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_12 (Batc (None, 35, 35, 32)   96          conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_14 (Batc (None, 35, 35, 32)   96          conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_17 (Batc (None, 35, 35, 64)   192         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 35, 35, 32)   0           batch_normalization_v1_12[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 35, 35, 32)   0           batch_normalization_v1_14[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 35, 35, 64)   0           batch_normalization_v1_17[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block35_1_mixed (Concatenate)   (None, 35, 35, 128)  0           activation_12[0][0]              \n",
      "                                                                 activation_14[0][0]              \n",
      "                                                                 activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block35_1_conv (Conv2D)         (None, 35, 35, 320)  41280       block35_1_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_1 (Lambda)              (None, 35, 35, 320)  0           mixed_5b[0][0]                   \n",
      "                                                                 block35_1_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_1_ac (Activation)       (None, 35, 35, 320)  0           block35_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 35, 35, 32)   10240       block35_1_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_21 (Batc (None, 35, 35, 32)   96          conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 35, 35, 32)   0           batch_normalization_v1_21[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 35, 35, 32)   10240       block35_1_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 35, 35, 48)   13824       activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_19 (Batc (None, 35, 35, 32)   96          conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_22 (Batc (None, 35, 35, 48)   144         conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 35, 35, 32)   0           batch_normalization_v1_19[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 35, 35, 48)   0           batch_normalization_v1_22[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 35, 35, 32)   10240       block35_1_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 35, 35, 32)   9216        activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 35, 35, 64)   27648       activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_18 (Batc (None, 35, 35, 32)   96          conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_20 (Batc (None, 35, 35, 32)   96          conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_23 (Batc (None, 35, 35, 64)   192         conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 35, 35, 32)   0           batch_normalization_v1_18[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 35, 35, 32)   0           batch_normalization_v1_20[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 35, 35, 64)   0           batch_normalization_v1_23[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block35_2_mixed (Concatenate)   (None, 35, 35, 128)  0           activation_18[0][0]              \n",
      "                                                                 activation_20[0][0]              \n",
      "                                                                 activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block35_2_conv (Conv2D)         (None, 35, 35, 320)  41280       block35_2_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_2 (Lambda)              (None, 35, 35, 320)  0           block35_1_ac[0][0]               \n",
      "                                                                 block35_2_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_2_ac (Activation)       (None, 35, 35, 320)  0           block35_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 35, 35, 32)   10240       block35_2_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_27 (Batc (None, 35, 35, 32)   96          conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 35, 35, 32)   0           batch_normalization_v1_27[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 35, 35, 32)   10240       block35_2_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 35, 35, 48)   13824       activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_25 (Batc (None, 35, 35, 32)   96          conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_28 (Batc (None, 35, 35, 48)   144         conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 35, 35, 32)   0           batch_normalization_v1_25[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 35, 35, 48)   0           batch_normalization_v1_28[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 35, 35, 32)   10240       block35_2_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 35, 35, 32)   9216        activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 35, 35, 64)   27648       activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_24 (Batc (None, 35, 35, 32)   96          conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_26 (Batc (None, 35, 35, 32)   96          conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_29 (Batc (None, 35, 35, 64)   192         conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 35, 35, 32)   0           batch_normalization_v1_24[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 35, 35, 32)   0           batch_normalization_v1_26[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 35, 35, 64)   0           batch_normalization_v1_29[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block35_3_mixed (Concatenate)   (None, 35, 35, 128)  0           activation_24[0][0]              \n",
      "                                                                 activation_26[0][0]              \n",
      "                                                                 activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block35_3_conv (Conv2D)         (None, 35, 35, 320)  41280       block35_3_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_3 (Lambda)              (None, 35, 35, 320)  0           block35_2_ac[0][0]               \n",
      "                                                                 block35_3_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_3_ac (Activation)       (None, 35, 35, 320)  0           block35_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 35, 35, 32)   10240       block35_3_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_33 (Batc (None, 35, 35, 32)   96          conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 35, 35, 32)   0           batch_normalization_v1_33[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 35, 35, 32)   10240       block35_3_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 35, 35, 48)   13824       activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_31 (Batc (None, 35, 35, 32)   96          conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_34 (Batc (None, 35, 35, 48)   144         conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 35, 35, 32)   0           batch_normalization_v1_31[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 35, 35, 48)   0           batch_normalization_v1_34[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 35, 35, 32)   10240       block35_3_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 35, 35, 32)   9216        activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 35, 35, 64)   27648       activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_30 (Batc (None, 35, 35, 32)   96          conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_32 (Batc (None, 35, 35, 32)   96          conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_35 (Batc (None, 35, 35, 64)   192         conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 35, 35, 32)   0           batch_normalization_v1_30[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 35, 35, 32)   0           batch_normalization_v1_32[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 35, 35, 64)   0           batch_normalization_v1_35[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block35_4_mixed (Concatenate)   (None, 35, 35, 128)  0           activation_30[0][0]              \n",
      "                                                                 activation_32[0][0]              \n",
      "                                                                 activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block35_4_conv (Conv2D)         (None, 35, 35, 320)  41280       block35_4_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_4 (Lambda)              (None, 35, 35, 320)  0           block35_3_ac[0][0]               \n",
      "                                                                 block35_4_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_4_ac (Activation)       (None, 35, 35, 320)  0           block35_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 35, 35, 32)   10240       block35_4_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_39 (Batc (None, 35, 35, 32)   96          conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 35, 35, 32)   0           batch_normalization_v1_39[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 35, 35, 32)   10240       block35_4_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 35, 35, 48)   13824       activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_37 (Batc (None, 35, 35, 32)   96          conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_40 (Batc (None, 35, 35, 48)   144         conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 35, 35, 32)   0           batch_normalization_v1_37[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 35, 35, 48)   0           batch_normalization_v1_40[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 35, 35, 32)   10240       block35_4_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 35, 35, 32)   9216        activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 35, 35, 64)   27648       activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_36 (Batc (None, 35, 35, 32)   96          conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_38 (Batc (None, 35, 35, 32)   96          conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_41 (Batc (None, 35, 35, 64)   192         conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 35, 35, 32)   0           batch_normalization_v1_36[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 35, 35, 32)   0           batch_normalization_v1_38[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 35, 35, 64)   0           batch_normalization_v1_41[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block35_5_mixed (Concatenate)   (None, 35, 35, 128)  0           activation_36[0][0]              \n",
      "                                                                 activation_38[0][0]              \n",
      "                                                                 activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block35_5_conv (Conv2D)         (None, 35, 35, 320)  41280       block35_5_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_5 (Lambda)              (None, 35, 35, 320)  0           block35_4_ac[0][0]               \n",
      "                                                                 block35_5_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_5_ac (Activation)       (None, 35, 35, 320)  0           block35_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 35, 35, 32)   10240       block35_5_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_45 (Batc (None, 35, 35, 32)   96          conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 35, 35, 32)   0           batch_normalization_v1_45[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 35, 35, 32)   10240       block35_5_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 35, 35, 48)   13824       activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_43 (Batc (None, 35, 35, 32)   96          conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_46 (Batc (None, 35, 35, 48)   144         conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 35, 35, 32)   0           batch_normalization_v1_43[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 35, 35, 48)   0           batch_normalization_v1_46[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 35, 35, 32)   10240       block35_5_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 35, 35, 32)   9216        activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 35, 35, 64)   27648       activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_42 (Batc (None, 35, 35, 32)   96          conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_44 (Batc (None, 35, 35, 32)   96          conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_47 (Batc (None, 35, 35, 64)   192         conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 35, 35, 32)   0           batch_normalization_v1_42[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 35, 35, 32)   0           batch_normalization_v1_44[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 35, 35, 64)   0           batch_normalization_v1_47[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block35_6_mixed (Concatenate)   (None, 35, 35, 128)  0           activation_42[0][0]              \n",
      "                                                                 activation_44[0][0]              \n",
      "                                                                 activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block35_6_conv (Conv2D)         (None, 35, 35, 320)  41280       block35_6_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_6 (Lambda)              (None, 35, 35, 320)  0           block35_5_ac[0][0]               \n",
      "                                                                 block35_6_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_6_ac (Activation)       (None, 35, 35, 320)  0           block35_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 35, 35, 32)   10240       block35_6_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_51 (Batc (None, 35, 35, 32)   96          conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 35, 35, 32)   0           batch_normalization_v1_51[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 35, 35, 32)   10240       block35_6_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 35, 35, 48)   13824       activation_51[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_49 (Batc (None, 35, 35, 32)   96          conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_52 (Batc (None, 35, 35, 48)   144         conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 35, 35, 32)   0           batch_normalization_v1_49[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 35, 35, 48)   0           batch_normalization_v1_52[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 35, 35, 32)   10240       block35_6_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 35, 35, 32)   9216        activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 35, 35, 64)   27648       activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_48 (Batc (None, 35, 35, 32)   96          conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_50 (Batc (None, 35, 35, 32)   96          conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_53 (Batc (None, 35, 35, 64)   192         conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 35, 35, 32)   0           batch_normalization_v1_48[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 35, 35, 32)   0           batch_normalization_v1_50[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 35, 35, 64)   0           batch_normalization_v1_53[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block35_7_mixed (Concatenate)   (None, 35, 35, 128)  0           activation_48[0][0]              \n",
      "                                                                 activation_50[0][0]              \n",
      "                                                                 activation_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block35_7_conv (Conv2D)         (None, 35, 35, 320)  41280       block35_7_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_7 (Lambda)              (None, 35, 35, 320)  0           block35_6_ac[0][0]               \n",
      "                                                                 block35_7_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_7_ac (Activation)       (None, 35, 35, 320)  0           block35_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 35, 35, 32)   10240       block35_7_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_57 (Batc (None, 35, 35, 32)   96          conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 35, 35, 32)   0           batch_normalization_v1_57[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 35, 35, 32)   10240       block35_7_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 35, 35, 48)   13824       activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_55 (Batc (None, 35, 35, 32)   96          conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_58 (Batc (None, 35, 35, 48)   144         conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 35, 35, 32)   0           batch_normalization_v1_55[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 35, 35, 48)   0           batch_normalization_v1_58[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 35, 35, 32)   10240       block35_7_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 35, 35, 32)   9216        activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 35, 35, 64)   27648       activation_58[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_54 (Batc (None, 35, 35, 32)   96          conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_56 (Batc (None, 35, 35, 32)   96          conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_59 (Batc (None, 35, 35, 64)   192         conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 35, 35, 32)   0           batch_normalization_v1_54[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 35, 35, 32)   0           batch_normalization_v1_56[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 35, 35, 64)   0           batch_normalization_v1_59[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block35_8_mixed (Concatenate)   (None, 35, 35, 128)  0           activation_54[0][0]              \n",
      "                                                                 activation_56[0][0]              \n",
      "                                                                 activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block35_8_conv (Conv2D)         (None, 35, 35, 320)  41280       block35_8_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_8 (Lambda)              (None, 35, 35, 320)  0           block35_7_ac[0][0]               \n",
      "                                                                 block35_8_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_8_ac (Activation)       (None, 35, 35, 320)  0           block35_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 35, 35, 32)   10240       block35_8_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_63 (Batc (None, 35, 35, 32)   96          conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 35, 35, 32)   0           batch_normalization_v1_63[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 35, 35, 32)   10240       block35_8_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 35, 35, 48)   13824       activation_63[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_61 (Batc (None, 35, 35, 32)   96          conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_64 (Batc (None, 35, 35, 48)   144         conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 35, 35, 32)   0           batch_normalization_v1_61[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, 35, 35, 48)   0           batch_normalization_v1_64[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 35, 35, 32)   10240       block35_8_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 35, 35, 32)   9216        activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 35, 35, 64)   27648       activation_64[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_60 (Batc (None, 35, 35, 32)   96          conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_62 (Batc (None, 35, 35, 32)   96          conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_65 (Batc (None, 35, 35, 64)   192         conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 35, 35, 32)   0           batch_normalization_v1_60[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 35, 35, 32)   0           batch_normalization_v1_62[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, 35, 35, 64)   0           batch_normalization_v1_65[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block35_9_mixed (Concatenate)   (None, 35, 35, 128)  0           activation_60[0][0]              \n",
      "                                                                 activation_62[0][0]              \n",
      "                                                                 activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block35_9_conv (Conv2D)         (None, 35, 35, 320)  41280       block35_9_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_9 (Lambda)              (None, 35, 35, 320)  0           block35_8_ac[0][0]               \n",
      "                                                                 block35_9_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_9_ac (Activation)       (None, 35, 35, 320)  0           block35_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 35, 35, 32)   10240       block35_9_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_69 (Batc (None, 35, 35, 32)   96          conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, 35, 35, 32)   0           batch_normalization_v1_69[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 35, 35, 32)   10240       block35_9_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, 35, 35, 48)   13824       activation_69[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_67 (Batc (None, 35, 35, 32)   96          conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_70 (Batc (None, 35, 35, 48)   144         conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, 35, 35, 32)   0           batch_normalization_v1_67[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_70 (Activation)      (None, 35, 35, 48)   0           batch_normalization_v1_70[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 35, 35, 32)   10240       block35_9_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 35, 35, 32)   9216        activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, 35, 35, 64)   27648       activation_70[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_66 (Batc (None, 35, 35, 32)   96          conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_68 (Batc (None, 35, 35, 32)   96          conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_71 (Batc (None, 35, 35, 64)   192         conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, 35, 35, 32)   0           batch_normalization_v1_66[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, 35, 35, 32)   0           batch_normalization_v1_68[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_71 (Activation)      (None, 35, 35, 64)   0           batch_normalization_v1_71[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block35_10_mixed (Concatenate)  (None, 35, 35, 128)  0           activation_66[0][0]              \n",
      "                                                                 activation_68[0][0]              \n",
      "                                                                 activation_71[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block35_10_conv (Conv2D)        (None, 35, 35, 320)  41280       block35_10_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block35_10 (Lambda)             (None, 35, 35, 320)  0           block35_9_ac[0][0]               \n",
      "                                                                 block35_10_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_10_ac (Activation)      (None, 35, 35, 320)  0           block35_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, 35, 35, 256)  81920       block35_10_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_73 (Batc (None, 35, 35, 256)  768         conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_73 (Activation)      (None, 35, 35, 256)  0           batch_normalization_v1_73[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, 35, 35, 256)  589824      activation_73[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_74 (Batc (None, 35, 35, 256)  768         conv2d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_74 (Activation)      (None, 35, 35, 256)  0           batch_normalization_v1_74[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, 17, 17, 384)  1105920     block35_10_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, 17, 17, 384)  884736      activation_74[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_72 (Batc (None, 17, 17, 384)  1152        conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_75 (Batc (None, 17, 17, 384)  1152        conv2d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_72 (Activation)      (None, 17, 17, 384)  0           batch_normalization_v1_72[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_75 (Activation)      (None, 17, 17, 384)  0           batch_normalization_v1_75[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 17, 17, 320)  0           block35_10_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "mixed_6a (Concatenate)          (None, 17, 17, 1088) 0           activation_72[0][0]              \n",
      "                                                                 activation_75[0][0]              \n",
      "                                                                 max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, 17, 17, 128)  139264      mixed_6a[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_77 (Batc (None, 17, 17, 128)  384         conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_77 (Activation)      (None, 17, 17, 128)  0           batch_normalization_v1_77[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, 17, 17, 160)  143360      activation_77[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_78 (Batc (None, 17, 17, 160)  480         conv2d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_78 (Activation)      (None, 17, 17, 160)  0           batch_normalization_v1_78[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, 17, 17, 192)  208896      mixed_6a[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, 17, 17, 192)  215040      activation_78[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_76 (Batc (None, 17, 17, 192)  576         conv2d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_79 (Batc (None, 17, 17, 192)  576         conv2d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_76 (Activation)      (None, 17, 17, 192)  0           batch_normalization_v1_76[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_79 (Activation)      (None, 17, 17, 192)  0           batch_normalization_v1_79[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block17_1_mixed (Concatenate)   (None, 17, 17, 384)  0           activation_76[0][0]              \n",
      "                                                                 activation_79[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block17_1_conv (Conv2D)         (None, 17, 17, 1088) 418880      block17_1_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_1 (Lambda)              (None, 17, 17, 1088) 0           mixed_6a[0][0]                   \n",
      "                                                                 block17_1_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_1_ac (Activation)       (None, 17, 17, 1088) 0           block17_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, 17, 17, 128)  139264      block17_1_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_81 (Batc (None, 17, 17, 128)  384         conv2d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_81 (Activation)      (None, 17, 17, 128)  0           batch_normalization_v1_81[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (None, 17, 17, 160)  143360      activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_82 (Batc (None, 17, 17, 160)  480         conv2d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_82 (Activation)      (None, 17, 17, 160)  0           batch_normalization_v1_82[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, 17, 17, 192)  208896      block17_1_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)              (None, 17, 17, 192)  215040      activation_82[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_80 (Batc (None, 17, 17, 192)  576         conv2d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_83 (Batc (None, 17, 17, 192)  576         conv2d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_80 (Activation)      (None, 17, 17, 192)  0           batch_normalization_v1_80[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_83 (Activation)      (None, 17, 17, 192)  0           batch_normalization_v1_83[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block17_2_mixed (Concatenate)   (None, 17, 17, 384)  0           activation_80[0][0]              \n",
      "                                                                 activation_83[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block17_2_conv (Conv2D)         (None, 17, 17, 1088) 418880      block17_2_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_2 (Lambda)              (None, 17, 17, 1088) 0           block17_1_ac[0][0]               \n",
      "                                                                 block17_2_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_2_ac (Activation)       (None, 17, 17, 1088) 0           block17_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)              (None, 17, 17, 128)  139264      block17_2_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_85 (Batc (None, 17, 17, 128)  384         conv2d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_85 (Activation)      (None, 17, 17, 128)  0           batch_normalization_v1_85[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)              (None, 17, 17, 160)  143360      activation_85[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_86 (Batc (None, 17, 17, 160)  480         conv2d_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_86 (Activation)      (None, 17, 17, 160)  0           batch_normalization_v1_86[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)              (None, 17, 17, 192)  208896      block17_2_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)              (None, 17, 17, 192)  215040      activation_86[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_84 (Batc (None, 17, 17, 192)  576         conv2d_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_87 (Batc (None, 17, 17, 192)  576         conv2d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_84 (Activation)      (None, 17, 17, 192)  0           batch_normalization_v1_84[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_87 (Activation)      (None, 17, 17, 192)  0           batch_normalization_v1_87[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block17_3_mixed (Concatenate)   (None, 17, 17, 384)  0           activation_84[0][0]              \n",
      "                                                                 activation_87[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block17_3_conv (Conv2D)         (None, 17, 17, 1088) 418880      block17_3_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_3 (Lambda)              (None, 17, 17, 1088) 0           block17_2_ac[0][0]               \n",
      "                                                                 block17_3_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_3_ac (Activation)       (None, 17, 17, 1088) 0           block17_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)              (None, 17, 17, 128)  139264      block17_3_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_89 (Batc (None, 17, 17, 128)  384         conv2d_89[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_89 (Activation)      (None, 17, 17, 128)  0           batch_normalization_v1_89[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)              (None, 17, 17, 160)  143360      activation_89[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_90 (Batc (None, 17, 17, 160)  480         conv2d_90[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_90 (Activation)      (None, 17, 17, 160)  0           batch_normalization_v1_90[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)              (None, 17, 17, 192)  208896      block17_3_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_91 (Conv2D)              (None, 17, 17, 192)  215040      activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_88 (Batc (None, 17, 17, 192)  576         conv2d_88[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_91 (Batc (None, 17, 17, 192)  576         conv2d_91[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_88 (Activation)      (None, 17, 17, 192)  0           batch_normalization_v1_88[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_91 (Activation)      (None, 17, 17, 192)  0           batch_normalization_v1_91[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block17_4_mixed (Concatenate)   (None, 17, 17, 384)  0           activation_88[0][0]              \n",
      "                                                                 activation_91[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block17_4_conv (Conv2D)         (None, 17, 17, 1088) 418880      block17_4_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_4 (Lambda)              (None, 17, 17, 1088) 0           block17_3_ac[0][0]               \n",
      "                                                                 block17_4_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_4_ac (Activation)       (None, 17, 17, 1088) 0           block17_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_93 (Conv2D)              (None, 17, 17, 128)  139264      block17_4_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_93 (Batc (None, 17, 17, 128)  384         conv2d_93[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_93 (Activation)      (None, 17, 17, 128)  0           batch_normalization_v1_93[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_94 (Conv2D)              (None, 17, 17, 160)  143360      activation_93[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_94 (Batc (None, 17, 17, 160)  480         conv2d_94[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_94 (Activation)      (None, 17, 17, 160)  0           batch_normalization_v1_94[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_92 (Conv2D)              (None, 17, 17, 192)  208896      block17_4_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_95 (Conv2D)              (None, 17, 17, 192)  215040      activation_94[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_92 (Batc (None, 17, 17, 192)  576         conv2d_92[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_95 (Batc (None, 17, 17, 192)  576         conv2d_95[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_92 (Activation)      (None, 17, 17, 192)  0           batch_normalization_v1_92[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_95 (Activation)      (None, 17, 17, 192)  0           batch_normalization_v1_95[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block17_5_mixed (Concatenate)   (None, 17, 17, 384)  0           activation_92[0][0]              \n",
      "                                                                 activation_95[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block17_5_conv (Conv2D)         (None, 17, 17, 1088) 418880      block17_5_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_5 (Lambda)              (None, 17, 17, 1088) 0           block17_4_ac[0][0]               \n",
      "                                                                 block17_5_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_5_ac (Activation)       (None, 17, 17, 1088) 0           block17_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_97 (Conv2D)              (None, 17, 17, 128)  139264      block17_5_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_97 (Batc (None, 17, 17, 128)  384         conv2d_97[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_97 (Activation)      (None, 17, 17, 128)  0           batch_normalization_v1_97[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_98 (Conv2D)              (None, 17, 17, 160)  143360      activation_97[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_98 (Batc (None, 17, 17, 160)  480         conv2d_98[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_98 (Activation)      (None, 17, 17, 160)  0           batch_normalization_v1_98[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_96 (Conv2D)              (None, 17, 17, 192)  208896      block17_5_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_99 (Conv2D)              (None, 17, 17, 192)  215040      activation_98[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_96 (Batc (None, 17, 17, 192)  576         conv2d_96[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_99 (Batc (None, 17, 17, 192)  576         conv2d_99[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_96 (Activation)      (None, 17, 17, 192)  0           batch_normalization_v1_96[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_99 (Activation)      (None, 17, 17, 192)  0           batch_normalization_v1_99[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block17_6_mixed (Concatenate)   (None, 17, 17, 384)  0           activation_96[0][0]              \n",
      "                                                                 activation_99[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block17_6_conv (Conv2D)         (None, 17, 17, 1088) 418880      block17_6_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_6 (Lambda)              (None, 17, 17, 1088) 0           block17_5_ac[0][0]               \n",
      "                                                                 block17_6_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_6_ac (Activation)       (None, 17, 17, 1088) 0           block17_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_101 (Conv2D)             (None, 17, 17, 128)  139264      block17_6_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_101 (Bat (None, 17, 17, 128)  384         conv2d_101[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_101 (Activation)     (None, 17, 17, 128)  0           batch_normalization_v1_101[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_102 (Conv2D)             (None, 17, 17, 160)  143360      activation_101[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_102 (Bat (None, 17, 17, 160)  480         conv2d_102[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_102 (Activation)     (None, 17, 17, 160)  0           batch_normalization_v1_102[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_100 (Conv2D)             (None, 17, 17, 192)  208896      block17_6_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_103 (Conv2D)             (None, 17, 17, 192)  215040      activation_102[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_100 (Bat (None, 17, 17, 192)  576         conv2d_100[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_103 (Bat (None, 17, 17, 192)  576         conv2d_103[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_100 (Activation)     (None, 17, 17, 192)  0           batch_normalization_v1_100[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_103 (Activation)     (None, 17, 17, 192)  0           batch_normalization_v1_103[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "block17_7_mixed (Concatenate)   (None, 17, 17, 384)  0           activation_100[0][0]             \n",
      "                                                                 activation_103[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_7_conv (Conv2D)         (None, 17, 17, 1088) 418880      block17_7_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_7 (Lambda)              (None, 17, 17, 1088) 0           block17_6_ac[0][0]               \n",
      "                                                                 block17_7_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_7_ac (Activation)       (None, 17, 17, 1088) 0           block17_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_105 (Conv2D)             (None, 17, 17, 128)  139264      block17_7_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_105 (Bat (None, 17, 17, 128)  384         conv2d_105[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_105 (Activation)     (None, 17, 17, 128)  0           batch_normalization_v1_105[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_106 (Conv2D)             (None, 17, 17, 160)  143360      activation_105[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_106 (Bat (None, 17, 17, 160)  480         conv2d_106[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_106 (Activation)     (None, 17, 17, 160)  0           batch_normalization_v1_106[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_104 (Conv2D)             (None, 17, 17, 192)  208896      block17_7_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_107 (Conv2D)             (None, 17, 17, 192)  215040      activation_106[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_104 (Bat (None, 17, 17, 192)  576         conv2d_104[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_107 (Bat (None, 17, 17, 192)  576         conv2d_107[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_104 (Activation)     (None, 17, 17, 192)  0           batch_normalization_v1_104[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_107 (Activation)     (None, 17, 17, 192)  0           batch_normalization_v1_107[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "block17_8_mixed (Concatenate)   (None, 17, 17, 384)  0           activation_104[0][0]             \n",
      "                                                                 activation_107[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_8_conv (Conv2D)         (None, 17, 17, 1088) 418880      block17_8_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_8 (Lambda)              (None, 17, 17, 1088) 0           block17_7_ac[0][0]               \n",
      "                                                                 block17_8_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_8_ac (Activation)       (None, 17, 17, 1088) 0           block17_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_109 (Conv2D)             (None, 17, 17, 128)  139264      block17_8_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_109 (Bat (None, 17, 17, 128)  384         conv2d_109[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_109 (Activation)     (None, 17, 17, 128)  0           batch_normalization_v1_109[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_110 (Conv2D)             (None, 17, 17, 160)  143360      activation_109[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_110 (Bat (None, 17, 17, 160)  480         conv2d_110[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_110 (Activation)     (None, 17, 17, 160)  0           batch_normalization_v1_110[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_108 (Conv2D)             (None, 17, 17, 192)  208896      block17_8_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_111 (Conv2D)             (None, 17, 17, 192)  215040      activation_110[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_108 (Bat (None, 17, 17, 192)  576         conv2d_108[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_111 (Bat (None, 17, 17, 192)  576         conv2d_111[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_108 (Activation)     (None, 17, 17, 192)  0           batch_normalization_v1_108[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_111 (Activation)     (None, 17, 17, 192)  0           batch_normalization_v1_111[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "block17_9_mixed (Concatenate)   (None, 17, 17, 384)  0           activation_108[0][0]             \n",
      "                                                                 activation_111[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_9_conv (Conv2D)         (None, 17, 17, 1088) 418880      block17_9_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_9 (Lambda)              (None, 17, 17, 1088) 0           block17_8_ac[0][0]               \n",
      "                                                                 block17_9_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_9_ac (Activation)       (None, 17, 17, 1088) 0           block17_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_113 (Conv2D)             (None, 17, 17, 128)  139264      block17_9_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_113 (Bat (None, 17, 17, 128)  384         conv2d_113[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_113 (Activation)     (None, 17, 17, 128)  0           batch_normalization_v1_113[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_114 (Conv2D)             (None, 17, 17, 160)  143360      activation_113[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_114 (Bat (None, 17, 17, 160)  480         conv2d_114[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_114 (Activation)     (None, 17, 17, 160)  0           batch_normalization_v1_114[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_112 (Conv2D)             (None, 17, 17, 192)  208896      block17_9_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_115 (Conv2D)             (None, 17, 17, 192)  215040      activation_114[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_112 (Bat (None, 17, 17, 192)  576         conv2d_112[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_115 (Bat (None, 17, 17, 192)  576         conv2d_115[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_112 (Activation)     (None, 17, 17, 192)  0           batch_normalization_v1_112[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_115 (Activation)     (None, 17, 17, 192)  0           batch_normalization_v1_115[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "block17_10_mixed (Concatenate)  (None, 17, 17, 384)  0           activation_112[0][0]             \n",
      "                                                                 activation_115[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_10_conv (Conv2D)        (None, 17, 17, 1088) 418880      block17_10_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_10 (Lambda)             (None, 17, 17, 1088) 0           block17_9_ac[0][0]               \n",
      "                                                                 block17_10_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_10_ac (Activation)      (None, 17, 17, 1088) 0           block17_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_117 (Conv2D)             (None, 17, 17, 128)  139264      block17_10_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_117 (Bat (None, 17, 17, 128)  384         conv2d_117[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_117 (Activation)     (None, 17, 17, 128)  0           batch_normalization_v1_117[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_118 (Conv2D)             (None, 17, 17, 160)  143360      activation_117[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_118 (Bat (None, 17, 17, 160)  480         conv2d_118[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_118 (Activation)     (None, 17, 17, 160)  0           batch_normalization_v1_118[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_116 (Conv2D)             (None, 17, 17, 192)  208896      block17_10_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_119 (Conv2D)             (None, 17, 17, 192)  215040      activation_118[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_116 (Bat (None, 17, 17, 192)  576         conv2d_116[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_119 (Bat (None, 17, 17, 192)  576         conv2d_119[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_116 (Activation)     (None, 17, 17, 192)  0           batch_normalization_v1_116[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_119 (Activation)     (None, 17, 17, 192)  0           batch_normalization_v1_119[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "block17_11_mixed (Concatenate)  (None, 17, 17, 384)  0           activation_116[0][0]             \n",
      "                                                                 activation_119[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_11_conv (Conv2D)        (None, 17, 17, 1088) 418880      block17_11_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_11 (Lambda)             (None, 17, 17, 1088) 0           block17_10_ac[0][0]              \n",
      "                                                                 block17_11_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_11_ac (Activation)      (None, 17, 17, 1088) 0           block17_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_121 (Conv2D)             (None, 17, 17, 128)  139264      block17_11_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_121 (Bat (None, 17, 17, 128)  384         conv2d_121[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_121 (Activation)     (None, 17, 17, 128)  0           batch_normalization_v1_121[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_122 (Conv2D)             (None, 17, 17, 160)  143360      activation_121[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_122 (Bat (None, 17, 17, 160)  480         conv2d_122[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_122 (Activation)     (None, 17, 17, 160)  0           batch_normalization_v1_122[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_120 (Conv2D)             (None, 17, 17, 192)  208896      block17_11_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_123 (Conv2D)             (None, 17, 17, 192)  215040      activation_122[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_120 (Bat (None, 17, 17, 192)  576         conv2d_120[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_123 (Bat (None, 17, 17, 192)  576         conv2d_123[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_120 (Activation)     (None, 17, 17, 192)  0           batch_normalization_v1_120[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_123 (Activation)     (None, 17, 17, 192)  0           batch_normalization_v1_123[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "block17_12_mixed (Concatenate)  (None, 17, 17, 384)  0           activation_120[0][0]             \n",
      "                                                                 activation_123[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_12_conv (Conv2D)        (None, 17, 17, 1088) 418880      block17_12_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_12 (Lambda)             (None, 17, 17, 1088) 0           block17_11_ac[0][0]              \n",
      "                                                                 block17_12_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_12_ac (Activation)      (None, 17, 17, 1088) 0           block17_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_125 (Conv2D)             (None, 17, 17, 128)  139264      block17_12_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_125 (Bat (None, 17, 17, 128)  384         conv2d_125[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_125 (Activation)     (None, 17, 17, 128)  0           batch_normalization_v1_125[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_126 (Conv2D)             (None, 17, 17, 160)  143360      activation_125[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_126 (Bat (None, 17, 17, 160)  480         conv2d_126[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_126 (Activation)     (None, 17, 17, 160)  0           batch_normalization_v1_126[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_124 (Conv2D)             (None, 17, 17, 192)  208896      block17_12_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_127 (Conv2D)             (None, 17, 17, 192)  215040      activation_126[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_124 (Bat (None, 17, 17, 192)  576         conv2d_124[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_127 (Bat (None, 17, 17, 192)  576         conv2d_127[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_124 (Activation)     (None, 17, 17, 192)  0           batch_normalization_v1_124[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_127 (Activation)     (None, 17, 17, 192)  0           batch_normalization_v1_127[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "block17_13_mixed (Concatenate)  (None, 17, 17, 384)  0           activation_124[0][0]             \n",
      "                                                                 activation_127[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_13_conv (Conv2D)        (None, 17, 17, 1088) 418880      block17_13_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_13 (Lambda)             (None, 17, 17, 1088) 0           block17_12_ac[0][0]              \n",
      "                                                                 block17_13_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_13_ac (Activation)      (None, 17, 17, 1088) 0           block17_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_129 (Conv2D)             (None, 17, 17, 128)  139264      block17_13_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_129 (Bat (None, 17, 17, 128)  384         conv2d_129[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_129 (Activation)     (None, 17, 17, 128)  0           batch_normalization_v1_129[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_130 (Conv2D)             (None, 17, 17, 160)  143360      activation_129[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_130 (Bat (None, 17, 17, 160)  480         conv2d_130[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_130 (Activation)     (None, 17, 17, 160)  0           batch_normalization_v1_130[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_128 (Conv2D)             (None, 17, 17, 192)  208896      block17_13_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_131 (Conv2D)             (None, 17, 17, 192)  215040      activation_130[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_128 (Bat (None, 17, 17, 192)  576         conv2d_128[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_131 (Bat (None, 17, 17, 192)  576         conv2d_131[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_128 (Activation)     (None, 17, 17, 192)  0           batch_normalization_v1_128[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_131 (Activation)     (None, 17, 17, 192)  0           batch_normalization_v1_131[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "block17_14_mixed (Concatenate)  (None, 17, 17, 384)  0           activation_128[0][0]             \n",
      "                                                                 activation_131[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_14_conv (Conv2D)        (None, 17, 17, 1088) 418880      block17_14_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_14 (Lambda)             (None, 17, 17, 1088) 0           block17_13_ac[0][0]              \n",
      "                                                                 block17_14_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_14_ac (Activation)      (None, 17, 17, 1088) 0           block17_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_133 (Conv2D)             (None, 17, 17, 128)  139264      block17_14_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_133 (Bat (None, 17, 17, 128)  384         conv2d_133[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_133 (Activation)     (None, 17, 17, 128)  0           batch_normalization_v1_133[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_134 (Conv2D)             (None, 17, 17, 160)  143360      activation_133[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_134 (Bat (None, 17, 17, 160)  480         conv2d_134[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_134 (Activation)     (None, 17, 17, 160)  0           batch_normalization_v1_134[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_132 (Conv2D)             (None, 17, 17, 192)  208896      block17_14_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_135 (Conv2D)             (None, 17, 17, 192)  215040      activation_134[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_132 (Bat (None, 17, 17, 192)  576         conv2d_132[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_135 (Bat (None, 17, 17, 192)  576         conv2d_135[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_132 (Activation)     (None, 17, 17, 192)  0           batch_normalization_v1_132[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_135 (Activation)     (None, 17, 17, 192)  0           batch_normalization_v1_135[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "block17_15_mixed (Concatenate)  (None, 17, 17, 384)  0           activation_132[0][0]             \n",
      "                                                                 activation_135[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_15_conv (Conv2D)        (None, 17, 17, 1088) 418880      block17_15_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_15 (Lambda)             (None, 17, 17, 1088) 0           block17_14_ac[0][0]              \n",
      "                                                                 block17_15_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_15_ac (Activation)      (None, 17, 17, 1088) 0           block17_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_137 (Conv2D)             (None, 17, 17, 128)  139264      block17_15_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_137 (Bat (None, 17, 17, 128)  384         conv2d_137[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_137 (Activation)     (None, 17, 17, 128)  0           batch_normalization_v1_137[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_138 (Conv2D)             (None, 17, 17, 160)  143360      activation_137[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_138 (Bat (None, 17, 17, 160)  480         conv2d_138[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_138 (Activation)     (None, 17, 17, 160)  0           batch_normalization_v1_138[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_136 (Conv2D)             (None, 17, 17, 192)  208896      block17_15_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_139 (Conv2D)             (None, 17, 17, 192)  215040      activation_138[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_136 (Bat (None, 17, 17, 192)  576         conv2d_136[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_139 (Bat (None, 17, 17, 192)  576         conv2d_139[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_136 (Activation)     (None, 17, 17, 192)  0           batch_normalization_v1_136[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_139 (Activation)     (None, 17, 17, 192)  0           batch_normalization_v1_139[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "block17_16_mixed (Concatenate)  (None, 17, 17, 384)  0           activation_136[0][0]             \n",
      "                                                                 activation_139[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_16_conv (Conv2D)        (None, 17, 17, 1088) 418880      block17_16_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_16 (Lambda)             (None, 17, 17, 1088) 0           block17_15_ac[0][0]              \n",
      "                                                                 block17_16_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_16_ac (Activation)      (None, 17, 17, 1088) 0           block17_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_141 (Conv2D)             (None, 17, 17, 128)  139264      block17_16_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_141 (Bat (None, 17, 17, 128)  384         conv2d_141[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_141 (Activation)     (None, 17, 17, 128)  0           batch_normalization_v1_141[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_142 (Conv2D)             (None, 17, 17, 160)  143360      activation_141[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_142 (Bat (None, 17, 17, 160)  480         conv2d_142[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_142 (Activation)     (None, 17, 17, 160)  0           batch_normalization_v1_142[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_140 (Conv2D)             (None, 17, 17, 192)  208896      block17_16_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_143 (Conv2D)             (None, 17, 17, 192)  215040      activation_142[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_140 (Bat (None, 17, 17, 192)  576         conv2d_140[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_143 (Bat (None, 17, 17, 192)  576         conv2d_143[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_140 (Activation)     (None, 17, 17, 192)  0           batch_normalization_v1_140[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_143 (Activation)     (None, 17, 17, 192)  0           batch_normalization_v1_143[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "block17_17_mixed (Concatenate)  (None, 17, 17, 384)  0           activation_140[0][0]             \n",
      "                                                                 activation_143[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_17_conv (Conv2D)        (None, 17, 17, 1088) 418880      block17_17_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_17 (Lambda)             (None, 17, 17, 1088) 0           block17_16_ac[0][0]              \n",
      "                                                                 block17_17_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_17_ac (Activation)      (None, 17, 17, 1088) 0           block17_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_145 (Conv2D)             (None, 17, 17, 128)  139264      block17_17_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_145 (Bat (None, 17, 17, 128)  384         conv2d_145[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_145 (Activation)     (None, 17, 17, 128)  0           batch_normalization_v1_145[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_146 (Conv2D)             (None, 17, 17, 160)  143360      activation_145[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_146 (Bat (None, 17, 17, 160)  480         conv2d_146[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_146 (Activation)     (None, 17, 17, 160)  0           batch_normalization_v1_146[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_144 (Conv2D)             (None, 17, 17, 192)  208896      block17_17_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_147 (Conv2D)             (None, 17, 17, 192)  215040      activation_146[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_144 (Bat (None, 17, 17, 192)  576         conv2d_144[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_147 (Bat (None, 17, 17, 192)  576         conv2d_147[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_144 (Activation)     (None, 17, 17, 192)  0           batch_normalization_v1_144[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_147 (Activation)     (None, 17, 17, 192)  0           batch_normalization_v1_147[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "block17_18_mixed (Concatenate)  (None, 17, 17, 384)  0           activation_144[0][0]             \n",
      "                                                                 activation_147[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_18_conv (Conv2D)        (None, 17, 17, 1088) 418880      block17_18_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_18 (Lambda)             (None, 17, 17, 1088) 0           block17_17_ac[0][0]              \n",
      "                                                                 block17_18_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_18_ac (Activation)      (None, 17, 17, 1088) 0           block17_18[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_149 (Conv2D)             (None, 17, 17, 128)  139264      block17_18_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_149 (Bat (None, 17, 17, 128)  384         conv2d_149[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_149 (Activation)     (None, 17, 17, 128)  0           batch_normalization_v1_149[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_150 (Conv2D)             (None, 17, 17, 160)  143360      activation_149[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_150 (Bat (None, 17, 17, 160)  480         conv2d_150[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_150 (Activation)     (None, 17, 17, 160)  0           batch_normalization_v1_150[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_148 (Conv2D)             (None, 17, 17, 192)  208896      block17_18_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_151 (Conv2D)             (None, 17, 17, 192)  215040      activation_150[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_148 (Bat (None, 17, 17, 192)  576         conv2d_148[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_151 (Bat (None, 17, 17, 192)  576         conv2d_151[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_148 (Activation)     (None, 17, 17, 192)  0           batch_normalization_v1_148[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_151 (Activation)     (None, 17, 17, 192)  0           batch_normalization_v1_151[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "block17_19_mixed (Concatenate)  (None, 17, 17, 384)  0           activation_148[0][0]             \n",
      "                                                                 activation_151[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_19_conv (Conv2D)        (None, 17, 17, 1088) 418880      block17_19_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_19 (Lambda)             (None, 17, 17, 1088) 0           block17_18_ac[0][0]              \n",
      "                                                                 block17_19_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_19_ac (Activation)      (None, 17, 17, 1088) 0           block17_19[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_153 (Conv2D)             (None, 17, 17, 128)  139264      block17_19_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_153 (Bat (None, 17, 17, 128)  384         conv2d_153[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_153 (Activation)     (None, 17, 17, 128)  0           batch_normalization_v1_153[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_154 (Conv2D)             (None, 17, 17, 160)  143360      activation_153[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_154 (Bat (None, 17, 17, 160)  480         conv2d_154[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_154 (Activation)     (None, 17, 17, 160)  0           batch_normalization_v1_154[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_152 (Conv2D)             (None, 17, 17, 192)  208896      block17_19_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_155 (Conv2D)             (None, 17, 17, 192)  215040      activation_154[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_152 (Bat (None, 17, 17, 192)  576         conv2d_152[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_155 (Bat (None, 17, 17, 192)  576         conv2d_155[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_152 (Activation)     (None, 17, 17, 192)  0           batch_normalization_v1_152[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_155 (Activation)     (None, 17, 17, 192)  0           batch_normalization_v1_155[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "block17_20_mixed (Concatenate)  (None, 17, 17, 384)  0           activation_152[0][0]             \n",
      "                                                                 activation_155[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_20_conv (Conv2D)        (None, 17, 17, 1088) 418880      block17_20_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_20 (Lambda)             (None, 17, 17, 1088) 0           block17_19_ac[0][0]              \n",
      "                                                                 block17_20_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_20_ac (Activation)      (None, 17, 17, 1088) 0           block17_20[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_160 (Conv2D)             (None, 17, 17, 256)  278528      block17_20_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_160 (Bat (None, 17, 17, 256)  768         conv2d_160[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_160 (Activation)     (None, 17, 17, 256)  0           batch_normalization_v1_160[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_156 (Conv2D)             (None, 17, 17, 256)  278528      block17_20_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_158 (Conv2D)             (None, 17, 17, 256)  278528      block17_20_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_161 (Conv2D)             (None, 17, 17, 288)  663552      activation_160[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_156 (Bat (None, 17, 17, 256)  768         conv2d_156[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_158 (Bat (None, 17, 17, 256)  768         conv2d_158[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_161 (Bat (None, 17, 17, 288)  864         conv2d_161[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_156 (Activation)     (None, 17, 17, 256)  0           batch_normalization_v1_156[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_158 (Activation)     (None, 17, 17, 256)  0           batch_normalization_v1_158[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_161 (Activation)     (None, 17, 17, 288)  0           batch_normalization_v1_161[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_157 (Conv2D)             (None, 8, 8, 384)    884736      activation_156[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_159 (Conv2D)             (None, 8, 8, 288)    663552      activation_158[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_162 (Conv2D)             (None, 8, 8, 320)    829440      activation_161[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_157 (Bat (None, 8, 8, 384)    1152        conv2d_157[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_159 (Bat (None, 8, 8, 288)    864         conv2d_159[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_162 (Bat (None, 8, 8, 320)    960         conv2d_162[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_157 (Activation)     (None, 8, 8, 384)    0           batch_normalization_v1_157[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_159 (Activation)     (None, 8, 8, 288)    0           batch_normalization_v1_159[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_162 (Activation)     (None, 8, 8, 320)    0           batch_normalization_v1_162[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 8, 8, 1088)   0           block17_20_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "mixed_7a (Concatenate)          (None, 8, 8, 2080)   0           activation_157[0][0]             \n",
      "                                                                 activation_159[0][0]             \n",
      "                                                                 activation_162[0][0]             \n",
      "                                                                 max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_164 (Conv2D)             (None, 8, 8, 192)    399360      mixed_7a[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_164 (Bat (None, 8, 8, 192)    576         conv2d_164[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_164 (Activation)     (None, 8, 8, 192)    0           batch_normalization_v1_164[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_165 (Conv2D)             (None, 8, 8, 224)    129024      activation_164[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_165 (Bat (None, 8, 8, 224)    672         conv2d_165[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_165 (Activation)     (None, 8, 8, 224)    0           batch_normalization_v1_165[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_163 (Conv2D)             (None, 8, 8, 192)    399360      mixed_7a[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_166 (Conv2D)             (None, 8, 8, 256)    172032      activation_165[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_163 (Bat (None, 8, 8, 192)    576         conv2d_163[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_166 (Bat (None, 8, 8, 256)    768         conv2d_166[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_163 (Activation)     (None, 8, 8, 192)    0           batch_normalization_v1_163[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_166 (Activation)     (None, 8, 8, 256)    0           batch_normalization_v1_166[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "block8_1_mixed (Concatenate)    (None, 8, 8, 448)    0           activation_163[0][0]             \n",
      "                                                                 activation_166[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_1_conv (Conv2D)          (None, 8, 8, 2080)   933920      block8_1_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_1 (Lambda)               (None, 8, 8, 2080)   0           mixed_7a[0][0]                   \n",
      "                                                                 block8_1_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_1_ac (Activation)        (None, 8, 8, 2080)   0           block8_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_168 (Conv2D)             (None, 8, 8, 192)    399360      block8_1_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_168 (Bat (None, 8, 8, 192)    576         conv2d_168[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_168 (Activation)     (None, 8, 8, 192)    0           batch_normalization_v1_168[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_169 (Conv2D)             (None, 8, 8, 224)    129024      activation_168[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_169 (Bat (None, 8, 8, 224)    672         conv2d_169[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_169 (Activation)     (None, 8, 8, 224)    0           batch_normalization_v1_169[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_167 (Conv2D)             (None, 8, 8, 192)    399360      block8_1_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_170 (Conv2D)             (None, 8, 8, 256)    172032      activation_169[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_167 (Bat (None, 8, 8, 192)    576         conv2d_167[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_170 (Bat (None, 8, 8, 256)    768         conv2d_170[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_167 (Activation)     (None, 8, 8, 192)    0           batch_normalization_v1_167[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_170 (Activation)     (None, 8, 8, 256)    0           batch_normalization_v1_170[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "block8_2_mixed (Concatenate)    (None, 8, 8, 448)    0           activation_167[0][0]             \n",
      "                                                                 activation_170[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_2_conv (Conv2D)          (None, 8, 8, 2080)   933920      block8_2_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_2 (Lambda)               (None, 8, 8, 2080)   0           block8_1_ac[0][0]                \n",
      "                                                                 block8_2_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_2_ac (Activation)        (None, 8, 8, 2080)   0           block8_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_172 (Conv2D)             (None, 8, 8, 192)    399360      block8_2_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_172 (Bat (None, 8, 8, 192)    576         conv2d_172[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_172 (Activation)     (None, 8, 8, 192)    0           batch_normalization_v1_172[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_173 (Conv2D)             (None, 8, 8, 224)    129024      activation_172[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_173 (Bat (None, 8, 8, 224)    672         conv2d_173[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_173 (Activation)     (None, 8, 8, 224)    0           batch_normalization_v1_173[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_171 (Conv2D)             (None, 8, 8, 192)    399360      block8_2_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_174 (Conv2D)             (None, 8, 8, 256)    172032      activation_173[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_171 (Bat (None, 8, 8, 192)    576         conv2d_171[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_174 (Bat (None, 8, 8, 256)    768         conv2d_174[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_171 (Activation)     (None, 8, 8, 192)    0           batch_normalization_v1_171[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_174 (Activation)     (None, 8, 8, 256)    0           batch_normalization_v1_174[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "block8_3_mixed (Concatenate)    (None, 8, 8, 448)    0           activation_171[0][0]             \n",
      "                                                                 activation_174[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_3_conv (Conv2D)          (None, 8, 8, 2080)   933920      block8_3_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_3 (Lambda)               (None, 8, 8, 2080)   0           block8_2_ac[0][0]                \n",
      "                                                                 block8_3_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_3_ac (Activation)        (None, 8, 8, 2080)   0           block8_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_176 (Conv2D)             (None, 8, 8, 192)    399360      block8_3_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_176 (Bat (None, 8, 8, 192)    576         conv2d_176[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_176 (Activation)     (None, 8, 8, 192)    0           batch_normalization_v1_176[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_177 (Conv2D)             (None, 8, 8, 224)    129024      activation_176[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_177 (Bat (None, 8, 8, 224)    672         conv2d_177[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_177 (Activation)     (None, 8, 8, 224)    0           batch_normalization_v1_177[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_175 (Conv2D)             (None, 8, 8, 192)    399360      block8_3_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_178 (Conv2D)             (None, 8, 8, 256)    172032      activation_177[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_175 (Bat (None, 8, 8, 192)    576         conv2d_175[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_178 (Bat (None, 8, 8, 256)    768         conv2d_178[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_175 (Activation)     (None, 8, 8, 192)    0           batch_normalization_v1_175[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_178 (Activation)     (None, 8, 8, 256)    0           batch_normalization_v1_178[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "block8_4_mixed (Concatenate)    (None, 8, 8, 448)    0           activation_175[0][0]             \n",
      "                                                                 activation_178[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_4_conv (Conv2D)          (None, 8, 8, 2080)   933920      block8_4_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_4 (Lambda)               (None, 8, 8, 2080)   0           block8_3_ac[0][0]                \n",
      "                                                                 block8_4_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_4_ac (Activation)        (None, 8, 8, 2080)   0           block8_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_180 (Conv2D)             (None, 8, 8, 192)    399360      block8_4_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_180 (Bat (None, 8, 8, 192)    576         conv2d_180[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_180 (Activation)     (None, 8, 8, 192)    0           batch_normalization_v1_180[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_181 (Conv2D)             (None, 8, 8, 224)    129024      activation_180[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_181 (Bat (None, 8, 8, 224)    672         conv2d_181[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_181 (Activation)     (None, 8, 8, 224)    0           batch_normalization_v1_181[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_179 (Conv2D)             (None, 8, 8, 192)    399360      block8_4_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_182 (Conv2D)             (None, 8, 8, 256)    172032      activation_181[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_179 (Bat (None, 8, 8, 192)    576         conv2d_179[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_182 (Bat (None, 8, 8, 256)    768         conv2d_182[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_179 (Activation)     (None, 8, 8, 192)    0           batch_normalization_v1_179[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_182 (Activation)     (None, 8, 8, 256)    0           batch_normalization_v1_182[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "block8_5_mixed (Concatenate)    (None, 8, 8, 448)    0           activation_179[0][0]             \n",
      "                                                                 activation_182[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_5_conv (Conv2D)          (None, 8, 8, 2080)   933920      block8_5_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_5 (Lambda)               (None, 8, 8, 2080)   0           block8_4_ac[0][0]                \n",
      "                                                                 block8_5_conv[0][0]              \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "block8_5_ac (Activation)        (None, 8, 8, 2080)   0           block8_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_184 (Conv2D)             (None, 8, 8, 192)    399360      block8_5_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_184 (Bat (None, 8, 8, 192)    576         conv2d_184[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_184 (Activation)     (None, 8, 8, 192)    0           batch_normalization_v1_184[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_185 (Conv2D)             (None, 8, 8, 224)    129024      activation_184[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_185 (Bat (None, 8, 8, 224)    672         conv2d_185[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_185 (Activation)     (None, 8, 8, 224)    0           batch_normalization_v1_185[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_183 (Conv2D)             (None, 8, 8, 192)    399360      block8_5_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_186 (Conv2D)             (None, 8, 8, 256)    172032      activation_185[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_183 (Bat (None, 8, 8, 192)    576         conv2d_183[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_186 (Bat (None, 8, 8, 256)    768         conv2d_186[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_183 (Activation)     (None, 8, 8, 192)    0           batch_normalization_v1_183[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_186 (Activation)     (None, 8, 8, 256)    0           batch_normalization_v1_186[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "block8_6_mixed (Concatenate)    (None, 8, 8, 448)    0           activation_183[0][0]             \n",
      "                                                                 activation_186[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_6_conv (Conv2D)          (None, 8, 8, 2080)   933920      block8_6_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_6 (Lambda)               (None, 8, 8, 2080)   0           block8_5_ac[0][0]                \n",
      "                                                                 block8_6_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_6_ac (Activation)        (None, 8, 8, 2080)   0           block8_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_188 (Conv2D)             (None, 8, 8, 192)    399360      block8_6_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_188 (Bat (None, 8, 8, 192)    576         conv2d_188[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_188 (Activation)     (None, 8, 8, 192)    0           batch_normalization_v1_188[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_189 (Conv2D)             (None, 8, 8, 224)    129024      activation_188[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_189 (Bat (None, 8, 8, 224)    672         conv2d_189[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_189 (Activation)     (None, 8, 8, 224)    0           batch_normalization_v1_189[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_187 (Conv2D)             (None, 8, 8, 192)    399360      block8_6_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_190 (Conv2D)             (None, 8, 8, 256)    172032      activation_189[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_187 (Bat (None, 8, 8, 192)    576         conv2d_187[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_190 (Bat (None, 8, 8, 256)    768         conv2d_190[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_187 (Activation)     (None, 8, 8, 192)    0           batch_normalization_v1_187[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_190 (Activation)     (None, 8, 8, 256)    0           batch_normalization_v1_190[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "block8_7_mixed (Concatenate)    (None, 8, 8, 448)    0           activation_187[0][0]             \n",
      "                                                                 activation_190[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_7_conv (Conv2D)          (None, 8, 8, 2080)   933920      block8_7_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_7 (Lambda)               (None, 8, 8, 2080)   0           block8_6_ac[0][0]                \n",
      "                                                                 block8_7_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_7_ac (Activation)        (None, 8, 8, 2080)   0           block8_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_192 (Conv2D)             (None, 8, 8, 192)    399360      block8_7_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_192 (Bat (None, 8, 8, 192)    576         conv2d_192[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_192 (Activation)     (None, 8, 8, 192)    0           batch_normalization_v1_192[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_193 (Conv2D)             (None, 8, 8, 224)    129024      activation_192[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_193 (Bat (None, 8, 8, 224)    672         conv2d_193[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_193 (Activation)     (None, 8, 8, 224)    0           batch_normalization_v1_193[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_191 (Conv2D)             (None, 8, 8, 192)    399360      block8_7_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_194 (Conv2D)             (None, 8, 8, 256)    172032      activation_193[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_191 (Bat (None, 8, 8, 192)    576         conv2d_191[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_194 (Bat (None, 8, 8, 256)    768         conv2d_194[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_191 (Activation)     (None, 8, 8, 192)    0           batch_normalization_v1_191[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_194 (Activation)     (None, 8, 8, 256)    0           batch_normalization_v1_194[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "block8_8_mixed (Concatenate)    (None, 8, 8, 448)    0           activation_191[0][0]             \n",
      "                                                                 activation_194[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_8_conv (Conv2D)          (None, 8, 8, 2080)   933920      block8_8_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_8 (Lambda)               (None, 8, 8, 2080)   0           block8_7_ac[0][0]                \n",
      "                                                                 block8_8_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_8_ac (Activation)        (None, 8, 8, 2080)   0           block8_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_196 (Conv2D)             (None, 8, 8, 192)    399360      block8_8_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_196 (Bat (None, 8, 8, 192)    576         conv2d_196[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_196 (Activation)     (None, 8, 8, 192)    0           batch_normalization_v1_196[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_197 (Conv2D)             (None, 8, 8, 224)    129024      activation_196[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_197 (Bat (None, 8, 8, 224)    672         conv2d_197[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_197 (Activation)     (None, 8, 8, 224)    0           batch_normalization_v1_197[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_195 (Conv2D)             (None, 8, 8, 192)    399360      block8_8_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_198 (Conv2D)             (None, 8, 8, 256)    172032      activation_197[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_195 (Bat (None, 8, 8, 192)    576         conv2d_195[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_198 (Bat (None, 8, 8, 256)    768         conv2d_198[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_195 (Activation)     (None, 8, 8, 192)    0           batch_normalization_v1_195[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_198 (Activation)     (None, 8, 8, 256)    0           batch_normalization_v1_198[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "block8_9_mixed (Concatenate)    (None, 8, 8, 448)    0           activation_195[0][0]             \n",
      "                                                                 activation_198[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_9_conv (Conv2D)          (None, 8, 8, 2080)   933920      block8_9_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_9 (Lambda)               (None, 8, 8, 2080)   0           block8_8_ac[0][0]                \n",
      "                                                                 block8_9_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_9_ac (Activation)        (None, 8, 8, 2080)   0           block8_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_200 (Conv2D)             (None, 8, 8, 192)    399360      block8_9_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_200 (Bat (None, 8, 8, 192)    576         conv2d_200[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_200 (Activation)     (None, 8, 8, 192)    0           batch_normalization_v1_200[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_201 (Conv2D)             (None, 8, 8, 224)    129024      activation_200[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_201 (Bat (None, 8, 8, 224)    672         conv2d_201[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_201 (Activation)     (None, 8, 8, 224)    0           batch_normalization_v1_201[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_199 (Conv2D)             (None, 8, 8, 192)    399360      block8_9_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_202 (Conv2D)             (None, 8, 8, 256)    172032      activation_201[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_199 (Bat (None, 8, 8, 192)    576         conv2d_199[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_202 (Bat (None, 8, 8, 256)    768         conv2d_202[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_199 (Activation)     (None, 8, 8, 192)    0           batch_normalization_v1_199[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_202 (Activation)     (None, 8, 8, 256)    0           batch_normalization_v1_202[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "block8_10_mixed (Concatenate)   (None, 8, 8, 448)    0           activation_199[0][0]             \n",
      "                                                                 activation_202[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_10_conv (Conv2D)         (None, 8, 8, 2080)   933920      block8_10_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block8_10 (Lambda)              (None, 8, 8, 2080)   0           block8_9_ac[0][0]                \n",
      "                                                                 block8_10_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d (Globa (None, 2080)         0           block8_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            2081        global_average_pooling2d[0][0]   \n",
      "==================================================================================================\n",
      "Total params: 51,139,329\n",
      "Trainable params: 51,081,857\n",
      "Non-trainable params: 57,472\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "# without FAKE images + Mobilenet pretrain\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from codes.data.train_model import train_and_test_model,train_and_test_model_by_load_data\n",
    "from codes.data.create_dataset_01 import create_dataset,load_dataset\n",
    "\n",
    "from codes.model.resnetv2 import build_InceptionResNetV2_pretrain\n",
    "\n",
    " \n",
    "model = build_InceptionResNetV2_pretrain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0/5] [Batch 0/346] [T loss: 1.063473, acc:  43%] time: 0:05:32.511492\n",
      "[Epoch 0/5] [Batch 20/346] [T loss: 0.400999, acc:  81%] time: 0:05:49.368597\n",
      "[Epoch 0/5] [Batch 40/346] [T loss: 0.503156, acc:  75%] time: 0:06:06.348030\n",
      "[Epoch 0/5] [Batch 60/346] [T loss: 0.538118, acc:  87%] time: 0:06:23.035188\n",
      "[Epoch 0/5] [Batch 80/346] [T loss: 0.367850, acc:  87%] time: 0:06:39.701080\n",
      "[Epoch 0/5] [Batch 100/346] [T loss: 0.861992, acc:  75%] time: 0:06:56.445344\n",
      "[Epoch 0/5] [Batch 120/346] [T loss: 0.777251, acc:  68%] time: 0:07:13.139903\n",
      "[Epoch 0/5] [Batch 140/346] [T loss: 0.212248, acc:  93%] time: 0:07:29.832506\n",
      "[Epoch 0/5] [Batch 160/346] [T loss: 0.226095, acc:  93%] time: 0:07:46.531015\n",
      "[Epoch 0/5] [Batch 180/346] [T loss: 0.162763, acc:  93%] time: 0:08:03.236665\n",
      "[Epoch 0/5] [Batch 200/346] [T loss: 0.060898, acc: 100%] time: 0:08:19.885709\n",
      "[Epoch 0/5] [Batch 220/346] [T loss: 0.221085, acc:  93%] time: 0:08:36.577770\n",
      "[Epoch 0/5] [Batch 240/346] [T loss: 0.310838, acc:  87%] time: 0:08:53.282464\n",
      "[Epoch 0/5] [Batch 260/346] [T loss: 0.016915, acc: 100%] time: 0:09:09.924104\n",
      "[Epoch 0/5] [Batch 280/346] [T loss: 0.308087, acc:  93%] time: 0:09:26.567902\n",
      "[Epoch 0/5] [Batch 300/346] [T loss: 0.082097, acc: 100%] time: 0:09:43.270675\n",
      "[Epoch 0/5] [Batch 320/346] [T loss: 0.042734, acc:  93%] time: 0:10:00.007640\n",
      "[Epoch 0/5] [Batch 340/346] [T loss: 0.122361, acc:  93%] time: 0:10:16.710398\n",
      "[Total testing images: 50 ] [2 class accuracy 88.0%] [40:44/50][100:0/0][200:0/0][400:0/0]\n",
      "[Total testing images: 100 ] [2 class accuracy 84.0%] [40:84/100][100:0/0][200:0/0][400:0/0]\n",
      "[Total testing images: 150 ] [2 class accuracy 87.33333333333333%] [40:131/150][100:0/0][200:0/0][400:0/0]\n",
      "[Total testing images: 200 ] [2 class accuracy 85.5%] [40:171/200][100:0/0][200:0/0][400:0/0]\n",
      "[Total testing images: 250 ] [2 class accuracy 85.2%] [40:213/250][100:0/0][200:0/0][400:0/0]\n",
      "[Total testing images: 300 ] [2 class accuracy 86.33333333333333%] [40:259/300][100:0/0][200:0/0][400:0/0]\n",
      "[Total testing images: 350 ] [2 class accuracy 86.28571428571429%] [40:302/350][100:0/0][200:0/0][400:0/0]\n",
      "[Total testing images: 400 ] [2 class accuracy 86.25%] [40:345/400][100:0/0][200:0/0][400:0/0]\n",
      "[Total testing images: 450 ] [2 class accuracy 86.0%] [40:387/450][100:0/0][200:0/0][400:0/0]\n",
      "[Total testing images: 500 ] [2 class accuracy 85.2%] [40:426/500][100:0/0][200:0/0][400:0/0]\n",
      "[Total testing images: 550 ] [2 class accuracy 84.72727272727273%] [40:466/550][100:0/0][200:0/0][400:0/0]\n",
      "[Total testing images: 600 ] [2 class accuracy 84.66666666666667%] [40:507/599][100:1/1][200:0/0][400:0/0]\n",
      "[Total testing images: 650 ] [2 class accuracy 84.92307692307692%] [40:507/599][100:45/51][200:0/0][400:0/0]\n",
      "[Total testing images: 700 ] [2 class accuracy 85.57142857142857%] [40:507/599][100:92/101][200:0/0][400:0/0]\n",
      "[Total testing images: 750 ] [2 class accuracy 86.0%] [40:507/599][100:138/151][200:0/0][400:0/0]\n",
      "[Total testing images: 800 ] [2 class accuracy 86.375%] [40:507/599][100:184/201][200:0/0][400:0/0]\n",
      "[Total testing images: 850 ] [2 class accuracy 86.23529411764706%] [40:507/599][100:226/251][200:0/0][400:0/0]\n",
      "[Total testing images: 900 ] [2 class accuracy 86.33333333333333%] [40:507/599][100:270/301][200:0/0][400:0/0]\n",
      "[Total testing images: 950 ] [2 class accuracy 86.31578947368422%] [40:507/599][100:313/351][200:0/0][400:0/0]\n",
      "[Total testing images: 1000 ] [2 class accuracy 86.7%] [40:507/599][100:360/401][200:0/0][400:0/0]\n",
      "[Total testing images: 1050 ] [2 class accuracy 86.76190476190476%] [40:507/599][100:404/451][200:0/0][400:0/0]\n",
      "[Total testing images: 1100 ] [2 class accuracy 86.54545454545455%] [40:507/599][100:445/501][200:0/0][400:0/0]\n",
      "[Total testing images: 1150 ] [2 class accuracy 86.52173913043478%] [40:507/599][100:488/551][200:0/0][400:0/0]\n",
      "[Total testing images: 1200 ] [2 class accuracy 86.66666666666667%] [40:507/599][100:533/601][200:0/0][400:0/0]\n",
      "[Total testing images: 1250 ] [2 class accuracy 86.96000000000001%] [40:507/599][100:556/625][200:24/26][400:0/0]\n",
      "[Total testing images: 1300 ] [2 class accuracy 86.92307692307692%] [40:507/599][100:556/625][200:67/76][400:0/0]\n",
      "[Total testing images: 1350 ] [2 class accuracy 86.96296296296296%] [40:507/599][100:556/625][200:111/126][400:0/0]\n",
      "[Total testing images: 1400 ] [2 class accuracy 87.14285714285714%] [40:507/599][100:556/625][200:157/176][400:0/0]\n",
      "[Total testing images: 1450 ] [2 class accuracy 87.24137931034483%] [40:507/599][100:556/625][200:202/226][400:0/0]\n",
      "[Total testing images: 1500 ] [2 class accuracy 87.33333333333333%] [40:507/599][100:556/625][200:247/276][400:0/0]\n",
      "[Total testing images: 1550 ] [2 class accuracy 87.48387096774194%] [40:507/599][100:556/625][200:293/326][400:0/0]\n",
      "[Total testing images: 1600 ] [2 class accuracy 87.375%] [40:507/599][100:556/625][200:335/376][400:0/0]\n",
      "[Total testing images: 1650 ] [2 class accuracy 87.33333333333333%] [40:507/599][100:556/625][200:378/426][400:0/0]\n",
      "[Total testing images: 1700 ] [2 class accuracy 87.17647058823529%] [40:507/599][100:556/625][200:419/476][400:0/0]\n",
      "[Total testing images: 1750 ] [2 class accuracy 87.4857142857143%] [40:507/599][100:556/625][200:468/526][400:0/0]\n",
      "[Total testing images: 1800 ] [2 class accuracy 87.33333333333333%] [40:507/599][100:556/625][200:509/576][400:0/0]\n",
      "[Total testing images: 1850 ] [2 class accuracy 87.35135135135135%] [40:507/599][100:556/625][200:534/604][400:19/22]\n",
      "[Total testing images: 1900 ] [2 class accuracy 87.31578947368422%] [40:507/599][100:556/625][200:534/604][400:62/72]\n",
      "[Total testing images: 1950 ] [2 class accuracy 87.28205128205128%] [40:507/599][100:556/625][200:534/604][400:105/122]\n",
      "[Total testing images: 2000 ] [2 class accuracy 86.95%] [40:507/599][100:556/625][200:534/604][400:142/172]\n",
      "[Total testing images: 2050 ] [2 class accuracy 86.97560975609755%] [40:507/599][100:556/625][200:534/604][400:186/222]\n",
      "[Total testing images: 2100 ] [2 class accuracy 87.0%] [40:507/599][100:556/625][200:534/604][400:230/272]\n",
      "[Total testing images: 2150 ] [2 class accuracy 87.16279069767442%] [40:507/599][100:556/625][200:534/604][400:277/322]\n",
      "[Total testing images: 2200 ] [2 class accuracy 87.04545454545455%] [40:507/599][100:556/625][200:534/604][400:318/372]\n",
      "[Total testing images: 2250 ] [2 class accuracy 87.1111111111111%] [40:507/599][100:556/625][200:534/604][400:363/422]\n",
      "[Total testing images: 2300 ] [2 class accuracy 87.04347826086956%] [40:507/599][100:556/625][200:534/604][400:405/472]\n",
      "[Total testing images: 2350 ] [2 class accuracy 87.06382978723404%] [40:507/599][100:556/625][200:534/604][400:449/522]\n",
      "[Epoch 1/5] [Batch 0/346] [T loss: 0.119687, acc:  93%] time: 0:13:20.043832\n",
      "[Epoch 1/5] [Batch 20/346] [T loss: 0.266010, acc:  81%] time: 0:13:36.781263\n",
      "[Epoch 1/5] [Batch 40/346] [T loss: 0.320386, acc:  81%] time: 0:13:53.935783\n",
      "[Epoch 1/5] [Batch 60/346] [T loss: 0.271584, acc:  87%] time: 0:14:10.606904\n",
      "[Epoch 1/5] [Batch 80/346] [T loss: 0.164851, acc:  93%] time: 0:14:27.238619\n",
      "[Epoch 1/5] [Batch 100/346] [T loss: 0.069870, acc:  93%] time: 0:14:43.862779\n",
      "[Epoch 1/5] [Batch 120/346] [T loss: 0.245522, acc:  87%] time: 0:15:00.563025\n",
      "[Epoch 1/5] [Batch 140/346] [T loss: 0.734401, acc:  62%] time: 0:15:17.243817\n",
      "[Epoch 1/5] [Batch 160/346] [T loss: 0.393830, acc:  87%] time: 0:15:33.885351\n",
      "[Epoch 1/5] [Batch 180/346] [T loss: 0.026701, acc: 100%] time: 0:15:50.596964\n",
      "[Epoch 1/5] [Batch 200/346] [T loss: 0.163272, acc:  93%] time: 0:16:07.278624\n",
      "[Epoch 1/5] [Batch 220/346] [T loss: 0.174076, acc:  93%] time: 0:16:23.957336\n",
      "[Epoch 1/5] [Batch 240/346] [T loss: 0.060346, acc: 100%] time: 0:16:40.709340\n",
      "[Epoch 1/5] [Batch 260/346] [T loss: 0.195094, acc:  87%] time: 0:16:57.428687\n",
      "[Epoch 1/5] [Batch 280/346] [T loss: 0.206529, acc:  93%] time: 0:17:14.096204\n",
      "[Epoch 1/5] [Batch 300/346] [T loss: 0.193944, acc:  87%] time: 0:17:30.767653\n",
      "[Epoch 1/5] [Batch 320/346] [T loss: 0.385700, acc:  87%] time: 0:17:47.415295\n",
      "[Epoch 1/5] [Batch 340/346] [T loss: 0.051865, acc:  93%] time: 0:18:04.062701\n",
      "[Total testing images: 50 ] [2 class accuracy 98.0%] [40:49/50][100:0/0][200:0/0][400:0/0]\n",
      "[Total testing images: 100 ] [2 class accuracy 89.0%] [40:89/100][100:0/0][200:0/0][400:0/0]\n",
      "[Total testing images: 150 ] [2 class accuracy 89.33333333333333%] [40:134/150][100:0/0][200:0/0][400:0/0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Total testing images: 200 ] [2 class accuracy 91.0%] [40:182/200][100:0/0][200:0/0][400:0/0]\n",
      "[Total testing images: 250 ] [2 class accuracy 90.0%] [40:225/250][100:0/0][200:0/0][400:0/0]\n",
      "[Total testing images: 300 ] [2 class accuracy 88.66666666666667%] [40:266/300][100:0/0][200:0/0][400:0/0]\n",
      "[Total testing images: 350 ] [2 class accuracy 88.57142857142857%] [40:310/350][100:0/0][200:0/0][400:0/0]\n",
      "[Total testing images: 400 ] [2 class accuracy 89.0%] [40:356/400][100:0/0][200:0/0][400:0/0]\n",
      "[Total testing images: 450 ] [2 class accuracy 88.88888888888889%] [40:400/450][100:0/0][200:0/0][400:0/0]\n",
      "[Total testing images: 500 ] [2 class accuracy 88.0%] [40:440/500][100:0/0][200:0/0][400:0/0]\n",
      "[Total testing images: 550 ] [2 class accuracy 88.0%] [40:484/550][100:0/0][200:0/0][400:0/0]\n",
      "[Total testing images: 600 ] [2 class accuracy 87.83333333333333%] [40:526/599][100:1/1][200:0/0][400:0/0]\n",
      "[Total testing images: 650 ] [2 class accuracy 88.0%] [40:526/599][100:46/51][200:0/0][400:0/0]\n",
      "[Total testing images: 700 ] [2 class accuracy 88.85714285714286%] [40:526/599][100:96/101][200:0/0][400:0/0]\n",
      "[Total testing images: 750 ] [2 class accuracy 88.93333333333334%] [40:526/599][100:141/151][200:0/0][400:0/0]\n",
      "[Total testing images: 800 ] [2 class accuracy 89.25%] [40:526/599][100:188/201][200:0/0][400:0/0]\n",
      "[Total testing images: 850 ] [2 class accuracy 89.41176470588236%] [40:526/599][100:234/251][200:0/0][400:0/0]\n",
      "[Total testing images: 900 ] [2 class accuracy 89.77777777777777%] [40:526/599][100:282/301][200:0/0][400:0/0]\n",
      "[Total testing images: 950 ] [2 class accuracy 90.21052631578948%] [40:526/599][100:331/351][200:0/0][400:0/0]\n",
      "[Total testing images: 1000 ] [2 class accuracy 90.3%] [40:526/599][100:377/401][200:0/0][400:0/0]\n",
      "[Total testing images: 1050 ] [2 class accuracy 90.38095238095238%] [40:526/599][100:423/451][200:0/0][400:0/0]\n",
      "[Total testing images: 1100 ] [2 class accuracy 90.36363636363637%] [40:526/599][100:468/501][200:0/0][400:0/0]\n",
      "[Total testing images: 1150 ] [2 class accuracy 90.34782608695652%] [40:526/599][100:513/551][200:0/0][400:0/0]\n",
      "[Total testing images: 1200 ] [2 class accuracy 90.75%] [40:526/599][100:563/601][200:0/0][400:0/0]\n",
      "[Total testing images: 1250 ] [2 class accuracy 90.96%] [40:526/599][100:585/625][200:26/26][400:0/0]\n",
      "[Total testing images: 1300 ] [2 class accuracy 91.0%] [40:526/599][100:585/625][200:72/76][400:0/0]\n",
      "[Total testing images: 1350 ] [2 class accuracy 90.96296296296296%] [40:526/599][100:585/625][200:117/126][400:0/0]\n",
      "[Total testing images: 1400 ] [2 class accuracy 91.14285714285715%] [40:526/599][100:585/625][200:165/176][400:0/0]\n",
      "[Total testing images: 1450 ] [2 class accuracy 91.3103448275862%] [40:526/599][100:585/625][200:213/226][400:0/0]\n",
      "[Total testing images: 1500 ] [2 class accuracy 91.46666666666667%] [40:526/599][100:585/625][200:261/276][400:0/0]\n",
      "[Total testing images: 1550 ] [2 class accuracy 91.6774193548387%] [40:526/599][100:585/625][200:310/326][400:0/0]\n",
      "[Total testing images: 1600 ] [2 class accuracy 91.5625%] [40:526/599][100:585/625][200:354/376][400:0/0]\n",
      "[Total testing images: 1650 ] [2 class accuracy 91.51515151515152%] [40:526/599][100:585/625][200:399/426][400:0/0]\n",
      "[Total testing images: 1700 ] [2 class accuracy 91.41176470588235%] [40:526/599][100:585/625][200:443/476][400:0/0]\n",
      "[Total testing images: 1750 ] [2 class accuracy 91.48571428571428%] [40:526/599][100:585/625][200:490/526][400:0/0]\n",
      "[Total testing images: 1800 ] [2 class accuracy 91.44444444444444%] [40:526/599][100:585/625][200:535/576][400:0/0]\n",
      "[Total testing images: 1850 ] [2 class accuracy 91.4054054054054%] [40:526/599][100:585/625][200:560/604][400:20/22]\n",
      "[Total testing images: 1900 ] [2 class accuracy 91.3157894736842%] [40:526/599][100:585/625][200:560/604][400:64/72]\n",
      "[Total testing images: 1950 ] [2 class accuracy 91.17948717948718%] [40:526/599][100:585/625][200:560/604][400:107/122]\n",
      "[Total testing images: 2000 ] [2 class accuracy 91.3%] [40:526/599][100:585/625][200:560/604][400:155/172]\n",
      "[Total testing images: 2050 ] [2 class accuracy 91.31707317073172%] [40:526/599][100:585/625][200:560/604][400:201/222]\n",
      "[Total testing images: 2100 ] [2 class accuracy 91.42857142857143%] [40:526/599][100:585/625][200:560/604][400:249/272]\n",
      "[Total testing images: 2150 ] [2 class accuracy 91.44186046511628%] [40:526/599][100:585/625][200:560/604][400:295/322]\n",
      "[Total testing images: 2200 ] [2 class accuracy 91.4090909090909%] [40:526/599][100:585/625][200:560/604][400:340/372]\n",
      "[Total testing images: 2250 ] [2 class accuracy 91.28888888888889%] [40:526/599][100:585/625][200:560/604][400:383/422]\n",
      "[Total testing images: 2300 ] [2 class accuracy 91.39130434782608%] [40:526/599][100:585/625][200:560/604][400:431/472]\n",
      "[Total testing images: 2350 ] [2 class accuracy 91.40425531914894%] [40:526/599][100:585/625][200:560/604][400:477/522]\n",
      "[Epoch 2/5] [Batch 0/346] [T loss: 0.042359, acc: 100%] time: 0:20:51.565012\n",
      "[Epoch 2/5] [Batch 20/346] [T loss: 0.178812, acc:  93%] time: 0:21:08.205290\n",
      "[Epoch 2/5] [Batch 40/346] [T loss: 0.094164, acc: 100%] time: 0:21:25.126287\n",
      "[Epoch 2/5] [Batch 60/346] [T loss: 0.265183, acc:  87%] time: 0:21:41.759950\n",
      "[Epoch 2/5] [Batch 80/346] [T loss: 0.565038, acc:  75%] time: 0:21:58.411076\n",
      "[Epoch 2/5] [Batch 100/346] [T loss: 0.546355, acc:  81%] time: 0:22:15.067841\n",
      "[Epoch 2/5] [Batch 120/346] [T loss: 0.020911, acc: 100%] time: 0:22:31.730072\n",
      "[Epoch 2/5] [Batch 140/346] [T loss: 0.182954, acc:  93%] time: 0:22:48.387889\n",
      "[Epoch 2/5] [Batch 160/346] [T loss: 0.235244, acc:  87%] time: 0:23:05.053912\n",
      "[Epoch 2/5] [Batch 180/346] [T loss: 0.175247, acc:  93%] time: 0:23:21.724487\n",
      "[Epoch 2/5] [Batch 200/346] [T loss: 0.097176, acc: 100%] time: 0:23:38.391041\n",
      "[Epoch 2/5] [Batch 220/346] [T loss: 0.369768, acc:  87%] time: 0:23:55.018834\n",
      "[Epoch 2/5] [Batch 240/346] [T loss: 0.152831, acc:  93%] time: 0:24:11.702422\n",
      "[Epoch 2/5] [Batch 260/346] [T loss: 0.324675, acc:  87%] time: 0:24:28.359128\n",
      "[Epoch 2/5] [Batch 280/346] [T loss: 0.142794, acc:  93%] time: 0:24:44.974508\n",
      "[Epoch 2/5] [Batch 300/346] [T loss: 0.185983, acc:  93%] time: 0:25:01.623659\n",
      "[Epoch 2/5] [Batch 320/346] [T loss: 0.247299, acc:  81%] time: 0:25:18.339061\n",
      "[Epoch 2/5] [Batch 340/346] [T loss: 0.095352, acc:  93%] time: 0:25:35.052120\n",
      "[Total testing images: 50 ] [2 class accuracy 84.0%] [40:42/50][100:0/0][200:0/0][400:0/0]\n",
      "[Total testing images: 100 ] [2 class accuracy 83.0%] [40:83/100][100:0/0][200:0/0][400:0/0]\n",
      "[Total testing images: 150 ] [2 class accuracy 82.0%] [40:123/150][100:0/0][200:0/0][400:0/0]\n",
      "[Total testing images: 200 ] [2 class accuracy 83.5%] [40:167/200][100:0/0][200:0/0][400:0/0]\n",
      "[Total testing images: 250 ] [2 class accuracy 82.8%] [40:207/250][100:0/0][200:0/0][400:0/0]\n",
      "[Total testing images: 300 ] [2 class accuracy 83.0%] [40:249/300][100:0/0][200:0/0][400:0/0]\n",
      "[Total testing images: 350 ] [2 class accuracy 83.71428571428572%] [40:293/350][100:0/0][200:0/0][400:0/0]\n",
      "[Total testing images: 400 ] [2 class accuracy 85.0%] [40:340/400][100:0/0][200:0/0][400:0/0]\n",
      "[Total testing images: 450 ] [2 class accuracy 85.55555555555556%] [40:385/450][100:0/0][200:0/0][400:0/0]\n",
      "[Total testing images: 500 ] [2 class accuracy 85.6%] [40:428/500][100:0/0][200:0/0][400:0/0]\n",
      "[Total testing images: 550 ] [2 class accuracy 85.45454545454545%] [40:470/550][100:0/0][200:0/0][400:0/0]\n",
      "[Total testing images: 600 ] [2 class accuracy 85.83333333333333%] [40:515/599][100:0/1][200:0/0][400:0/0]\n",
      "[Total testing images: 650 ] [2 class accuracy 85.6923076923077%] [40:515/599][100:42/51][200:0/0][400:0/0]\n",
      "[Total testing images: 700 ] [2 class accuracy 85.57142857142857%] [40:515/599][100:84/101][200:0/0][400:0/0]\n",
      "[Total testing images: 750 ] [2 class accuracy 85.46666666666667%] [40:515/599][100:126/151][200:0/0][400:0/0]\n",
      "[Total testing images: 800 ] [2 class accuracy 86.125%] [40:515/599][100:174/201][200:0/0][400:0/0]\n",
      "[Total testing images: 850 ] [2 class accuracy 85.76470588235294%] [40:515/599][100:214/251][200:0/0][400:0/0]\n",
      "[Total testing images: 900 ] [2 class accuracy 85.88888888888889%] [40:515/599][100:258/301][200:0/0][400:0/0]\n",
      "[Total testing images: 950 ] [2 class accuracy 85.68421052631578%] [40:515/599][100:299/351][200:0/0][400:0/0]\n",
      "[Total testing images: 1000 ] [2 class accuracy 85.5%] [40:515/599][100:340/401][200:0/0][400:0/0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Total testing images: 1050 ] [2 class accuracy 85.23809523809524%] [40:515/599][100:380/451][200:0/0][400:0/0]\n",
      "[Total testing images: 1100 ] [2 class accuracy 85.45454545454545%] [40:515/599][100:425/501][200:0/0][400:0/0]\n",
      "[Total testing images: 1150 ] [2 class accuracy 85.30434782608695%] [40:515/599][100:466/551][200:0/0][400:0/0]\n",
      "[Total testing images: 1200 ] [2 class accuracy 85.08333333333333%] [40:515/599][100:506/601][200:0/0][400:0/0]\n",
      "[Total testing images: 1250 ] [2 class accuracy 84.96000000000001%] [40:515/599][100:525/625][200:22/26][400:0/0]\n",
      "[Total testing images: 1300 ] [2 class accuracy 85.0%] [40:515/599][100:525/625][200:65/76][400:0/0]\n",
      "[Total testing images: 1350 ] [2 class accuracy 85.18518518518519%] [40:515/599][100:525/625][200:110/126][400:0/0]\n",
      "[Total testing images: 1400 ] [2 class accuracy 85.35714285714285%] [40:515/599][100:525/625][200:155/176][400:0/0]\n",
      "[Total testing images: 1450 ] [2 class accuracy 85.17241379310346%] [40:515/599][100:525/625][200:195/226][400:0/0]\n",
      "[Total testing images: 1500 ] [2 class accuracy 84.93333333333334%] [40:515/599][100:525/625][200:234/276][400:0/0]\n",
      "[Total testing images: 1550 ] [2 class accuracy 85.09677419354838%] [40:515/599][100:525/625][200:279/326][400:0/0]\n",
      "[Total testing images: 1600 ] [2 class accuracy 85.125%] [40:515/599][100:525/625][200:322/376][400:0/0]\n",
      "[Total testing images: 1650 ] [2 class accuracy 85.27272727272728%] [40:515/599][100:525/625][200:367/426][400:0/0]\n",
      "[Total testing images: 1700 ] [2 class accuracy 85.0%] [40:515/599][100:525/625][200:405/476][400:0/0]\n",
      "[Total testing images: 1750 ] [2 class accuracy 85.14285714285714%] [40:515/599][100:525/625][200:450/526][400:0/0]\n",
      "[Total testing images: 1800 ] [2 class accuracy 85.11111111111111%] [40:515/599][100:525/625][200:492/576][400:0/0]\n",
      "[Total testing images: 1850 ] [2 class accuracy 85.02702702702703%] [40:515/599][100:525/625][200:516/604][400:17/22]\n",
      "[Total testing images: 1900 ] [2 class accuracy 84.84210526315789%] [40:515/599][100:525/625][200:516/604][400:56/72]\n",
      "[Total testing images: 1950 ] [2 class accuracy 84.82051282051282%] [40:515/599][100:525/625][200:516/604][400:98/122]\n",
      "[Total testing images: 2000 ] [2 class accuracy 85.05%] [40:515/599][100:525/625][200:516/604][400:145/172]\n",
      "[Total testing images: 2050 ] [2 class accuracy 84.82926829268293%] [40:515/599][100:525/625][200:516/604][400:183/222]\n",
      "[Total testing images: 2100 ] [2 class accuracy 84.9047619047619%] [40:515/599][100:525/625][200:516/604][400:227/272]\n",
      "[Total testing images: 2150 ] [2 class accuracy 84.7906976744186%] [40:515/599][100:525/625][200:516/604][400:267/322]\n",
      "[Total testing images: 2200 ] [2 class accuracy 84.86363636363636%] [40:515/599][100:525/625][200:516/604][400:311/372]\n",
      "[Total testing images: 2250 ] [2 class accuracy 84.97777777777777%] [40:515/599][100:525/625][200:516/604][400:356/422]\n",
      "[Total testing images: 2300 ] [2 class accuracy 84.86956521739131%] [40:515/599][100:525/625][200:516/604][400:396/472]\n",
      "[Total testing images: 2350 ] [2 class accuracy 84.8936170212766%] [40:515/599][100:525/625][200:516/604][400:439/522]\n",
      "[Epoch 3/5] [Batch 0/346] [T loss: 0.201763, acc:  93%] time: 0:28:22.067327\n",
      "[Epoch 3/5] [Batch 20/346] [T loss: 0.002670, acc: 100%] time: 0:28:38.779444\n",
      "[Epoch 3/5] [Batch 40/346] [T loss: 0.355587, acc:  87%] time: 0:28:55.467286\n",
      "[Epoch 3/5] [Batch 60/346] [T loss: 0.215951, acc:  93%] time: 0:29:12.106111\n",
      "[Epoch 3/5] [Batch 80/346] [T loss: 0.150195, acc:  93%] time: 0:29:28.829565\n",
      "[Epoch 3/5] [Batch 100/346] [T loss: 0.042961, acc:  93%] time: 0:29:45.511633\n",
      "[Epoch 3/5] [Batch 120/346] [T loss: 0.110052, acc:  93%] time: 0:30:02.234440\n",
      "[Epoch 3/5] [Batch 140/346] [T loss: 0.129589, acc:  93%] time: 0:30:18.889909\n",
      "[Epoch 3/5] [Batch 160/346] [T loss: 0.002781, acc: 100%] time: 0:30:35.579256\n",
      "[Epoch 3/5] [Batch 180/346] [T loss: 0.150769, acc:  93%] time: 0:30:52.230187\n",
      "[Epoch 3/5] [Batch 200/346] [T loss: 0.224642, acc:  93%] time: 0:31:08.897720\n",
      "[Epoch 3/5] [Batch 220/346] [T loss: 0.042603, acc: 100%] time: 0:31:25.535328\n",
      "[Epoch 3/5] [Batch 240/346] [T loss: 0.315118, acc:  81%] time: 0:31:42.189328\n",
      "[Epoch 3/5] [Batch 260/346] [T loss: 0.007723, acc: 100%] time: 0:31:58.867898\n",
      "[Epoch 3/5] [Batch 280/346] [T loss: 0.038101, acc:  93%] time: 0:32:15.564784\n",
      "[Epoch 3/5] [Batch 300/346] [T loss: 0.012034, acc: 100%] time: 0:32:32.215557\n",
      "[Epoch 3/5] [Batch 320/346] [T loss: 0.039933, acc: 100%] time: 0:32:48.944284\n",
      "[Epoch 3/5] [Batch 340/346] [T loss: 0.017705, acc: 100%] time: 0:33:05.614185\n",
      "[Total testing images: 50 ] [2 class accuracy 88.0%] [40:44/50][100:0/0][200:0/0][400:0/0]\n",
      "[Total testing images: 100 ] [2 class accuracy 86.0%] [40:86/100][100:0/0][200:0/0][400:0/0]\n",
      "[Total testing images: 150 ] [2 class accuracy 86.66666666666667%] [40:130/150][100:0/0][200:0/0][400:0/0]\n",
      "[Total testing images: 200 ] [2 class accuracy 86.0%] [40:172/200][100:0/0][200:0/0][400:0/0]\n",
      "[Total testing images: 250 ] [2 class accuracy 85.2%] [40:213/250][100:0/0][200:0/0][400:0/0]\n",
      "[Total testing images: 300 ] [2 class accuracy 84.0%] [40:252/300][100:0/0][200:0/0][400:0/0]\n",
      "[Total testing images: 350 ] [2 class accuracy 84.57142857142857%] [40:296/350][100:0/0][200:0/0][400:0/0]\n",
      "[Total testing images: 400 ] [2 class accuracy 84.25%] [40:337/400][100:0/0][200:0/0][400:0/0]\n",
      "[Total testing images: 450 ] [2 class accuracy 84.88888888888889%] [40:382/450][100:0/0][200:0/0][400:0/0]\n",
      "[Total testing images: 500 ] [2 class accuracy 85.0%] [40:425/500][100:0/0][200:0/0][400:0/0]\n",
      "[Total testing images: 550 ] [2 class accuracy 84.54545454545455%] [40:465/550][100:0/0][200:0/0][400:0/0]\n",
      "[Total testing images: 600 ] [2 class accuracy 84.66666666666667%] [40:507/599][100:1/1][200:0/0][400:0/0]\n",
      "[Total testing images: 650 ] [2 class accuracy 84.46153846153847%] [40:507/599][100:42/51][200:0/0][400:0/0]\n",
      "[Total testing images: 700 ] [2 class accuracy 83.28571428571429%] [40:507/599][100:76/101][200:0/0][400:0/0]\n",
      "[Total testing images: 750 ] [2 class accuracy 82.66666666666667%] [40:507/599][100:113/151][200:0/0][400:0/0]\n",
      "[Total testing images: 800 ] [2 class accuracy 82.75%] [40:507/599][100:155/201][200:0/0][400:0/0]\n",
      "[Total testing images: 850 ] [2 class accuracy 83.17647058823529%] [40:507/599][100:200/251][200:0/0][400:0/0]\n",
      "[Total testing images: 900 ] [2 class accuracy 83.44444444444444%] [40:507/599][100:244/301][200:0/0][400:0/0]\n",
      "[Total testing images: 950 ] [2 class accuracy 83.57894736842105%] [40:507/599][100:287/351][200:0/0][400:0/0]\n",
      "[Total testing images: 1000 ] [2 class accuracy 83.2%] [40:507/599][100:325/401][200:0/0][400:0/0]\n",
      "[Total testing images: 1050 ] [2 class accuracy 83.04761904761905%] [40:507/599][100:365/451][200:0/0][400:0/0]\n",
      "[Total testing images: 1100 ] [2 class accuracy 82.63636363636364%] [40:507/599][100:402/501][200:0/0][400:0/0]\n",
      "[Total testing images: 1150 ] [2 class accuracy 82.78260869565217%] [40:507/599][100:445/551][200:0/0][400:0/0]\n",
      "[Total testing images: 1200 ] [2 class accuracy 83.16666666666667%] [40:507/599][100:491/601][200:0/0][400:0/0]\n",
      "[Total testing images: 1250 ] [2 class accuracy 83.12%] [40:507/599][100:510/625][200:22/26][400:0/0]\n",
      "[Total testing images: 1300 ] [2 class accuracy 83.53846153846153%] [40:507/599][100:510/625][200:69/76][400:0/0]\n",
      "[Total testing images: 1350 ] [2 class accuracy 83.4074074074074%] [40:507/599][100:510/625][200:109/126][400:0/0]\n",
      "[Total testing images: 1400 ] [2 class accuracy 83.71428571428572%] [40:507/599][100:510/625][200:155/176][400:0/0]\n",
      "[Total testing images: 1450 ] [2 class accuracy 83.72413793103448%] [40:507/599][100:510/625][200:197/226][400:0/0]\n",
      "[Total testing images: 1500 ] [2 class accuracy 84.13333333333334%] [40:507/599][100:510/625][200:245/276][400:0/0]\n",
      "[Total testing images: 1550 ] [2 class accuracy 84.38709677419355%] [40:507/599][100:510/625][200:291/326][400:0/0]\n",
      "[Total testing images: 1600 ] [2 class accuracy 84.625%] [40:507/599][100:510/625][200:337/376][400:0/0]\n",
      "[Total testing images: 1650 ] [2 class accuracy 84.84848484848484%] [40:507/599][100:510/625][200:383/426][400:0/0]\n",
      "[Total testing images: 1700 ] [2 class accuracy 84.76470588235294%] [40:507/599][100:510/625][200:424/476][400:0/0]\n",
      "[Total testing images: 1750 ] [2 class accuracy 84.8%] [40:507/599][100:510/625][200:467/526][400:0/0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Total testing images: 1800 ] [2 class accuracy 85.0%] [40:507/599][100:510/625][200:513/576][400:0/0]\n",
      "[Total testing images: 1850 ] [2 class accuracy 85.18918918918918%] [40:507/599][100:510/625][200:539/604][400:20/22]\n",
      "[Total testing images: 1900 ] [2 class accuracy 85.21052631578947%] [40:507/599][100:510/625][200:539/604][400:63/72]\n",
      "[Total testing images: 1950 ] [2 class accuracy 85.38461538461539%] [40:507/599][100:510/625][200:539/604][400:109/122]\n",
      "[Total testing images: 2000 ] [2 class accuracy 85.45%] [40:507/599][100:510/625][200:539/604][400:153/172]\n",
      "[Total testing images: 2050 ] [2 class accuracy 85.51219512195122%] [40:507/599][100:510/625][200:539/604][400:197/222]\n",
      "[Total testing images: 2100 ] [2 class accuracy 85.66666666666667%] [40:507/599][100:510/625][200:539/604][400:243/272]\n",
      "[Total testing images: 2150 ] [2 class accuracy 85.81395348837209%] [40:507/599][100:510/625][200:539/604][400:289/322]\n",
      "[Total testing images: 2200 ] [2 class accuracy 86.0%] [40:507/599][100:510/625][200:539/604][400:336/372]\n",
      "[Total testing images: 2250 ] [2 class accuracy 86.04444444444445%] [40:507/599][100:510/625][200:539/604][400:380/422]\n",
      "[Total testing images: 2300 ] [2 class accuracy 86.08695652173914%] [40:507/599][100:510/625][200:539/604][400:424/472]\n",
      "[Total testing images: 2350 ] [2 class accuracy 86.17021276595744%] [40:507/599][100:510/625][200:539/604][400:469/522]\n",
      "[Epoch 4/5] [Batch 0/346] [T loss: 0.052015, acc:  93%] time: 0:35:53.338219\n",
      "[Epoch 4/5] [Batch 20/346] [T loss: 0.005472, acc: 100%] time: 0:36:10.005324\n",
      "[Epoch 4/5] [Batch 40/346] [T loss: 0.184974, acc:  87%] time: 0:36:27.084913\n",
      "[Epoch 4/5] [Batch 60/346] [T loss: 0.224837, acc: 100%] time: 0:36:43.690559\n",
      "[Epoch 4/5] [Batch 80/346] [T loss: 0.404716, acc:  87%] time: 0:37:00.329833\n",
      "[Epoch 4/5] [Batch 100/346] [T loss: 0.281424, acc:  87%] time: 0:37:16.941695\n",
      "[Epoch 4/5] [Batch 120/346] [T loss: 0.045691, acc:  93%] time: 0:37:33.548349\n",
      "[Epoch 4/5] [Batch 140/346] [T loss: 0.217740, acc:  93%] time: 0:37:50.161456\n",
      "[Epoch 4/5] [Batch 160/346] [T loss: 0.094964, acc:  93%] time: 0:38:06.852775\n",
      "[Epoch 4/5] [Batch 180/346] [T loss: 0.529151, acc:  75%] time: 0:38:23.542504\n",
      "[Epoch 4/5] [Batch 200/346] [T loss: 0.101824, acc:  93%] time: 0:38:40.227237\n",
      "[Epoch 4/5] [Batch 220/346] [T loss: 0.024953, acc: 100%] time: 0:38:56.948976\n",
      "[Epoch 4/5] [Batch 240/346] [T loss: 0.135553, acc:  93%] time: 0:39:13.623532\n",
      "[Epoch 4/5] [Batch 260/346] [T loss: 0.048953, acc:  93%] time: 0:39:30.263287\n",
      "[Epoch 4/5] [Batch 280/346] [T loss: 0.204043, acc:  93%] time: 0:39:46.930573\n",
      "[Epoch 4/5] [Batch 300/346] [T loss: 0.347763, acc:  87%] time: 0:40:03.604432\n",
      "[Epoch 4/5] [Batch 320/346] [T loss: 0.004307, acc: 100%] time: 0:40:20.266935\n",
      "[Epoch 4/5] [Batch 340/346] [T loss: 0.128493, acc:  93%] time: 0:40:36.981222\n",
      "[Total testing images: 50 ] [2 class accuracy 96.0%] [40:48/50][100:0/0][200:0/0][400:0/0]\n",
      "[Total testing images: 100 ] [2 class accuracy 95.0%] [40:95/100][100:0/0][200:0/0][400:0/0]\n",
      "[Total testing images: 150 ] [2 class accuracy 92.66666666666666%] [40:139/150][100:0/0][200:0/0][400:0/0]\n",
      "[Total testing images: 200 ] [2 class accuracy 93.0%] [40:186/200][100:0/0][200:0/0][400:0/0]\n",
      "[Total testing images: 250 ] [2 class accuracy 94.0%] [40:235/250][100:0/0][200:0/0][400:0/0]\n",
      "[Total testing images: 300 ] [2 class accuracy 94.33333333333334%] [40:283/300][100:0/0][200:0/0][400:0/0]\n",
      "[Total testing images: 350 ] [2 class accuracy 94.28571428571428%] [40:330/350][100:0/0][200:0/0][400:0/0]\n",
      "[Total testing images: 400 ] [2 class accuracy 94.25%] [40:377/400][100:0/0][200:0/0][400:0/0]\n",
      "[Total testing images: 450 ] [2 class accuracy 94.44444444444444%] [40:425/450][100:0/0][200:0/0][400:0/0]\n",
      "[Total testing images: 500 ] [2 class accuracy 94.6%] [40:473/500][100:0/0][200:0/0][400:0/0]\n",
      "[Total testing images: 550 ] [2 class accuracy 94.54545454545455%] [40:520/550][100:0/0][200:0/0][400:0/0]\n",
      "[Total testing images: 600 ] [2 class accuracy 94.5%] [40:566/599][100:1/1][200:0/0][400:0/0]\n",
      "[Total testing images: 650 ] [2 class accuracy 94.61538461538461%] [40:566/599][100:49/51][200:0/0][400:0/0]\n",
      "[Total testing images: 700 ] [2 class accuracy 94.71428571428572%] [40:566/599][100:97/101][200:0/0][400:0/0]\n",
      "[Total testing images: 750 ] [2 class accuracy 94.53333333333333%] [40:566/599][100:143/151][200:0/0][400:0/0]\n",
      "[Total testing images: 800 ] [2 class accuracy 94.625%] [40:566/599][100:191/201][200:0/0][400:0/0]\n",
      "[Total testing images: 850 ] [2 class accuracy 94.82352941176471%] [40:566/599][100:240/251][200:0/0][400:0/0]\n",
      "[Total testing images: 900 ] [2 class accuracy 94.55555555555556%] [40:566/599][100:285/301][200:0/0][400:0/0]\n",
      "[Total testing images: 950 ] [2 class accuracy 94.52631578947368%] [40:566/599][100:332/351][200:0/0][400:0/0]\n",
      "[Total testing images: 1000 ] [2 class accuracy 94.6%] [40:566/599][100:380/401][200:0/0][400:0/0]\n",
      "[Total testing images: 1050 ] [2 class accuracy 94.57142857142857%] [40:566/599][100:427/451][200:0/0][400:0/0]\n",
      "[Total testing images: 1100 ] [2 class accuracy 94.72727272727272%] [40:566/599][100:476/501][200:0/0][400:0/0]\n",
      "[Total testing images: 1150 ] [2 class accuracy 94.78260869565217%] [40:566/599][100:524/551][200:0/0][400:0/0]\n",
      "[Total testing images: 1200 ] [2 class accuracy 94.75%] [40:566/599][100:571/601][200:0/0][400:0/0]\n",
      "[Total testing images: 1250 ] [2 class accuracy 94.64%] [40:566/599][100:593/625][200:24/26][400:0/0]\n",
      "[Total testing images: 1300 ] [2 class accuracy 94.6923076923077%] [40:566/599][100:593/625][200:72/76][400:0/0]\n",
      "[Total testing images: 1350 ] [2 class accuracy 94.51851851851852%] [40:566/599][100:593/625][200:117/126][400:0/0]\n",
      "[Total testing images: 1400 ] [2 class accuracy 94.57142857142857%] [40:566/599][100:593/625][200:165/176][400:0/0]\n",
      "[Total testing images: 1450 ] [2 class accuracy 94.6896551724138%] [40:566/599][100:593/625][200:214/226][400:0/0]\n",
      "[Total testing images: 1500 ] [2 class accuracy 94.66666666666667%] [40:566/599][100:593/625][200:261/276][400:0/0]\n",
      "[Total testing images: 1550 ] [2 class accuracy 94.83870967741936%] [40:566/599][100:593/625][200:311/326][400:0/0]\n",
      "[Total testing images: 1600 ] [2 class accuracy 95.0%] [40:566/599][100:593/625][200:361/376][400:0/0]\n",
      "[Total testing images: 1650 ] [2 class accuracy 95.15151515151516%] [40:566/599][100:593/625][200:411/426][400:0/0]\n",
      "[Total testing images: 1700 ] [2 class accuracy 94.94117647058825%] [40:566/599][100:593/625][200:455/476][400:0/0]\n",
      "[Total testing images: 1750 ] [2 class accuracy 94.85714285714286%] [40:566/599][100:593/625][200:501/526][400:0/0]\n",
      "[Total testing images: 1800 ] [2 class accuracy 94.83333333333334%] [40:566/599][100:593/625][200:548/576][400:0/0]\n",
      "[Total testing images: 1850 ] [2 class accuracy 94.8108108108108%] [40:566/599][100:593/625][200:575/604][400:20/22]\n",
      "[Total testing images: 1900 ] [2 class accuracy 94.84210526315789%] [40:566/599][100:593/625][200:575/604][400:68/72]\n",
      "[Total testing images: 1950 ] [2 class accuracy 94.82051282051283%] [40:566/599][100:593/625][200:575/604][400:115/122]\n",
      "[Total testing images: 2000 ] [2 class accuracy 94.75%] [40:566/599][100:593/625][200:575/604][400:161/172]\n",
      "[Total testing images: 2050 ] [2 class accuracy 94.82926829268293%] [40:566/599][100:593/625][200:575/604][400:210/222]\n",
      "[Total testing images: 2100 ] [2 class accuracy 94.9047619047619%] [40:566/599][100:593/625][200:575/604][400:259/272]\n",
      "[Total testing images: 2150 ] [2 class accuracy 94.88372093023256%] [40:566/599][100:593/625][200:575/604][400:306/322]\n",
      "[Total testing images: 2200 ] [2 class accuracy 94.95454545454545%] [40:566/599][100:593/625][200:575/604][400:355/372]\n",
      "[Total testing images: 2250 ] [2 class accuracy 95.02222222222223%] [40:566/599][100:593/625][200:575/604][400:404/422]\n",
      "[Total testing images: 2300 ] [2 class accuracy 95.04347826086956%] [40:566/599][100:593/625][200:575/604][400:452/472]\n",
      "[Total testing images: 2350 ] [2 class accuracy 95.06382978723404%] [40:566/599][100:593/625][200:575/604][400:500/522]\n",
      "Model saved\n",
      "40x:87.51252086811351 +/- 3.6779444755198245\n",
      "100x:88.608 +/- 5.1909089762776635\n",
      "200x:90.19867549668874 +/- 3.411399635281994\n",
      "400x:89.36014625228518 +/- 4.228373367618952\n",
      "Average:88.90947368421052 +/- 3.7778159866262513\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# without FAKE images + Mobilenet pretrain\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from codes.data.train_model import train_and_test_model,train_and_test_model_by_load_data\n",
    "from codes.data.create_dataset_01 import create_dataset,load_dataset\n",
    "\n",
    "from codes.model.resnetv2 import build_InceptionResNetV2_pretrain\n",
    "\n",
    " \n",
    "model = build_InceptionResNetV2_pretrain()\n",
    "\n",
    "\n",
    "input_ds_filename =\"/tf/dataset/classes\" \n",
    "\n",
    "train_log, test_log = train_and_test_model_by_load_data(model, input_ds_filename,ratio=0.7\n",
    "                                                        , dataset_volume=7909, epochs=5\n",
    "                                                        ,batch_size=16, print_interval=20 \n",
    "                                                        , output_filename=\"/tf/experiments/resnet16_299x299_16.h5\"\n",
    "                                                        , fake_volumn = 0\n",
    "                                                       )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0/5] [Batch 0/346] [T loss: 1.018768, acc:  75%] time: 0:05:12.236250\n",
      "[Epoch 0/5] [Batch 20/346] [T loss: 0.306980, acc:  93%] time: 0:05:28.967580\n",
      "[Epoch 0/5] [Batch 40/346] [T loss: 0.654628, acc:  87%] time: 0:05:45.670724\n",
      "[Epoch 0/5] [Batch 60/346] [T loss: 0.288929, acc:  87%] time: 0:06:02.386114\n",
      "[Epoch 0/5] [Batch 80/346] [T loss: 0.884178, acc:  62%] time: 0:06:19.080902\n",
      "[Epoch 0/5] [Batch 100/346] [T loss: 0.587212, acc:  81%] time: 0:06:35.757797\n",
      "[Epoch 0/5] [Batch 120/346] [T loss: 0.334253, acc:  87%] time: 0:06:52.472042\n",
      "[Epoch 0/5] [Batch 140/346] [T loss: 0.190125, acc:  93%] time: 0:07:09.149135\n",
      "[Epoch 0/5] [Batch 160/346] [T loss: 0.262115, acc:  87%] time: 0:07:25.781679\n",
      "[Epoch 0/5] [Batch 180/346] [T loss: 0.269998, acc:  93%] time: 0:07:42.453977\n",
      "[Epoch 0/5] [Batch 200/346] [T loss: 0.650358, acc:  68%] time: 0:07:59.141318\n",
      "[Epoch 0/5] [Batch 220/346] [T loss: 0.534510, acc:  75%] time: 0:08:15.902238\n",
      "[Epoch 0/5] [Batch 240/346] [T loss: 0.088690, acc:  93%] time: 0:08:37.941427\n",
      "[Epoch 0/5] [Batch 260/346] [T loss: 0.312990, acc:  87%] time: 0:08:54.627736\n",
      "[Epoch 0/5] [Batch 280/346] [T loss: 0.753352, acc:  68%] time: 0:09:11.316301\n",
      "[Epoch 0/5] [Batch 300/346] [T loss: 0.380468, acc:  87%] time: 0:09:27.994509\n",
      "[Epoch 0/5] [Batch 320/346] [T loss: 0.181401, acc:  81%] time: 0:09:44.707795\n",
      "[Epoch 0/5] [Batch 340/346] [T loss: 0.027633, acc: 100%] time: 0:10:01.362064\n",
      "[Total testing images: 50 ] [2 class accuracy 60.0%] [40:30/50][100:0/0][200:0/0][400:0/0]\n",
      "[Total testing images: 100 ] [2 class accuracy 65.0%] [40:65/100][100:0/0][200:0/0][400:0/0]\n",
      "[Total testing images: 150 ] [2 class accuracy 68.66666666666667%] [40:103/150][100:0/0][200:0/0][400:0/0]\n",
      "[Total testing images: 200 ] [2 class accuracy 69.5%] [40:139/200][100:0/0][200:0/0][400:0/0]\n",
      "[Total testing images: 250 ] [2 class accuracy 67.60000000000001%] [40:169/250][100:0/0][200:0/0][400:0/0]\n",
      "[Total testing images: 300 ] [2 class accuracy 66.0%] [40:198/300][100:0/0][200:0/0][400:0/0]\n",
      "[Total testing images: 350 ] [2 class accuracy 65.71428571428571%] [40:230/350][100:0/0][200:0/0][400:0/0]\n",
      "[Total testing images: 400 ] [2 class accuracy 66.5%] [40:266/400][100:0/0][200:0/0][400:0/0]\n",
      "[Total testing images: 450 ] [2 class accuracy 66.0%] [40:297/450][100:0/0][200:0/0][400:0/0]\n",
      "[Total testing images: 500 ] [2 class accuracy 67.2%] [40:336/500][100:0/0][200:0/0][400:0/0]\n",
      "[Total testing images: 550 ] [2 class accuracy 66.54545454545455%] [40:366/550][100:0/0][200:0/0][400:0/0]\n",
      "[Total testing images: 600 ] [2 class accuracy 66.66666666666666%] [40:400/598][100:0/2][200:0/0][400:0/0]\n",
      "[Total testing images: 650 ] [2 class accuracy 65.38461538461539%] [40:400/598][100:25/52][200:0/0][400:0/0]\n",
      "[Total testing images: 700 ] [2 class accuracy 64.42857142857143%] [40:400/598][100:51/102][200:0/0][400:0/0]\n",
      "[Total testing images: 750 ] [2 class accuracy 63.46666666666667%] [40:400/598][100:76/152][200:0/0][400:0/0]\n",
      "[Total testing images: 800 ] [2 class accuracy 62.125%] [40:400/598][100:97/202][200:0/0][400:0/0]\n",
      "[Total testing images: 850 ] [2 class accuracy 61.52941176470588%] [40:400/598][100:123/252][200:0/0][400:0/0]\n",
      "[Total testing images: 900 ] [2 class accuracy 61.33333333333333%] [40:400/598][100:152/302][200:0/0][400:0/0]\n",
      "[Total testing images: 950 ] [2 class accuracy 60.94736842105263%] [40:400/598][100:179/352][200:0/0][400:0/0]\n",
      "[Total testing images: 1000 ] [2 class accuracy 60.3%] [40:400/598][100:203/402][200:0/0][400:0/0]\n",
      "[Total testing images: 1050 ] [2 class accuracy 59.61904761904761%] [40:400/598][100:226/452][200:0/0][400:0/0]\n",
      "[Total testing images: 1100 ] [2 class accuracy 58.909090909090914%] [40:400/598][100:248/502][200:0/0][400:0/0]\n",
      "[Total testing images: 1150 ] [2 class accuracy 58.08695652173913%] [40:400/598][100:268/552][200:0/0][400:0/0]\n",
      "[Total testing images: 1200 ] [2 class accuracy 57.41666666666667%] [40:400/598][100:289/602][200:0/0][400:0/0]\n",
      "[Total testing images: 1250 ] [2 class accuracy 57.28%] [40:400/598][100:303/624][200:13/28][400:0/0]\n",
      "[Total testing images: 1300 ] [2 class accuracy 56.38461538461539%] [40:400/598][100:303/624][200:30/78][400:0/0]\n",
      "[Total testing images: 1350 ] [2 class accuracy 56.00000000000001%] [40:400/598][100:303/624][200:53/128][400:0/0]\n",
      "[Total testing images: 1400 ] [2 class accuracy 55.92857142857143%] [40:400/598][100:303/624][200:80/178][400:0/0]\n",
      "[Total testing images: 1450 ] [2 class accuracy 55.72413793103448%] [40:400/598][100:303/624][200:105/228][400:0/0]\n",
      "[Total testing images: 1500 ] [2 class accuracy 55.53333333333333%] [40:400/598][100:303/624][200:130/278][400:0/0]\n",
      "[Total testing images: 1550 ] [2 class accuracy 55.29032258064516%] [40:400/598][100:303/624][200:154/328][400:0/0]\n",
      "[Total testing images: 1600 ] [2 class accuracy 55.0625%] [40:400/598][100:303/624][200:178/378][400:0/0]\n",
      "[Total testing images: 1650 ] [2 class accuracy 54.666666666666664%] [40:400/598][100:303/624][200:199/428][400:0/0]\n",
      "[Total testing images: 1700 ] [2 class accuracy 54.352941176470594%] [40:400/598][100:303/624][200:221/478][400:0/0]\n",
      "[Total testing images: 1750 ] [2 class accuracy 54.0%] [40:400/598][100:303/624][200:242/528][400:0/0]\n",
      "[Total testing images: 1800 ] [2 class accuracy 53.94444444444444%] [40:400/598][100:303/624][200:268/578][400:0/0]\n",
      "[Total testing images: 1850 ] [2 class accuracy 53.783783783783775%] [40:400/598][100:303/624][200:277/603][400:15/25]\n",
      "[Total testing images: 1900 ] [2 class accuracy 53.26315789473684%] [40:400/598][100:303/624][200:277/603][400:32/75]\n",
      "[Total testing images: 1950 ] [2 class accuracy 52.97435897435897%] [40:400/598][100:303/624][200:277/603][400:53/125]\n",
      "[Total testing images: 2000 ] [2 class accuracy 52.849999999999994%] [40:400/598][100:303/624][200:277/603][400:77/175]\n",
      "[Total testing images: 2050 ] [2 class accuracy 52.4390243902439%] [40:400/598][100:303/624][200:277/603][400:95/225]\n",
      "[Total testing images: 2100 ] [2 class accuracy 52.28571428571429%] [40:400/598][100:303/624][200:277/603][400:118/275]\n",
      "[Total testing images: 2150 ] [2 class accuracy 51.95348837209303%] [40:400/598][100:303/624][200:277/603][400:137/325]\n",
      "[Total testing images: 2200 ] [2 class accuracy 51.72727272727272%] [40:400/598][100:303/624][200:277/603][400:158/375]\n",
      "[Total testing images: 2250 ] [2 class accuracy 51.46666666666667%] [40:400/598][100:303/624][200:277/603][400:178/425]\n",
      "[Total testing images: 2300 ] [2 class accuracy 51.52173913043478%] [40:400/598][100:303/624][200:277/603][400:205/475]\n",
      "[Total testing images: 2350 ] [2 class accuracy 51.36170212765957%] [40:400/598][100:303/624][200:277/603][400:227/525]\n",
      "[Epoch 1/5] [Batch 0/346] [T loss: 0.448213, acc:  93%] time: 0:12:52.529665\n",
      "[Epoch 1/5] [Batch 20/346] [T loss: 0.424329, acc:  81%] time: 0:13:09.325056\n",
      "[Epoch 1/5] [Batch 40/346] [T loss: 0.165672, acc:  93%] time: 0:13:26.178039\n",
      "[Epoch 1/5] [Batch 60/346] [T loss: 0.185463, acc:  87%] time: 0:13:42.844344\n",
      "[Epoch 1/5] [Batch 80/346] [T loss: 0.069550, acc: 100%] time: 0:13:59.499076\n",
      "[Epoch 1/5] [Batch 100/346] [T loss: 0.043410, acc: 100%] time: 0:14:16.145146\n",
      "[Epoch 1/5] [Batch 120/346] [T loss: 0.212766, acc:  87%] time: 0:14:32.833272\n",
      "[Epoch 1/5] [Batch 140/346] [T loss: 0.470541, acc:  81%] time: 0:14:49.476850\n",
      "[Epoch 1/5] [Batch 160/346] [T loss: 0.089968, acc: 100%] time: 0:15:06.069864\n",
      "[Epoch 1/5] [Batch 180/346] [T loss: 0.101621, acc:  93%] time: 0:15:22.677068\n",
      "[Epoch 1/5] [Batch 200/346] [T loss: 0.253519, acc:  87%] time: 0:15:39.348139\n",
      "[Epoch 1/5] [Batch 220/346] [T loss: 0.548371, acc:  81%] time: 0:15:55.974614\n",
      "[Epoch 1/5] [Batch 240/346] [T loss: 0.205087, acc:  93%] time: 0:16:12.615848\n",
      "[Epoch 1/5] [Batch 260/346] [T loss: 0.250014, acc:  93%] time: 0:16:29.246411\n",
      "[Epoch 1/5] [Batch 280/346] [T loss: 0.175342, acc:  87%] time: 0:16:45.905676\n",
      "[Epoch 1/5] [Batch 300/346] [T loss: 0.269451, acc:  87%] time: 0:17:02.578657\n",
      "[Epoch 1/5] [Batch 320/346] [T loss: 0.149604, acc:  93%] time: 0:17:19.201275\n",
      "[Epoch 1/5] [Batch 340/346] [T loss: 0.448338, acc:  87%] time: 0:17:42.928288\n",
      "[Total testing images: 50 ] [2 class accuracy 74.0%] [40:37/50][100:0/0][200:0/0][400:0/0]\n",
      "[Total testing images: 100 ] [2 class accuracy 81.0%] [40:81/100][100:0/0][200:0/0][400:0/0]\n",
      "[Total testing images: 150 ] [2 class accuracy 82.0%] [40:123/150][100:0/0][200:0/0][400:0/0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Total testing images: 200 ] [2 class accuracy 82.5%] [40:165/200][100:0/0][200:0/0][400:0/0]\n",
      "[Total testing images: 250 ] [2 class accuracy 81.6%] [40:204/250][100:0/0][200:0/0][400:0/0]\n",
      "[Total testing images: 300 ] [2 class accuracy 80.0%] [40:240/300][100:0/0][200:0/0][400:0/0]\n",
      "[Total testing images: 350 ] [2 class accuracy 79.42857142857143%] [40:278/350][100:0/0][200:0/0][400:0/0]\n",
      "[Total testing images: 400 ] [2 class accuracy 79.75%] [40:319/400][100:0/0][200:0/0][400:0/0]\n",
      "[Total testing images: 450 ] [2 class accuracy 79.11111111111111%] [40:356/450][100:0/0][200:0/0][400:0/0]\n",
      "[Total testing images: 500 ] [2 class accuracy 79.80000000000001%] [40:399/500][100:0/0][200:0/0][400:0/0]\n",
      "[Total testing images: 550 ] [2 class accuracy 80.18181818181817%] [40:441/550][100:0/0][200:0/0][400:0/0]\n",
      "[Total testing images: 600 ] [2 class accuracy 81.0%] [40:485/598][100:1/2][200:0/0][400:0/0]\n",
      "[Total testing images: 650 ] [2 class accuracy 80.46153846153847%] [40:485/598][100:38/52][200:0/0][400:0/0]\n",
      "[Total testing images: 700 ] [2 class accuracy 79.57142857142857%] [40:485/598][100:72/102][200:0/0][400:0/0]\n",
      "[Total testing images: 750 ] [2 class accuracy 79.46666666666667%] [40:485/598][100:111/152][200:0/0][400:0/0]\n",
      "[Total testing images: 800 ] [2 class accuracy 79.125%] [40:485/598][100:148/202][200:0/0][400:0/0]\n",
      "[Total testing images: 850 ] [2 class accuracy 78.70588235294119%] [40:485/598][100:184/252][200:0/0][400:0/0]\n",
      "[Total testing images: 900 ] [2 class accuracy 78.66666666666666%] [40:485/598][100:223/302][200:0/0][400:0/0]\n",
      "[Total testing images: 950 ] [2 class accuracy 78.10526315789474%] [40:485/598][100:257/352][200:0/0][400:0/0]\n",
      "[Total testing images: 1000 ] [2 class accuracy 77.9%] [40:485/598][100:294/402][200:0/0][400:0/0]\n",
      "[Total testing images: 1050 ] [2 class accuracy 77.80952380952381%] [40:485/598][100:332/452][200:0/0][400:0/0]\n",
      "[Total testing images: 1100 ] [2 class accuracy 77.54545454545455%] [40:485/598][100:368/502][200:0/0][400:0/0]\n",
      "[Total testing images: 1150 ] [2 class accuracy 77.13043478260869%] [40:485/598][100:402/552][200:0/0][400:0/0]\n",
      "[Total testing images: 1200 ] [2 class accuracy 77.16666666666666%] [40:485/598][100:441/602][200:0/0][400:0/0]\n",
      "[Total testing images: 1250 ] [2 class accuracy 77.52%] [40:485/598][100:460/624][200:24/28][400:0/0]\n",
      "[Total testing images: 1300 ] [2 class accuracy 76.6923076923077%] [40:485/598][100:460/624][200:52/78][400:0/0]\n",
      "[Total testing images: 1350 ] [2 class accuracy 76.37037037037037%] [40:485/598][100:460/624][200:86/128][400:0/0]\n",
      "[Total testing images: 1400 ] [2 class accuracy 76.0%] [40:485/598][100:460/624][200:119/178][400:0/0]\n",
      "[Total testing images: 1450 ] [2 class accuracy 76.06896551724138%] [40:485/598][100:460/624][200:158/228][400:0/0]\n",
      "[Total testing images: 1500 ] [2 class accuracy 76.13333333333333%] [40:485/598][100:460/624][200:197/278][400:0/0]\n",
      "[Total testing images: 1550 ] [2 class accuracy 76.58064516129032%] [40:485/598][100:460/624][200:242/328][400:0/0]\n",
      "[Total testing images: 1600 ] [2 class accuracy 76.5%] [40:485/598][100:460/624][200:279/378][400:0/0]\n",
      "[Total testing images: 1650 ] [2 class accuracy 76.30303030303031%] [40:485/598][100:460/624][200:314/428][400:0/0]\n",
      "[Total testing images: 1700 ] [2 class accuracy 76.0%] [40:485/598][100:460/624][200:347/478][400:0/0]\n",
      "[Total testing images: 1750 ] [2 class accuracy 76.11428571428571%] [40:485/598][100:460/624][200:387/528][400:0/0]\n",
      "[Total testing images: 1800 ] [2 class accuracy 76.11111111111111%] [40:485/598][100:460/624][200:425/578][400:0/0]\n",
      "[Total testing images: 1850 ] [2 class accuracy 76.0%] [40:485/598][100:460/624][200:444/603][400:17/25]\n",
      "[Total testing images: 1900 ] [2 class accuracy 75.73684210526316%] [40:485/598][100:460/624][200:444/603][400:50/75]\n",
      "[Total testing images: 1950 ] [2 class accuracy 75.64102564102564%] [40:485/598][100:460/624][200:444/603][400:86/125]\n",
      "[Total testing images: 2000 ] [2 class accuracy 75.35%] [40:485/598][100:460/624][200:444/603][400:118/175]\n",
      "[Total testing images: 2050 ] [2 class accuracy 75.07317073170732%] [40:485/598][100:460/624][200:444/603][400:150/225]\n",
      "[Total testing images: 2100 ] [2 class accuracy 74.85714285714286%] [40:485/598][100:460/624][200:444/603][400:183/275]\n",
      "[Total testing images: 2150 ] [2 class accuracy 74.51162790697674%] [40:485/598][100:460/624][200:444/603][400:213/325]\n",
      "[Total testing images: 2200 ] [2 class accuracy 74.45454545454545%] [40:485/598][100:460/624][200:444/603][400:249/375]\n",
      "[Total testing images: 2250 ] [2 class accuracy 74.26666666666667%] [40:485/598][100:460/624][200:444/603][400:282/425]\n",
      "[Total testing images: 2300 ] [2 class accuracy 74.34782608695653%] [40:485/598][100:460/624][200:444/603][400:321/475]\n",
      "[Total testing images: 2350 ] [2 class accuracy 74.38297872340426%] [40:485/598][100:460/624][200:444/603][400:359/525]\n",
      "[Epoch 2/5] [Batch 0/346] [T loss: 0.101374, acc:  93%] time: 0:20:26.212456\n",
      "[Epoch 2/5] [Batch 20/346] [T loss: 0.007544, acc: 100%] time: 0:20:43.535276\n",
      "[Epoch 2/5] [Batch 40/346] [T loss: 0.005974, acc: 100%] time: 0:21:00.205559\n",
      "[Epoch 2/5] [Batch 60/346] [T loss: 0.469322, acc:  81%] time: 0:21:16.893334\n",
      "[Epoch 2/5] [Batch 80/346] [T loss: 0.070848, acc: 100%] time: 0:21:33.490898\n",
      "[Epoch 2/5] [Batch 100/346] [T loss: 0.200030, acc:  93%] time: 0:21:50.153335\n",
      "[Epoch 2/5] [Batch 120/346] [T loss: 0.002445, acc: 100%] time: 0:22:06.836967\n",
      "[Epoch 2/5] [Batch 140/346] [T loss: 0.412698, acc:  75%] time: 0:22:23.510265\n",
      "[Epoch 2/5] [Batch 160/346] [T loss: 0.086946, acc:  93%] time: 0:22:40.188556\n",
      "[Epoch 2/5] [Batch 180/346] [T loss: 0.352380, acc:  75%] time: 0:22:56.852317\n",
      "[Epoch 2/5] [Batch 200/346] [T loss: 0.303578, acc:  93%] time: 0:23:13.509877\n",
      "[Epoch 2/5] [Batch 220/346] [T loss: 0.172989, acc:  93%] time: 0:23:30.098296\n",
      "[Epoch 2/5] [Batch 240/346] [T loss: 0.272133, acc:  87%] time: 0:23:46.767803\n",
      "[Epoch 2/5] [Batch 260/346] [T loss: 0.221436, acc:  87%] time: 0:24:03.426769\n",
      "[Epoch 2/5] [Batch 280/346] [T loss: 0.040975, acc: 100%] time: 0:24:20.019172\n",
      "[Epoch 2/5] [Batch 300/346] [T loss: 0.013599, acc: 100%] time: 0:24:36.693038\n",
      "[Epoch 2/5] [Batch 320/346] [T loss: 0.122027, acc: 100%] time: 0:24:53.389159\n",
      "[Epoch 2/5] [Batch 340/346] [T loss: 0.125417, acc: 100%] time: 0:25:10.095632\n",
      "[Total testing images: 50 ] [2 class accuracy 82.0%] [40:41/50][100:0/0][200:0/0][400:0/0]\n",
      "[Total testing images: 100 ] [2 class accuracy 86.0%] [40:86/100][100:0/0][200:0/0][400:0/0]\n",
      "[Total testing images: 150 ] [2 class accuracy 86.66666666666667%] [40:130/150][100:0/0][200:0/0][400:0/0]\n",
      "[Total testing images: 200 ] [2 class accuracy 89.5%] [40:179/200][100:0/0][200:0/0][400:0/0]\n",
      "[Total testing images: 250 ] [2 class accuracy 88.4%] [40:221/250][100:0/0][200:0/0][400:0/0]\n",
      "[Total testing images: 300 ] [2 class accuracy 89.0%] [40:267/300][100:0/0][200:0/0][400:0/0]\n",
      "[Total testing images: 350 ] [2 class accuracy 88.57142857142857%] [40:310/350][100:0/0][200:0/0][400:0/0]\n",
      "[Total testing images: 400 ] [2 class accuracy 89.5%] [40:358/400][100:0/0][200:0/0][400:0/0]\n",
      "[Total testing images: 450 ] [2 class accuracy 90.22222222222223%] [40:406/450][100:0/0][200:0/0][400:0/0]\n",
      "[Total testing images: 500 ] [2 class accuracy 90.4%] [40:452/500][100:0/0][200:0/0][400:0/0]\n",
      "[Total testing images: 550 ] [2 class accuracy 90.18181818181819%] [40:496/550][100:0/0][200:0/0][400:0/0]\n",
      "[Total testing images: 600 ] [2 class accuracy 90.5%] [40:541/598][100:2/2][200:0/0][400:0/0]\n",
      "[Total testing images: 650 ] [2 class accuracy 90.3076923076923%] [40:541/598][100:46/52][200:0/0][400:0/0]\n",
      "[Total testing images: 700 ] [2 class accuracy 90.14285714285715%] [40:541/598][100:90/102][200:0/0][400:0/0]\n",
      "[Total testing images: 750 ] [2 class accuracy 90.0%] [40:541/598][100:134/152][200:0/0][400:0/0]\n",
      "[Total testing images: 800 ] [2 class accuracy 90.0%] [40:541/598][100:179/202][200:0/0][400:0/0]\n",
      "[Total testing images: 850 ] [2 class accuracy 90.0%] [40:541/598][100:224/252][200:0/0][400:0/0]\n",
      "[Total testing images: 900 ] [2 class accuracy 89.88888888888889%] [40:541/598][100:268/302][200:0/0][400:0/0]\n",
      "[Total testing images: 950 ] [2 class accuracy 89.26315789473685%] [40:541/598][100:307/352][200:0/0][400:0/0]\n",
      "[Total testing images: 1000 ] [2 class accuracy 89.2%] [40:541/598][100:351/402][200:0/0][400:0/0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Total testing images: 1050 ] [2 class accuracy 89.04761904761904%] [40:541/598][100:394/452][200:0/0][400:0/0]\n",
      "[Total testing images: 1100 ] [2 class accuracy 89.18181818181819%] [40:541/598][100:440/502][200:0/0][400:0/0]\n",
      "[Total testing images: 1150 ] [2 class accuracy 88.95652173913044%] [40:541/598][100:482/552][200:0/0][400:0/0]\n",
      "[Total testing images: 1200 ] [2 class accuracy 88.75%] [40:541/598][100:524/602][200:0/0][400:0/0]\n",
      "[Total testing images: 1250 ] [2 class accuracy 88.96%] [40:541/598][100:545/624][200:26/28][400:0/0]\n",
      "[Total testing images: 1300 ] [2 class accuracy 88.76923076923077%] [40:541/598][100:545/624][200:68/78][400:0/0]\n",
      "[Total testing images: 1350 ] [2 class accuracy 88.81481481481481%] [40:541/598][100:545/624][200:113/128][400:0/0]\n",
      "[Total testing images: 1400 ] [2 class accuracy 88.78571428571429%] [40:541/598][100:545/624][200:157/178][400:0/0]\n",
      "[Total testing images: 1450 ] [2 class accuracy 88.89655172413794%] [40:541/598][100:545/624][200:203/228][400:0/0]\n",
      "[Total testing images: 1500 ] [2 class accuracy 89.06666666666668%] [40:541/598][100:545/624][200:250/278][400:0/0]\n",
      "[Total testing images: 1550 ] [2 class accuracy 89.2258064516129%] [40:541/598][100:545/624][200:297/328][400:0/0]\n",
      "[Total testing images: 1600 ] [2 class accuracy 89.25%] [40:541/598][100:545/624][200:342/378][400:0/0]\n",
      "[Total testing images: 1650 ] [2 class accuracy 89.0909090909091%] [40:541/598][100:545/624][200:384/428][400:0/0]\n",
      "[Total testing images: 1700 ] [2 class accuracy 89.17647058823529%] [40:541/598][100:545/624][200:430/478][400:0/0]\n",
      "[Total testing images: 1750 ] [2 class accuracy 89.08571428571429%] [40:541/598][100:545/624][200:473/528][400:0/0]\n",
      "[Total testing images: 1800 ] [2 class accuracy 89.0%] [40:541/598][100:545/624][200:516/578][400:0/0]\n",
      "[Total testing images: 1850 ] [2 class accuracy 89.13513513513513%] [40:541/598][100:545/624][200:541/603][400:22/25]\n",
      "[Total testing images: 1900 ] [2 class accuracy 89.21052631578948%] [40:541/598][100:545/624][200:541/603][400:68/75]\n",
      "[Total testing images: 1950 ] [2 class accuracy 89.33333333333333%] [40:541/598][100:545/624][200:541/603][400:115/125]\n",
      "[Total testing images: 2000 ] [2 class accuracy 89.5%] [40:541/598][100:545/624][200:541/603][400:163/175]\n",
      "[Total testing images: 2050 ] [2 class accuracy 89.5609756097561%] [40:541/598][100:545/624][200:541/603][400:209/225]\n",
      "[Total testing images: 2100 ] [2 class accuracy 89.57142857142857%] [40:541/598][100:545/624][200:541/603][400:254/275]\n",
      "[Total testing images: 2150 ] [2 class accuracy 89.62790697674419%] [40:541/598][100:545/624][200:541/603][400:300/325]\n",
      "[Total testing images: 2200 ] [2 class accuracy 89.5909090909091%] [40:541/598][100:545/624][200:541/603][400:344/375]\n",
      "[Total testing images: 2250 ] [2 class accuracy 89.64444444444445%] [40:541/598][100:545/624][200:541/603][400:390/425]\n",
      "[Total testing images: 2300 ] [2 class accuracy 89.73913043478261%] [40:541/598][100:545/624][200:541/603][400:437/475]\n",
      "[Total testing images: 2350 ] [2 class accuracy 89.6595744680851%] [40:541/598][100:545/624][200:541/603][400:480/525]\n",
      "[Epoch 3/5] [Batch 0/346] [T loss: 0.105203, acc: 100%] time: 0:27:58.229191\n",
      "[Epoch 3/5] [Batch 20/346] [T loss: 0.162028, acc:  93%] time: 0:28:14.879105\n",
      "[Epoch 3/5] [Batch 40/346] [T loss: 0.132794, acc:  87%] time: 0:28:31.975829\n",
      "[Epoch 3/5] [Batch 60/346] [T loss: 0.107263, acc: 100%] time: 0:28:48.565849\n",
      "[Epoch 3/5] [Batch 80/346] [T loss: 0.435135, acc:  87%] time: 0:29:05.169244\n",
      "[Epoch 3/5] [Batch 100/346] [T loss: 0.191313, acc:  87%] time: 0:29:21.833046\n",
      "[Epoch 3/5] [Batch 120/346] [T loss: 0.134254, acc:  87%] time: 0:29:38.442386\n",
      "[Epoch 3/5] [Batch 140/346] [T loss: 0.200512, acc:  87%] time: 0:29:55.053808\n",
      "[Epoch 3/5] [Batch 160/346] [T loss: 0.351050, acc:  75%] time: 0:30:11.659397\n",
      "[Epoch 3/5] [Batch 180/346] [T loss: 0.107456, acc:  93%] time: 0:30:28.323934\n",
      "[Epoch 3/5] [Batch 200/346] [T loss: 0.147877, acc:  93%] time: 0:30:44.928652\n",
      "[Epoch 3/5] [Batch 220/346] [T loss: 0.275558, acc:  81%] time: 0:31:01.538282\n",
      "[Epoch 3/5] [Batch 240/346] [T loss: 0.133953, acc:  93%] time: 0:31:18.188180\n",
      "[Epoch 3/5] [Batch 260/346] [T loss: 0.101181, acc:  93%] time: 0:31:34.843560\n",
      "[Epoch 3/5] [Batch 280/346] [T loss: 0.100075, acc: 100%] time: 0:31:51.440922\n",
      "[Epoch 3/5] [Batch 300/346] [T loss: 0.324177, acc:  93%] time: 0:32:08.049315\n",
      "[Epoch 3/5] [Batch 320/346] [T loss: 0.317963, acc:  87%] time: 0:32:24.683013\n",
      "[Epoch 3/5] [Batch 340/346] [T loss: 0.076684, acc: 100%] time: 0:32:41.337273\n",
      "[Total testing images: 50 ] [2 class accuracy 90.0%] [40:45/50][100:0/0][200:0/0][400:0/0]\n",
      "[Total testing images: 100 ] [2 class accuracy 93.0%] [40:93/100][100:0/0][200:0/0][400:0/0]\n",
      "[Total testing images: 150 ] [2 class accuracy 94.0%] [40:141/150][100:0/0][200:0/0][400:0/0]\n",
      "[Total testing images: 200 ] [2 class accuracy 95.5%] [40:191/200][100:0/0][200:0/0][400:0/0]\n",
      "[Total testing images: 250 ] [2 class accuracy 94.0%] [40:235/250][100:0/0][200:0/0][400:0/0]\n",
      "[Total testing images: 300 ] [2 class accuracy 94.0%] [40:282/300][100:0/0][200:0/0][400:0/0]\n",
      "[Total testing images: 350 ] [2 class accuracy 93.71428571428572%] [40:328/350][100:0/0][200:0/0][400:0/0]\n",
      "[Total testing images: 400 ] [2 class accuracy 94.0%] [40:376/400][100:0/0][200:0/0][400:0/0]\n",
      "[Total testing images: 450 ] [2 class accuracy 94.22222222222221%] [40:424/450][100:0/0][200:0/0][400:0/0]\n",
      "[Total testing images: 500 ] [2 class accuracy 94.6%] [40:473/500][100:0/0][200:0/0][400:0/0]\n",
      "[Total testing images: 550 ] [2 class accuracy 94.72727272727272%] [40:521/550][100:0/0][200:0/0][400:0/0]\n",
      "[Total testing images: 600 ] [2 class accuracy 95.16666666666667%] [40:569/598][100:2/2][200:0/0][400:0/0]\n",
      "[Total testing images: 650 ] [2 class accuracy 94.61538461538461%] [40:569/598][100:46/52][200:0/0][400:0/0]\n",
      "[Total testing images: 700 ] [2 class accuracy 94.28571428571428%] [40:569/598][100:91/102][200:0/0][400:0/0]\n",
      "[Total testing images: 750 ] [2 class accuracy 94.39999999999999%] [40:569/598][100:139/152][200:0/0][400:0/0]\n",
      "[Total testing images: 800 ] [2 class accuracy 94.5%] [40:569/598][100:187/202][200:0/0][400:0/0]\n",
      "[Total testing images: 850 ] [2 class accuracy 94.47058823529412%] [40:569/598][100:234/252][200:0/0][400:0/0]\n",
      "[Total testing images: 900 ] [2 class accuracy 94.0%] [40:569/598][100:277/302][200:0/0][400:0/0]\n",
      "[Total testing images: 950 ] [2 class accuracy 93.89473684210526%] [40:569/598][100:323/352][200:0/0][400:0/0]\n",
      "[Total testing images: 1000 ] [2 class accuracy 93.7%] [40:569/598][100:368/402][200:0/0][400:0/0]\n",
      "[Total testing images: 1050 ] [2 class accuracy 93.61904761904762%] [40:569/598][100:414/452][200:0/0][400:0/0]\n",
      "[Total testing images: 1100 ] [2 class accuracy 93.9090909090909%] [40:569/598][100:464/502][200:0/0][400:0/0]\n",
      "[Total testing images: 1150 ] [2 class accuracy 93.82608695652173%] [40:569/598][100:510/552][200:0/0][400:0/0]\n",
      "[Total testing images: 1200 ] [2 class accuracy 93.91666666666667%] [40:569/598][100:558/602][200:0/0][400:0/0]\n",
      "[Total testing images: 1250 ] [2 class accuracy 94.0%] [40:569/598][100:579/624][200:27/28][400:0/0]\n",
      "[Total testing images: 1300 ] [2 class accuracy 94.15384615384616%] [40:569/598][100:579/624][200:76/78][400:0/0]\n",
      "[Total testing images: 1350 ] [2 class accuracy 94.14814814814815%] [40:569/598][100:579/624][200:123/128][400:0/0]\n",
      "[Total testing images: 1400 ] [2 class accuracy 94.07142857142857%] [40:569/598][100:579/624][200:169/178][400:0/0]\n",
      "[Total testing images: 1450 ] [2 class accuracy 94.20689655172414%] [40:569/598][100:579/624][200:218/228][400:0/0]\n",
      "[Total testing images: 1500 ] [2 class accuracy 94.19999999999999%] [40:569/598][100:579/624][200:265/278][400:0/0]\n",
      "[Total testing images: 1550 ] [2 class accuracy 94.19354838709677%] [40:569/598][100:579/624][200:312/328][400:0/0]\n",
      "[Total testing images: 1600 ] [2 class accuracy 94.1875%] [40:569/598][100:579/624][200:359/378][400:0/0]\n",
      "[Total testing images: 1650 ] [2 class accuracy 94.12121212121211%] [40:569/598][100:579/624][200:405/428][400:0/0]\n",
      "[Total testing images: 1700 ] [2 class accuracy 94.11764705882352%] [40:569/598][100:579/624][200:452/478][400:0/0]\n",
      "[Total testing images: 1750 ] [2 class accuracy 94.0%] [40:569/598][100:579/624][200:497/528][400:0/0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Total testing images: 1800 ] [2 class accuracy 93.94444444444444%] [40:569/598][100:579/624][200:543/578][400:0/0]\n",
      "[Total testing images: 1850 ] [2 class accuracy 93.94594594594594%] [40:569/598][100:579/624][200:566/603][400:24/25]\n",
      "[Total testing images: 1900 ] [2 class accuracy 93.78947368421052%] [40:569/598][100:579/624][200:566/603][400:68/75]\n",
      "[Total testing images: 1950 ] [2 class accuracy 93.7948717948718%] [40:569/598][100:579/624][200:566/603][400:115/125]\n",
      "[Total testing images: 2000 ] [2 class accuracy 93.65%] [40:569/598][100:579/624][200:566/603][400:159/175]\n",
      "[Total testing images: 2050 ] [2 class accuracy 93.5609756097561%] [40:569/598][100:579/624][200:566/603][400:204/225]\n",
      "[Total testing images: 2100 ] [2 class accuracy 93.19047619047619%] [40:569/598][100:579/624][200:566/603][400:243/275]\n",
      "[Total testing images: 2150 ] [2 class accuracy 93.25581395348837%] [40:569/598][100:579/624][200:566/603][400:291/325]\n",
      "[Total testing images: 2200 ] [2 class accuracy 93.04545454545455%] [40:569/598][100:579/624][200:566/603][400:333/375]\n",
      "[Total testing images: 2250 ] [2 class accuracy 92.71111111111111%] [40:569/598][100:579/624][200:566/603][400:372/425]\n",
      "[Total testing images: 2300 ] [2 class accuracy 92.78260869565217%] [40:569/598][100:579/624][200:566/603][400:420/475]\n",
      "[Total testing images: 2350 ] [2 class accuracy 92.80851063829788%] [40:569/598][100:579/624][200:566/603][400:467/525]\n",
      "[Epoch 4/5] [Batch 0/346] [T loss: 0.034447, acc: 100%] time: 0:35:28.927654\n",
      "[Epoch 4/5] [Batch 20/346] [T loss: 0.387709, acc:  81%] time: 0:35:45.567495\n",
      "[Epoch 4/5] [Batch 40/346] [T loss: 0.191579, acc:  87%] time: 0:36:02.424919\n",
      "[Epoch 4/5] [Batch 60/346] [T loss: 0.060586, acc: 100%] time: 0:36:19.052747\n",
      "[Epoch 4/5] [Batch 80/346] [T loss: 0.002450, acc: 100%] time: 0:36:35.698533\n",
      "[Epoch 4/5] [Batch 100/346] [T loss: 0.352798, acc:  81%] time: 0:36:52.360402\n",
      "[Epoch 4/5] [Batch 120/346] [T loss: 0.206830, acc:  87%] time: 0:37:08.955420\n",
      "[Epoch 4/5] [Batch 140/346] [T loss: 0.220227, acc:  93%] time: 0:37:25.638584\n",
      "[Epoch 4/5] [Batch 160/346] [T loss: 0.021012, acc: 100%] time: 0:37:42.243362\n",
      "[Epoch 4/5] [Batch 180/346] [T loss: 0.075282, acc: 100%] time: 0:37:58.853708\n",
      "[Epoch 4/5] [Batch 200/346] [T loss: 0.026418, acc: 100%] time: 0:38:15.518995\n",
      "[Epoch 4/5] [Batch 220/346] [T loss: 0.121280, acc: 100%] time: 0:38:32.203513\n",
      "[Epoch 4/5] [Batch 240/346] [T loss: 0.454976, acc:  87%] time: 0:38:48.861516\n",
      "[Epoch 4/5] [Batch 260/346] [T loss: 0.301891, acc:  93%] time: 0:39:05.482835\n",
      "[Epoch 4/5] [Batch 280/346] [T loss: 0.161739, acc:  93%] time: 0:39:22.077109\n",
      "[Epoch 4/5] [Batch 300/346] [T loss: 0.266020, acc:  87%] time: 0:39:38.713756\n",
      "[Epoch 4/5] [Batch 320/346] [T loss: 0.002581, acc: 100%] time: 0:39:55.352848\n",
      "[Epoch 4/5] [Batch 340/346] [T loss: 0.199103, acc:  93%] time: 0:40:11.985653\n",
      "[Total testing images: 50 ] [2 class accuracy 66.0%] [40:33/50][100:0/0][200:0/0][400:0/0]\n",
      "[Total testing images: 100 ] [2 class accuracy 75.0%] [40:75/100][100:0/0][200:0/0][400:0/0]\n",
      "[Total testing images: 150 ] [2 class accuracy 76.0%] [40:114/150][100:0/0][200:0/0][400:0/0]\n",
      "[Total testing images: 200 ] [2 class accuracy 77.5%] [40:155/200][100:0/0][200:0/0][400:0/0]\n",
      "[Total testing images: 250 ] [2 class accuracy 77.60000000000001%] [40:194/250][100:0/0][200:0/0][400:0/0]\n",
      "[Total testing images: 300 ] [2 class accuracy 77.33333333333333%] [40:232/300][100:0/0][200:0/0][400:0/0]\n",
      "[Total testing images: 350 ] [2 class accuracy 76.85714285714286%] [40:269/350][100:0/0][200:0/0][400:0/0]\n",
      "[Total testing images: 400 ] [2 class accuracy 77.0%] [40:308/400][100:0/0][200:0/0][400:0/0]\n",
      "[Total testing images: 450 ] [2 class accuracy 77.11111111111111%] [40:347/450][100:0/0][200:0/0][400:0/0]\n",
      "[Total testing images: 500 ] [2 class accuracy 77.0%] [40:385/500][100:0/0][200:0/0][400:0/0]\n",
      "[Total testing images: 550 ] [2 class accuracy 76.36363636363637%] [40:420/550][100:0/0][200:0/0][400:0/0]\n",
      "[Total testing images: 600 ] [2 class accuracy 76.66666666666667%] [40:459/598][100:1/2][200:0/0][400:0/0]\n",
      "[Total testing images: 650 ] [2 class accuracy 75.6923076923077%] [40:459/598][100:33/52][200:0/0][400:0/0]\n",
      "[Total testing images: 700 ] [2 class accuracy 75.28571428571429%] [40:459/598][100:68/102][200:0/0][400:0/0]\n",
      "[Total testing images: 750 ] [2 class accuracy 75.06666666666668%] [40:459/598][100:104/152][200:0/0][400:0/0]\n",
      "[Total testing images: 800 ] [2 class accuracy 74.25%] [40:459/598][100:135/202][200:0/0][400:0/0]\n",
      "[Total testing images: 850 ] [2 class accuracy 73.1764705882353%] [40:459/598][100:163/252][200:0/0][400:0/0]\n",
      "[Total testing images: 900 ] [2 class accuracy 72.88888888888889%] [40:459/598][100:197/302][200:0/0][400:0/0]\n",
      "[Total testing images: 950 ] [2 class accuracy 72.3157894736842%] [40:459/598][100:228/352][200:0/0][400:0/0]\n",
      "[Total testing images: 1000 ] [2 class accuracy 72.1%] [40:459/598][100:262/402][200:0/0][400:0/0]\n",
      "[Total testing images: 1050 ] [2 class accuracy 72.47619047619047%] [40:459/598][100:302/452][200:0/0][400:0/0]\n",
      "[Total testing images: 1100 ] [2 class accuracy 72.54545454545455%] [40:459/598][100:339/502][200:0/0][400:0/0]\n",
      "[Total testing images: 1150 ] [2 class accuracy 72.08695652173913%] [40:459/598][100:370/552][200:0/0][400:0/0]\n",
      "[Total testing images: 1200 ] [2 class accuracy 71.33333333333334%] [40:459/598][100:397/602][200:0/0][400:0/0]\n",
      "[Total testing images: 1250 ] [2 class accuracy 71.44%] [40:459/598][100:414/624][200:20/28][400:0/0]\n",
      "[Total testing images: 1300 ] [2 class accuracy 70.46153846153847%] [40:459/598][100:414/624][200:43/78][400:0/0]\n",
      "[Total testing images: 1350 ] [2 class accuracy 70.14814814814815%] [40:459/598][100:414/624][200:74/128][400:0/0]\n",
      "[Total testing images: 1400 ] [2 class accuracy 70.21428571428572%] [40:459/598][100:414/624][200:110/178][400:0/0]\n",
      "[Total testing images: 1450 ] [2 class accuracy 69.93103448275862%] [40:459/598][100:414/624][200:141/228][400:0/0]\n",
      "[Total testing images: 1500 ] [2 class accuracy 69.86666666666666%] [40:459/598][100:414/624][200:175/278][400:0/0]\n",
      "[Total testing images: 1550 ] [2 class accuracy 69.87096774193549%] [40:459/598][100:414/624][200:210/328][400:0/0]\n",
      "[Total testing images: 1600 ] [2 class accuracy 69.75%] [40:459/598][100:414/624][200:243/378][400:0/0]\n",
      "[Total testing images: 1650 ] [2 class accuracy 69.63636363636364%] [40:459/598][100:414/624][200:276/428][400:0/0]\n",
      "[Total testing images: 1700 ] [2 class accuracy 69.82352941176471%] [40:459/598][100:414/624][200:314/478][400:0/0]\n",
      "[Total testing images: 1750 ] [2 class accuracy 69.65714285714286%] [40:459/598][100:414/624][200:346/528][400:0/0]\n",
      "[Total testing images: 1800 ] [2 class accuracy 69.5%] [40:459/598][100:414/624][200:378/578][400:0/0]\n",
      "[Total testing images: 1850 ] [2 class accuracy 69.67567567567568%] [40:459/598][100:414/624][200:395/603][400:21/25]\n",
      "[Total testing images: 1900 ] [2 class accuracy 69.42105263157895%] [40:459/598][100:414/624][200:395/603][400:51/75]\n",
      "[Total testing images: 1950 ] [2 class accuracy 69.6923076923077%] [40:459/598][100:414/624][200:395/603][400:91/125]\n",
      "[Total testing images: 2000 ] [2 class accuracy 69.69999999999999%] [40:459/598][100:414/624][200:395/603][400:126/175]\n",
      "[Total testing images: 2050 ] [2 class accuracy 69.46341463414633%] [40:459/598][100:414/624][200:395/603][400:156/225]\n",
      "[Total testing images: 2100 ] [2 class accuracy 69.66666666666667%] [40:459/598][100:414/624][200:395/603][400:195/275]\n",
      "[Total testing images: 2150 ] [2 class accuracy 69.3953488372093%] [40:459/598][100:414/624][200:395/603][400:224/325]\n",
      "[Total testing images: 2200 ] [2 class accuracy 69.27272727272728%] [40:459/598][100:414/624][200:395/603][400:256/375]\n",
      "[Total testing images: 2250 ] [2 class accuracy 69.24444444444444%] [40:459/598][100:414/624][200:395/603][400:290/425]\n",
      "[Total testing images: 2300 ] [2 class accuracy 69.26086956521739%] [40:459/598][100:414/624][200:395/603][400:325/475]\n",
      "[Total testing images: 2350 ] [2 class accuracy 69.14893617021278%] [40:459/598][100:414/624][200:395/603][400:357/525]\n",
      "Model saved\n",
      "40x:82.074 +/- 10.0\n",
      "100x:73.75 +/- 16.0\n",
      "200x:73.731 +/- 17.0\n",
      "400x:72.015 +/- 17.0\n",
      "Average:75.445 +/- 15.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "input_ds_filename =\"/tf/dataset/classes\" \n",
    "\n",
    "train_log, test_log = train_and_test_model(model, input_ds_filename,ratio=0.7, dataset_volume=7909, epochs=5,batch_size=16, print_interval=20 , output_filename=\"/tf/experiments/resnet16_299x299_16.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0/5] [Batch 0/1384] [T loss: 0.002194, acc: 100%] time: 0:00:02.505230\n",
      "[Epoch 0/5] [Batch 20/1384] [T loss: 0.139924, acc:  75%] time: 0:00:10.120693\n",
      "[Epoch 0/5] [Batch 40/1384] [T loss: 0.056560, acc: 100%] time: 0:00:17.742218\n",
      "[Epoch 0/5] [Batch 60/1384] [T loss: 0.387491, acc: 100%] time: 0:00:25.341669\n",
      "[Epoch 0/5] [Batch 80/1384] [T loss: 0.002468, acc: 100%] time: 0:00:32.952789\n",
      "[Epoch 0/5] [Batch 100/1384] [T loss: 0.362081, acc:  75%] time: 0:00:40.507839\n",
      "[Epoch 0/5] [Batch 120/1384] [T loss: 0.035875, acc: 100%] time: 0:00:48.147291\n",
      "[Epoch 0/5] [Batch 140/1384] [T loss: 0.897140, acc:  75%] time: 0:00:55.771862\n",
      "[Epoch 0/5] [Batch 160/1384] [T loss: 0.477993, acc: 100%] time: 0:01:03.376945\n",
      "[Epoch 0/5] [Batch 180/1384] [T loss: 0.002226, acc: 100%] time: 0:01:10.943649\n",
      "[Epoch 0/5] [Batch 200/1384] [T loss: 0.276041, acc: 100%] time: 0:01:18.518061\n",
      "[Epoch 0/5] [Batch 220/1384] [T loss: 0.002282, acc: 100%] time: 0:01:26.051460\n",
      "[Epoch 0/5] [Batch 240/1384] [T loss: 0.048462, acc: 100%] time: 0:01:33.575677\n",
      "[Epoch 0/5] [Batch 260/1384] [T loss: 0.504883, acc:  75%] time: 0:01:41.203006\n",
      "[Epoch 0/5] [Batch 280/1384] [T loss: 0.837661, acc:  75%] time: 0:01:48.825368\n",
      "[Epoch 0/5] [Batch 300/1384] [T loss: 0.002304, acc: 100%] time: 0:01:56.580316\n",
      "[Epoch 0/5] [Batch 320/1384] [T loss: 0.355699, acc:  75%] time: 0:02:04.207282\n",
      "[Epoch 0/5] [Batch 340/1384] [T loss: 0.002432, acc: 100%] time: 0:02:11.855426\n",
      "[Epoch 0/5] [Batch 360/1384] [T loss: 0.299668, acc: 100%] time: 0:02:19.453234\n",
      "[Epoch 0/5] [Batch 380/1384] [T loss: 1.106140, acc:  50%] time: 0:02:27.010025\n",
      "[Epoch 0/5] [Batch 400/1384] [T loss: 0.233366, acc: 100%] time: 0:02:34.591829\n",
      "[Epoch 0/5] [Batch 420/1384] [T loss: 1.563828, acc:   0%] time: 0:02:42.189397\n",
      "[Epoch 0/5] [Batch 440/1384] [T loss: 0.318862, acc: 100%] time: 0:02:49.787957\n",
      "[Epoch 0/5] [Batch 460/1384] [T loss: 1.082420, acc:  75%] time: 0:03:03.592197\n",
      "[Epoch 0/5] [Batch 480/1384] [T loss: 0.068409, acc: 100%] time: 0:03:11.174552\n",
      "[Epoch 0/5] [Batch 500/1384] [T loss: 0.287276, acc:  75%] time: 0:03:18.797261\n",
      "[Epoch 0/5] [Batch 520/1384] [T loss: 0.145891, acc: 100%] time: 0:03:26.406369\n",
      "[Epoch 0/5] [Batch 540/1384] [T loss: 0.318216, acc: 100%] time: 0:03:34.043939\n",
      "[Epoch 0/5] [Batch 560/1384] [T loss: 0.588150, acc:  75%] time: 0:03:41.612079\n",
      "[Epoch 0/5] [Batch 580/1384] [T loss: 0.676916, acc:  75%] time: 0:03:49.282581\n",
      "[Epoch 0/5] [Batch 600/1384] [T loss: 0.002232, acc: 100%] time: 0:03:56.851520\n",
      "[Epoch 0/5] [Batch 620/1384] [T loss: 0.782292, acc:  75%] time: 0:04:04.472670\n",
      "[Epoch 0/5] [Batch 640/1384] [T loss: 0.150437, acc: 100%] time: 0:04:12.055095\n",
      "[Epoch 0/5] [Batch 660/1384] [T loss: 0.002587, acc: 100%] time: 0:04:19.646971\n",
      "[Epoch 0/5] [Batch 680/1384] [T loss: 0.048303, acc: 100%] time: 0:04:27.224670\n",
      "[Epoch 0/5] [Batch 700/1384] [T loss: 1.446909, acc:  50%] time: 0:04:34.849895\n",
      "[Epoch 0/5] [Batch 720/1384] [T loss: 0.149660, acc:  75%] time: 0:04:42.500380\n",
      "[Epoch 0/5] [Batch 740/1384] [T loss: 0.002146, acc: 100%] time: 0:04:50.177407\n",
      "[Epoch 0/5] [Batch 760/1384] [T loss: 0.093521, acc: 100%] time: 0:04:57.778136\n",
      "[Epoch 0/5] [Batch 780/1384] [T loss: 0.053239, acc: 100%] time: 0:05:05.413191\n",
      "[Epoch 0/5] [Batch 800/1384] [T loss: 0.759403, acc:  50%] time: 0:05:13.029157\n",
      "[Epoch 0/5] [Batch 820/1384] [T loss: 0.394515, acc:  75%] time: 0:05:20.653779\n",
      "[Epoch 0/5] [Batch 840/1384] [T loss: 0.002167, acc: 100%] time: 0:05:28.176157\n",
      "[Epoch 0/5] [Batch 860/1384] [T loss: 1.302710, acc:  25%] time: 0:05:35.724698\n",
      "[Epoch 0/5] [Batch 880/1384] [T loss: 0.052093, acc: 100%] time: 0:05:43.327143\n",
      "[Epoch 0/5] [Batch 900/1384] [T loss: 0.006141, acc: 100%] time: 0:05:50.920788\n",
      "[Epoch 0/5] [Batch 920/1384] [T loss: 0.002098, acc: 100%] time: 0:05:58.523042\n",
      "[Epoch 0/5] [Batch 940/1384] [T loss: 0.119254, acc: 100%] time: 0:06:06.130465\n",
      "[Epoch 0/5] [Batch 960/1384] [T loss: 0.617776, acc:  75%] time: 0:06:13.766346\n",
      "[Epoch 0/5] [Batch 980/1384] [T loss: 0.364727, acc:  75%] time: 0:06:21.339028\n",
      "[Epoch 0/5] [Batch 1000/1384] [T loss: 0.586093, acc:  75%] time: 0:06:28.922018\n",
      "[Epoch 0/5] [Batch 1020/1384] [T loss: 0.002397, acc: 100%] time: 0:06:36.498520\n",
      "[Epoch 0/5] [Batch 1040/1384] [T loss: 0.837260, acc:  50%] time: 0:06:44.136855\n",
      "[Epoch 0/5] [Batch 1060/1384] [T loss: 0.279531, acc:  75%] time: 0:06:51.745053\n",
      "[Epoch 0/5] [Batch 1080/1384] [T loss: 0.001887, acc: 100%] time: 0:06:59.305464\n",
      "[Epoch 0/5] [Batch 1100/1384] [T loss: 0.001912, acc: 100%] time: 0:07:06.988812\n",
      "[Epoch 0/5] [Batch 1120/1384] [T loss: 0.244112, acc: 100%] time: 0:07:14.627683\n",
      "[Epoch 0/5] [Batch 1140/1384] [T loss: 0.446914, acc:  75%] time: 0:07:22.256952\n",
      "[Epoch 0/5] [Batch 1160/1384] [T loss: 0.284580, acc: 100%] time: 0:07:29.884358\n",
      "[Epoch 0/5] [Batch 1180/1384] [T loss: 0.002258, acc: 100%] time: 0:07:37.467862\n",
      "[Epoch 0/5] [Batch 1200/1384] [T loss: 0.502341, acc:  75%] time: 0:07:45.127421\n",
      "[Epoch 0/5] [Batch 1220/1384] [T loss: 0.002374, acc: 100%] time: 0:07:52.705218\n",
      "[Epoch 0/5] [Batch 1240/1384] [T loss: 1.746212, acc:  50%] time: 0:08:00.240632\n",
      "[Epoch 0/5] [Batch 1260/1384] [T loss: 0.432903, acc:  75%] time: 0:08:07.793209\n",
      "[Epoch 0/5] [Batch 1280/1384] [T loss: 0.549769, acc:  75%] time: 0:08:15.339125\n",
      "[Epoch 0/5] [Batch 1300/1384] [T loss: 0.010897, acc: 100%] time: 0:08:22.875578\n",
      "[Epoch 0/5] [Batch 1320/1384] [T loss: 0.002222, acc: 100%] time: 0:08:30.476095\n",
      "[Epoch 0/5] [Batch 1340/1384] [T loss: 0.002292, acc: 100%] time: 0:08:38.158107\n",
      "[Epoch 0/5] [Batch 1360/1384] [T loss: 0.165127, acc: 100%] time: 0:08:45.844009\n",
      "[Epoch 0/5] [Batch 1380/1384] [T loss: 0.893380, acc:  50%] time: 0:08:53.471983\n",
      "[Total testing images: 50 ] [2 class accuracy 90.0%] [40:45/50][100:0/0][200:0/0][400:0/0]\n",
      "[Total testing images: 100 ] [2 class accuracy 91.0%] [40:91/100][100:0/0][200:0/0][400:0/0]\n",
      "[Total testing images: 150 ] [2 class accuracy 92.66666666666666%] [40:139/150][100:0/0][200:0/0][400:0/0]\n",
      "[Total testing images: 200 ] [2 class accuracy 94.0%] [40:188/200][100:0/0][200:0/0][400:0/0]\n",
      "[Total testing images: 250 ] [2 class accuracy 92.4%] [40:231/250][100:0/0][200:0/0][400:0/0]\n",
      "[Total testing images: 300 ] [2 class accuracy 92.0%] [40:276/300][100:0/0][200:0/0][400:0/0]\n",
      "[Total testing images: 350 ] [2 class accuracy 91.42857142857143%] [40:320/350][100:0/0][200:0/0][400:0/0]\n",
      "[Total testing images: 400 ] [2 class accuracy 92.0%] [40:368/400][100:0/0][200:0/0][400:0/0]\n",
      "[Total testing images: 450 ] [2 class accuracy 92.0%] [40:414/450][100:0/0][200:0/0][400:0/0]\n",
      "[Total testing images: 500 ] [2 class accuracy 92.60000000000001%] [40:463/500][100:0/0][200:0/0][400:0/0]\n",
      "[Total testing images: 550 ] [2 class accuracy 92.54545454545455%] [40:509/550][100:0/0][200:0/0][400:0/0]\n",
      "[Total testing images: 600 ] [2 class accuracy 92.83333333333333%] [40:555/598][100:2/2][200:0/0][400:0/0]\n",
      "[Total testing images: 650 ] [2 class accuracy 92.46153846153847%] [40:555/598][100:46/52][200:0/0][400:0/0]\n",
      "[Total testing images: 700 ] [2 class accuracy 91.71428571428571%] [40:555/598][100:87/102][200:0/0][400:0/0]\n",
      "[Total testing images: 750 ] [2 class accuracy 91.86666666666666%] [40:555/598][100:134/152][200:0/0][400:0/0]\n",
      "[Total testing images: 800 ] [2 class accuracy 91.75%] [40:555/598][100:179/202][200:0/0][400:0/0]\n",
      "[Total testing images: 850 ] [2 class accuracy 92.0%] [40:555/598][100:227/252][200:0/0][400:0/0]\n",
      "[Total testing images: 900 ] [2 class accuracy 91.88888888888889%] [40:555/598][100:272/302][200:0/0][400:0/0]\n",
      "[Total testing images: 950 ] [2 class accuracy 91.6842105263158%] [40:555/598][100:316/352][200:0/0][400:0/0]\n",
      "[Total testing images: 1000 ] [2 class accuracy 91.9%] [40:555/598][100:364/402][200:0/0][400:0/0]\n",
      "[Total testing images: 1050 ] [2 class accuracy 92.0%] [40:555/598][100:411/452][200:0/0][400:0/0]\n",
      "[Total testing images: 1100 ] [2 class accuracy 92.18181818181819%] [40:555/598][100:459/502][200:0/0][400:0/0]\n",
      "[Total testing images: 1150 ] [2 class accuracy 92.0%] [40:555/598][100:503/552][200:0/0][400:0/0]\n",
      "[Total testing images: 1200 ] [2 class accuracy 92.08333333333333%] [40:555/598][100:550/602][200:0/0][400:0/0]\n",
      "[Total testing images: 1250 ] [2 class accuracy 92.16%] [40:555/598][100:571/624][200:26/28][400:0/0]\n",
      "[Total testing images: 1300 ] [2 class accuracy 92.0%] [40:555/598][100:571/624][200:70/78][400:0/0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Total testing images: 1350 ] [2 class accuracy 91.85185185185185%] [40:555/598][100:571/624][200:114/128][400:0/0]\n",
      "[Total testing images: 1400 ] [2 class accuracy 91.71428571428571%] [40:555/598][100:571/624][200:158/178][400:0/0]\n",
      "[Total testing images: 1450 ] [2 class accuracy 91.72413793103448%] [40:555/598][100:571/624][200:204/228][400:0/0]\n",
      "[Total testing images: 1500 ] [2 class accuracy 91.8%] [40:555/598][100:571/624][200:251/278][400:0/0]\n",
      "[Total testing images: 1550 ] [2 class accuracy 91.87096774193549%] [40:555/598][100:571/624][200:298/328][400:0/0]\n",
      "[Total testing images: 1600 ] [2 class accuracy 91.8125%] [40:555/598][100:571/624][200:343/378][400:0/0]\n",
      "[Total testing images: 1650 ] [2 class accuracy 91.87878787878788%] [40:555/598][100:571/624][200:390/428][400:0/0]\n",
      "[Total testing images: 1700 ] [2 class accuracy 92.0%] [40:555/598][100:571/624][200:438/478][400:0/0]\n",
      "[Total testing images: 1750 ] [2 class accuracy 91.94285714285715%] [40:555/598][100:571/624][200:483/528][400:0/0]\n",
      "[Total testing images: 1800 ] [2 class accuracy 92.11111111111111%] [40:555/598][100:571/624][200:532/578][400:0/0]\n",
      "[Total testing images: 1850 ] [2 class accuracy 92.21621621621622%] [40:555/598][100:571/624][200:555/603][400:25/25]\n",
      "[Total testing images: 1900 ] [2 class accuracy 91.94736842105263%] [40:555/598][100:571/624][200:555/603][400:66/75]\n",
      "[Total testing images: 1950 ] [2 class accuracy 92.1025641025641%] [40:555/598][100:571/624][200:555/603][400:115/125]\n",
      "[Total testing images: 2000 ] [2 class accuracy 92.10000000000001%] [40:555/598][100:571/624][200:555/603][400:161/175]\n",
      "[Total testing images: 2050 ] [2 class accuracy 92.09756097560977%] [40:555/598][100:571/624][200:555/603][400:207/225]\n",
      "[Total testing images: 2100 ] [2 class accuracy 92.04761904761905%] [40:555/598][100:571/624][200:555/603][400:252/275]\n",
      "[Total testing images: 2150 ] [2 class accuracy 92.0%] [40:555/598][100:571/624][200:555/603][400:297/325]\n",
      "[Total testing images: 2200 ] [2 class accuracy 91.9090909090909%] [40:555/598][100:571/624][200:555/603][400:341/375]\n",
      "[Total testing images: 2250 ] [2 class accuracy 91.73333333333333%] [40:555/598][100:571/624][200:555/603][400:383/425]\n",
      "[Total testing images: 2300 ] [2 class accuracy 91.82608695652173%] [40:555/598][100:571/624][200:555/603][400:431/475]\n",
      "[Total testing images: 2350 ] [2 class accuracy 91.91489361702128%] [40:555/598][100:571/624][200:555/603][400:479/525]\n",
      "[Epoch 1/5] [Batch 0/1384] [T loss: 0.002203, acc: 100%] time: 0:11:37.417182\n",
      "[Epoch 1/5] [Batch 20/1384] [T loss: 0.025731, acc: 100%] time: 0:11:44.996483\n",
      "[Epoch 1/5] [Batch 40/1384] [T loss: 0.002164, acc: 100%] time: 0:11:52.563506\n",
      "[Epoch 1/5] [Batch 60/1384] [T loss: 1.247328, acc:  25%] time: 0:12:00.153670\n",
      "[Epoch 1/5] [Batch 80/1384] [T loss: 0.002275, acc: 100%] time: 0:12:07.699574\n",
      "[Epoch 1/5] [Batch 100/1384] [T loss: 0.126904, acc: 100%] time: 0:12:15.370096\n",
      "[Epoch 1/5] [Batch 120/1384] [T loss: 0.055199, acc: 100%] time: 0:12:23.086660\n",
      "[Epoch 1/5] [Batch 140/1384] [T loss: 0.089813, acc: 100%] time: 0:12:30.639945\n",
      "[Epoch 1/5] [Batch 160/1384] [T loss: 0.002266, acc: 100%] time: 0:12:38.293026\n",
      "[Epoch 1/5] [Batch 180/1384] [T loss: 0.158065, acc:  75%] time: 0:12:45.951523\n",
      "[Epoch 1/5] [Batch 200/1384] [T loss: 0.418991, acc:  75%] time: 0:12:53.594812\n",
      "[Epoch 1/5] [Batch 220/1384] [T loss: 0.995979, acc:  25%] time: 0:13:01.163674\n",
      "[Epoch 1/5] [Batch 240/1384] [T loss: 0.048074, acc: 100%] time: 0:13:08.695983\n",
      "[Epoch 1/5] [Batch 260/1384] [T loss: 0.002715, acc: 100%] time: 0:13:16.328891\n",
      "[Epoch 1/5] [Batch 280/1384] [T loss: 0.730603, acc:  50%] time: 0:13:23.901276\n",
      "[Epoch 1/5] [Batch 300/1384] [T loss: 0.063156, acc: 100%] time: 0:13:31.511131\n",
      "[Epoch 1/5] [Batch 320/1384] [T loss: 0.128264, acc: 100%] time: 0:13:39.204010\n",
      "[Epoch 1/5] [Batch 340/1384] [T loss: 0.551177, acc:  50%] time: 0:13:46.886965\n",
      "[Epoch 1/5] [Batch 360/1384] [T loss: 0.206375, acc:  75%] time: 0:13:54.493736\n",
      "[Epoch 1/5] [Batch 380/1384] [T loss: 0.543606, acc:  75%] time: 0:14:02.193030\n",
      "[Epoch 1/5] [Batch 400/1384] [T loss: 0.431678, acc:  75%] time: 0:14:09.746074\n",
      "[Epoch 1/5] [Batch 420/1384] [T loss: 0.002398, acc: 100%] time: 0:14:17.327224\n",
      "[Epoch 1/5] [Batch 440/1384] [T loss: 0.002829, acc: 100%] time: 0:14:24.915482\n",
      "[Epoch 1/5] [Batch 460/1384] [T loss: 0.002287, acc: 100%] time: 0:14:32.559439\n",
      "[Epoch 1/5] [Batch 480/1384] [T loss: 0.002413, acc: 100%] time: 0:14:40.168391\n",
      "[Epoch 1/5] [Batch 500/1384] [T loss: 0.002610, acc: 100%] time: 0:14:47.841771\n",
      "[Epoch 1/5] [Batch 520/1384] [T loss: 0.460005, acc:  75%] time: 0:14:55.526621\n",
      "[Epoch 1/5] [Batch 540/1384] [T loss: 0.451765, acc:  75%] time: 0:15:03.147872\n",
      "[Epoch 1/5] [Batch 560/1384] [T loss: 0.104851, acc: 100%] time: 0:15:10.898355\n",
      "[Epoch 1/5] [Batch 580/1384] [T loss: 0.002663, acc: 100%] time: 0:15:18.643487\n",
      "[Epoch 1/5] [Batch 600/1384] [T loss: 0.029945, acc: 100%] time: 0:15:26.261549\n",
      "[Epoch 1/5] [Batch 620/1384] [T loss: 1.054491, acc:  50%] time: 0:15:33.867716\n",
      "[Epoch 1/5] [Batch 640/1384] [T loss: 0.002334, acc: 100%] time: 0:15:41.519568\n",
      "[Epoch 1/5] [Batch 660/1384] [T loss: 0.366546, acc:  75%] time: 0:15:49.083335\n",
      "[Epoch 1/5] [Batch 680/1384] [T loss: 0.002315, acc: 100%] time: 0:15:56.630215\n",
      "[Epoch 1/5] [Batch 700/1384] [T loss: 0.941982, acc:  75%] time: 0:16:04.235096\n",
      "[Epoch 1/5] [Batch 720/1384] [T loss: 0.624245, acc:  75%] time: 0:16:11.795113\n",
      "[Epoch 1/5] [Batch 740/1384] [T loss: 0.002465, acc: 100%] time: 0:16:19.496272\n",
      "[Epoch 1/5] [Batch 760/1384] [T loss: 0.002288, acc: 100%] time: 0:16:27.154281\n",
      "[Epoch 1/5] [Batch 780/1384] [T loss: 0.056062, acc: 100%] time: 0:16:34.764450\n",
      "[Epoch 1/5] [Batch 800/1384] [T loss: 0.197269, acc: 100%] time: 0:16:42.351666\n",
      "[Epoch 1/5] [Batch 820/1384] [T loss: 0.402643, acc:  75%] time: 0:16:49.956614\n",
      "[Epoch 1/5] [Batch 840/1384] [T loss: 0.271213, acc:  75%] time: 0:16:57.614067\n",
      "[Epoch 1/5] [Batch 860/1384] [T loss: 0.111659, acc: 100%] time: 0:17:05.187395\n",
      "[Epoch 1/5] [Batch 880/1384] [T loss: 1.587275, acc:  50%] time: 0:17:19.669811\n",
      "[Epoch 1/5] [Batch 900/1384] [T loss: 0.002284, acc: 100%] time: 0:17:27.372436\n",
      "[Epoch 1/5] [Batch 920/1384] [T loss: 0.002331, acc: 100%] time: 0:17:35.082102\n",
      "[Epoch 1/5] [Batch 940/1384] [T loss: 0.002380, acc: 100%] time: 0:17:42.769027\n",
      "[Epoch 1/5] [Batch 960/1384] [T loss: 0.044906, acc: 100%] time: 0:17:50.436708\n",
      "[Epoch 1/5] [Batch 980/1384] [T loss: 1.531502, acc:  50%] time: 0:17:57.989230\n",
      "[Epoch 1/5] [Batch 1000/1384] [T loss: 0.154815, acc:  75%] time: 0:18:05.598542\n",
      "[Epoch 1/5] [Batch 1020/1384] [T loss: 0.002400, acc: 100%] time: 0:18:13.194666\n",
      "[Epoch 1/5] [Batch 1040/1384] [T loss: 0.002699, acc: 100%] time: 0:18:20.822625\n",
      "[Epoch 1/5] [Batch 1060/1384] [T loss: 0.353865, acc:  75%] time: 0:18:28.415907\n",
      "[Epoch 1/5] [Batch 1080/1384] [T loss: 0.002672, acc: 100%] time: 0:18:36.055937\n",
      "[Epoch 1/5] [Batch 1100/1384] [T loss: 1.182408, acc:  50%] time: 0:18:43.622371\n",
      "[Epoch 1/5] [Batch 1120/1384] [T loss: 0.002268, acc: 100%] time: 0:18:51.170125\n",
      "[Epoch 1/5] [Batch 1140/1384] [T loss: 0.002324, acc: 100%] time: 0:18:58.723156\n",
      "[Epoch 1/5] [Batch 1160/1384] [T loss: 0.002183, acc: 100%] time: 0:19:06.312314\n",
      "[Epoch 1/5] [Batch 1180/1384] [T loss: 0.096861, acc: 100%] time: 0:19:13.936458\n",
      "[Epoch 1/5] [Batch 1200/1384] [T loss: 0.002204, acc: 100%] time: 0:19:21.525169\n",
      "[Epoch 1/5] [Batch 1220/1384] [T loss: 0.381548, acc:  75%] time: 0:19:29.078790\n",
      "[Epoch 1/5] [Batch 1240/1384] [T loss: 1.178974, acc:  50%] time: 0:19:36.677930\n",
      "[Epoch 1/5] [Batch 1260/1384] [T loss: 0.223728, acc: 100%] time: 0:19:44.401646\n",
      "[Epoch 1/5] [Batch 1280/1384] [T loss: 0.568117, acc:  75%] time: 0:19:52.060271\n",
      "[Epoch 1/5] [Batch 1300/1384] [T loss: 0.238120, acc:  75%] time: 0:19:59.643605\n",
      "[Epoch 1/5] [Batch 1320/1384] [T loss: 0.574667, acc:  50%] time: 0:20:07.231877\n",
      "[Epoch 1/5] [Batch 1340/1384] [T loss: 0.969790, acc:  50%] time: 0:20:14.904950\n",
      "[Epoch 1/5] [Batch 1360/1384] [T loss: 0.005549, acc: 100%] time: 0:20:22.482296\n",
      "[Epoch 1/5] [Batch 1380/1384] [T loss: 0.002126, acc: 100%] time: 0:20:30.045114\n",
      "[Total testing images: 50 ] [2 class accuracy 86.0%] [40:43/50][100:0/0][200:0/0][400:0/0]\n",
      "[Total testing images: 100 ] [2 class accuracy 90.0%] [40:90/100][100:0/0][200:0/0][400:0/0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Total testing images: 150 ] [2 class accuracy 89.33333333333333%] [40:134/150][100:0/0][200:0/0][400:0/0]\n",
      "[Total testing images: 200 ] [2 class accuracy 91.0%] [40:182/200][100:0/0][200:0/0][400:0/0]\n",
      "[Total testing images: 250 ] [2 class accuracy 89.60000000000001%] [40:224/250][100:0/0][200:0/0][400:0/0]\n",
      "[Total testing images: 300 ] [2 class accuracy 90.0%] [40:270/300][100:0/0][200:0/0][400:0/0]\n",
      "[Total testing images: 350 ] [2 class accuracy 89.71428571428571%] [40:314/350][100:0/0][200:0/0][400:0/0]\n",
      "[Total testing images: 400 ] [2 class accuracy 90.5%] [40:362/400][100:0/0][200:0/0][400:0/0]\n",
      "[Total testing images: 450 ] [2 class accuracy 90.66666666666666%] [40:408/450][100:0/0][200:0/0][400:0/0]\n",
      "[Total testing images: 500 ] [2 class accuracy 91.0%] [40:455/500][100:0/0][200:0/0][400:0/0]\n",
      "[Total testing images: 550 ] [2 class accuracy 91.0909090909091%] [40:501/550][100:0/0][200:0/0][400:0/0]\n",
      "[Total testing images: 600 ] [2 class accuracy 91.66666666666666%] [40:548/598][100:2/2][200:0/0][400:0/0]\n",
      "[Total testing images: 650 ] [2 class accuracy 91.53846153846153%] [40:548/598][100:47/52][200:0/0][400:0/0]\n",
      "[Total testing images: 700 ] [2 class accuracy 91.28571428571428%] [40:548/598][100:91/102][200:0/0][400:0/0]\n",
      "[Total testing images: 750 ] [2 class accuracy 90.93333333333334%] [40:548/598][100:134/152][200:0/0][400:0/0]\n",
      "[Total testing images: 800 ] [2 class accuracy 91.0%] [40:548/598][100:180/202][200:0/0][400:0/0]\n",
      "[Total testing images: 850 ] [2 class accuracy 91.41176470588235%] [40:548/598][100:229/252][200:0/0][400:0/0]\n",
      "[Total testing images: 900 ] [2 class accuracy 91.44444444444444%] [40:548/598][100:275/302][200:0/0][400:0/0]\n",
      "[Total testing images: 950 ] [2 class accuracy 91.15789473684211%] [40:548/598][100:318/352][200:0/0][400:0/0]\n",
      "[Total testing images: 1000 ] [2 class accuracy 91.2%] [40:548/598][100:364/402][200:0/0][400:0/0]\n",
      "[Total testing images: 1050 ] [2 class accuracy 91.14285714285715%] [40:548/598][100:409/452][200:0/0][400:0/0]\n",
      "[Total testing images: 1100 ] [2 class accuracy 91.27272727272727%] [40:548/598][100:456/502][200:0/0][400:0/0]\n",
      "[Total testing images: 1150 ] [2 class accuracy 91.13043478260869%] [40:548/598][100:500/552][200:0/0][400:0/0]\n",
      "[Total testing images: 1200 ] [2 class accuracy 91.16666666666666%] [40:548/598][100:546/602][200:0/0][400:0/0]\n",
      "[Total testing images: 1250 ] [2 class accuracy 91.28%] [40:548/598][100:567/624][200:26/28][400:0/0]\n",
      "[Total testing images: 1300 ] [2 class accuracy 91.46153846153847%] [40:548/598][100:567/624][200:74/78][400:0/0]\n",
      "[Total testing images: 1350 ] [2 class accuracy 91.25925925925927%] [40:548/598][100:567/624][200:117/128][400:0/0]\n",
      "[Total testing images: 1400 ] [2 class accuracy 91.07142857142857%] [40:548/598][100:567/624][200:160/178][400:0/0]\n",
      "[Total testing images: 1450 ] [2 class accuracy 91.17241379310344%] [40:548/598][100:567/624][200:207/228][400:0/0]\n",
      "[Total testing images: 1500 ] [2 class accuracy 91.33333333333333%] [40:548/598][100:567/624][200:255/278][400:0/0]\n",
      "[Total testing images: 1550 ] [2 class accuracy 91.48387096774194%] [40:548/598][100:567/624][200:303/328][400:0/0]\n",
      "[Total testing images: 1600 ] [2 class accuracy 91.5%] [40:548/598][100:567/624][200:349/378][400:0/0]\n",
      "[Total testing images: 1650 ] [2 class accuracy 91.57575757575758%] [40:548/598][100:567/624][200:396/428][400:0/0]\n",
      "[Total testing images: 1700 ] [2 class accuracy 91.58823529411765%] [40:548/598][100:567/624][200:442/478][400:0/0]\n",
      "[Total testing images: 1750 ] [2 class accuracy 91.54285714285714%] [40:548/598][100:567/624][200:487/528][400:0/0]\n",
      "[Total testing images: 1800 ] [2 class accuracy 91.61111111111111%] [40:548/598][100:567/624][200:534/578][400:0/0]\n",
      "[Total testing images: 1850 ] [2 class accuracy 91.62162162162161%] [40:548/598][100:567/624][200:559/603][400:21/25]\n",
      "[Total testing images: 1900 ] [2 class accuracy 91.52631578947368%] [40:548/598][100:567/624][200:559/603][400:65/75]\n",
      "[Total testing images: 1950 ] [2 class accuracy 91.38461538461539%] [40:548/598][100:567/624][200:559/603][400:108/125]\n",
      "[Total testing images: 2000 ] [2 class accuracy 91.45%] [40:548/598][100:567/624][200:559/603][400:155/175]\n",
      "[Total testing images: 2050 ] [2 class accuracy 91.46341463414635%] [40:548/598][100:567/624][200:559/603][400:201/225]\n",
      "[Total testing images: 2100 ] [2 class accuracy 91.14285714285715%] [40:548/598][100:567/624][200:559/603][400:240/275]\n",
      "[Total testing images: 2150 ] [2 class accuracy 91.02325581395348%] [40:548/598][100:567/624][200:559/603][400:283/325]\n",
      "[Total testing images: 2200 ] [2 class accuracy 90.86363636363637%] [40:548/598][100:567/624][200:559/603][400:325/375]\n",
      "[Total testing images: 2250 ] [2 class accuracy 90.57777777777778%] [40:548/598][100:567/624][200:559/603][400:364/425]\n",
      "[Total testing images: 2300 ] [2 class accuracy 90.52173913043478%] [40:548/598][100:567/624][200:559/603][400:408/475]\n",
      "[Total testing images: 2350 ] [2 class accuracy 90.42553191489363%] [40:548/598][100:567/624][200:559/603][400:451/525]\n",
      "[Epoch 2/5] [Batch 0/1384] [T loss: 1.253812, acc:  50%] time: 0:23:07.779965\n",
      "[Epoch 2/5] [Batch 20/1384] [T loss: 0.518080, acc:  75%] time: 0:23:15.446521\n",
      "[Epoch 2/5] [Batch 40/1384] [T loss: 0.002338, acc: 100%] time: 0:23:23.031506\n",
      "[Epoch 2/5] [Batch 60/1384] [T loss: 0.002297, acc: 100%] time: 0:23:30.675516\n",
      "[Epoch 2/5] [Batch 80/1384] [T loss: 0.641345, acc:  75%] time: 0:23:38.246303\n",
      "[Epoch 2/5] [Batch 100/1384] [T loss: 0.233494, acc: 100%] time: 0:23:45.954101\n",
      "[Epoch 2/5] [Batch 120/1384] [T loss: 0.610470, acc:  75%] time: 0:23:53.640468\n",
      "[Epoch 2/5] [Batch 140/1384] [T loss: 0.002305, acc: 100%] time: 0:24:01.225587\n",
      "[Epoch 2/5] [Batch 160/1384] [T loss: 0.079418, acc: 100%] time: 0:24:08.791788\n",
      "[Epoch 2/5] [Batch 180/1384] [T loss: 0.002508, acc: 100%] time: 0:24:16.351480\n",
      "[Epoch 2/5] [Batch 200/1384] [T loss: 0.002458, acc: 100%] time: 0:24:23.921050\n",
      "[Epoch 2/5] [Batch 220/1384] [T loss: 0.697177, acc:  50%] time: 0:24:31.484558\n",
      "[Epoch 2/5] [Batch 240/1384] [T loss: 0.002502, acc: 100%] time: 0:24:39.147175\n",
      "[Epoch 2/5] [Batch 260/1384] [T loss: 0.443548, acc:  75%] time: 0:24:46.861832\n",
      "[Epoch 2/5] [Batch 280/1384] [T loss: 0.359131, acc:  75%] time: 0:24:54.471843\n",
      "[Epoch 2/5] [Batch 300/1384] [T loss: 0.002525, acc: 100%] time: 0:25:02.128368\n",
      "[Epoch 2/5] [Batch 320/1384] [T loss: 0.010583, acc: 100%] time: 0:25:15.407331\n",
      "[Epoch 2/5] [Batch 340/1384] [T loss: 0.399736, acc:  75%] time: 0:25:23.097719\n",
      "[Epoch 2/5] [Batch 360/1384] [T loss: 0.002840, acc: 100%] time: 0:25:30.654182\n",
      "[Epoch 2/5] [Batch 380/1384] [T loss: 0.106627, acc: 100%] time: 0:25:38.276064\n",
      "[Epoch 2/5] [Batch 400/1384] [T loss: 0.522440, acc:  75%] time: 0:25:45.926528\n",
      "[Epoch 2/5] [Batch 420/1384] [T loss: 0.002538, acc: 100%] time: 0:25:53.538807\n",
      "[Epoch 2/5] [Batch 440/1384] [T loss: 0.002586, acc: 100%] time: 0:26:01.213663\n",
      "[Epoch 2/5] [Batch 460/1384] [T loss: 0.942338, acc:  50%] time: 0:26:08.841514\n",
      "[Epoch 2/5] [Batch 480/1384] [T loss: 0.871793, acc:  75%] time: 0:26:16.506763\n",
      "[Epoch 2/5] [Batch 500/1384] [T loss: 0.002580, acc: 100%] time: 0:26:24.133970\n",
      "[Epoch 2/5] [Batch 520/1384] [T loss: 0.202595, acc: 100%] time: 0:26:31.731566\n",
      "[Epoch 2/5] [Batch 540/1384] [T loss: 0.002597, acc: 100%] time: 0:26:39.306869\n",
      "[Epoch 2/5] [Batch 560/1384] [T loss: 0.002741, acc: 100%] time: 0:26:46.899724\n",
      "[Epoch 2/5] [Batch 580/1384] [T loss: 0.002572, acc: 100%] time: 0:26:54.511379\n",
      "[Epoch 2/5] [Batch 600/1384] [T loss: 0.002581, acc: 100%] time: 0:27:02.097549\n",
      "[Epoch 2/5] [Batch 620/1384] [T loss: 0.664413, acc:  75%] time: 0:27:09.697526\n",
      "[Epoch 2/5] [Batch 640/1384] [T loss: 0.540108, acc:  75%] time: 0:27:17.225256\n",
      "[Epoch 2/5] [Batch 660/1384] [T loss: 0.063079, acc: 100%] time: 0:27:24.789383\n",
      "[Epoch 2/5] [Batch 680/1384] [T loss: 0.106974, acc: 100%] time: 0:27:32.343750\n",
      "[Epoch 2/5] [Batch 700/1384] [T loss: 0.002533, acc: 100%] time: 0:27:39.953874\n",
      "[Epoch 2/5] [Batch 720/1384] [T loss: 0.198806, acc: 100%] time: 0:27:47.737028\n",
      "[Epoch 2/5] [Batch 740/1384] [T loss: 0.189773, acc: 100%] time: 0:27:55.520190\n",
      "[Epoch 2/5] [Batch 760/1384] [T loss: 0.214450, acc:  75%] time: 0:28:03.094056\n",
      "[Epoch 2/5] [Batch 780/1384] [T loss: 0.830867, acc:  75%] time: 0:28:10.702393\n",
      "[Epoch 2/5] [Batch 800/1384] [T loss: 0.002481, acc: 100%] time: 0:28:18.330013\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2/5] [Batch 820/1384] [T loss: 0.509232, acc:  75%] time: 0:28:25.907947\n",
      "[Epoch 2/5] [Batch 840/1384] [T loss: 0.002466, acc: 100%] time: 0:28:33.534364\n",
      "[Epoch 2/5] [Batch 860/1384] [T loss: 0.002354, acc: 100%] time: 0:28:41.125637\n",
      "[Epoch 2/5] [Batch 880/1384] [T loss: 0.654690, acc:  75%] time: 0:28:48.824296\n",
      "[Epoch 2/5] [Batch 900/1384] [T loss: 0.065704, acc: 100%] time: 0:28:56.406724\n",
      "[Epoch 2/5] [Batch 920/1384] [T loss: 0.652357, acc:  75%] time: 0:29:04.083688\n",
      "[Epoch 2/5] [Batch 940/1384] [T loss: 1.356575, acc:  25%] time: 0:29:11.727894\n",
      "[Epoch 2/5] [Batch 960/1384] [T loss: 0.398164, acc:  75%] time: 0:29:19.388073\n",
      "[Epoch 2/5] [Batch 980/1384] [T loss: 0.002324, acc: 100%] time: 0:29:27.056021\n",
      "[Epoch 2/5] [Batch 1000/1384] [T loss: 0.016345, acc: 100%] time: 0:29:34.766678\n",
      "[Epoch 2/5] [Batch 1020/1384] [T loss: 0.054519, acc: 100%] time: 0:29:42.485788\n",
      "[Epoch 2/5] [Batch 1040/1384] [T loss: 0.586612, acc:  75%] time: 0:29:50.212929\n",
      "[Epoch 2/5] [Batch 1060/1384] [T loss: 0.049542, acc: 100%] time: 0:29:57.894370\n",
      "[Epoch 2/5] [Batch 1080/1384] [T loss: 0.002260, acc: 100%] time: 0:30:05.514427\n",
      "[Epoch 2/5] [Batch 1100/1384] [T loss: 0.645457, acc:  75%] time: 0:30:13.138118\n",
      "[Epoch 2/5] [Batch 1120/1384] [T loss: 0.385612, acc:  75%] time: 0:30:20.783269\n",
      "[Epoch 2/5] [Batch 1140/1384] [T loss: 0.002358, acc: 100%] time: 0:30:28.456788\n",
      "[Epoch 2/5] [Batch 1160/1384] [T loss: 0.002306, acc: 100%] time: 0:30:36.031784\n",
      "[Epoch 2/5] [Batch 1180/1384] [T loss: 0.002329, acc: 100%] time: 0:30:43.733246\n",
      "[Epoch 2/5] [Batch 1200/1384] [T loss: 0.317155, acc: 100%] time: 0:30:51.478740\n",
      "[Epoch 2/5] [Batch 1220/1384] [T loss: 0.096013, acc: 100%] time: 0:30:59.009837\n",
      "[Epoch 2/5] [Batch 1240/1384] [T loss: 0.503693, acc:  50%] time: 0:31:06.600421\n",
      "[Epoch 2/5] [Batch 1260/1384] [T loss: 0.002368, acc: 100%] time: 0:31:14.224209\n",
      "[Epoch 2/5] [Batch 1280/1384] [T loss: 0.021710, acc: 100%] time: 0:31:21.870745\n",
      "[Epoch 2/5] [Batch 1300/1384] [T loss: 0.002620, acc: 100%] time: 0:31:29.617004\n",
      "[Epoch 2/5] [Batch 1320/1384] [T loss: 0.052826, acc: 100%] time: 0:31:43.795818\n",
      "[Epoch 2/5] [Batch 1340/1384] [T loss: 0.002600, acc: 100%] time: 0:31:51.317307\n",
      "[Epoch 2/5] [Batch 1360/1384] [T loss: 0.642262, acc:  75%] time: 0:31:58.839687\n",
      "[Epoch 2/5] [Batch 1380/1384] [T loss: 0.015921, acc: 100%] time: 0:32:06.400186\n",
      "[Total testing images: 50 ] [2 class accuracy 92.0%] [40:46/50][100:0/0][200:0/0][400:0/0]\n",
      "[Total testing images: 100 ] [2 class accuracy 94.0%] [40:94/100][100:0/0][200:0/0][400:0/0]\n",
      "[Total testing images: 150 ] [2 class accuracy 94.0%] [40:141/150][100:0/0][200:0/0][400:0/0]\n",
      "[Total testing images: 200 ] [2 class accuracy 94.5%] [40:189/200][100:0/0][200:0/0][400:0/0]\n",
      "[Total testing images: 250 ] [2 class accuracy 94.39999999999999%] [40:236/250][100:0/0][200:0/0][400:0/0]\n",
      "[Total testing images: 300 ] [2 class accuracy 93.66666666666667%] [40:281/300][100:0/0][200:0/0][400:0/0]\n",
      "[Total testing images: 350 ] [2 class accuracy 93.14285714285714%] [40:326/350][100:0/0][200:0/0][400:0/0]\n",
      "[Total testing images: 400 ] [2 class accuracy 93.75%] [40:375/400][100:0/0][200:0/0][400:0/0]\n",
      "[Total testing images: 450 ] [2 class accuracy 93.77777777777779%] [40:422/450][100:0/0][200:0/0][400:0/0]\n",
      "[Total testing images: 500 ] [2 class accuracy 94.19999999999999%] [40:471/500][100:0/0][200:0/0][400:0/0]\n",
      "[Total testing images: 550 ] [2 class accuracy 94.0%] [40:517/550][100:0/0][200:0/0][400:0/0]\n",
      "[Total testing images: 600 ] [2 class accuracy 94.16666666666667%] [40:563/598][100:2/2][200:0/0][400:0/0]\n",
      "[Total testing images: 650 ] [2 class accuracy 93.53846153846153%] [40:563/598][100:45/52][200:0/0][400:0/0]\n",
      "[Total testing images: 700 ] [2 class accuracy 93.28571428571428%] [40:563/598][100:90/102][200:0/0][400:0/0]\n",
      "[Total testing images: 750 ] [2 class accuracy 93.06666666666666%] [40:563/598][100:135/152][200:0/0][400:0/0]\n",
      "[Total testing images: 800 ] [2 class accuracy 93.0%] [40:563/598][100:181/202][200:0/0][400:0/0]\n",
      "[Total testing images: 850 ] [2 class accuracy 93.05882352941175%] [40:563/598][100:228/252][200:0/0][400:0/0]\n",
      "[Total testing images: 900 ] [2 class accuracy 92.77777777777779%] [40:563/598][100:272/302][200:0/0][400:0/0]\n",
      "[Total testing images: 950 ] [2 class accuracy 92.42105263157895%] [40:563/598][100:315/352][200:0/0][400:0/0]\n",
      "[Total testing images: 1000 ] [2 class accuracy 92.5%] [40:563/598][100:362/402][200:0/0][400:0/0]\n",
      "[Total testing images: 1050 ] [2 class accuracy 92.47619047619048%] [40:563/598][100:408/452][200:0/0][400:0/0]\n",
      "[Total testing images: 1100 ] [2 class accuracy 92.54545454545455%] [40:563/598][100:455/502][200:0/0][400:0/0]\n",
      "[Total testing images: 1150 ] [2 class accuracy 92.26086956521739%] [40:563/598][100:498/552][200:0/0][400:0/0]\n",
      "[Total testing images: 1200 ] [2 class accuracy 92.33333333333333%] [40:563/598][100:545/602][200:0/0][400:0/0]\n",
      "[Total testing images: 1250 ] [2 class accuracy 92.32000000000001%] [40:563/598][100:565/624][200:26/28][400:0/0]\n",
      "[Total testing images: 1300 ] [2 class accuracy 92.38461538461539%] [40:563/598][100:565/624][200:73/78][400:0/0]\n",
      "[Total testing images: 1350 ] [2 class accuracy 92.22222222222223%] [40:563/598][100:565/624][200:117/128][400:0/0]\n",
      "[Total testing images: 1400 ] [2 class accuracy 92.21428571428572%] [40:563/598][100:565/624][200:163/178][400:0/0]\n",
      "[Total testing images: 1450 ] [2 class accuracy 92.20689655172414%] [40:563/598][100:565/624][200:209/228][400:0/0]\n",
      "[Total testing images: 1500 ] [2 class accuracy 92.26666666666667%] [40:563/598][100:565/624][200:256/278][400:0/0]\n",
      "[Total testing images: 1550 ] [2 class accuracy 92.25806451612904%] [40:563/598][100:565/624][200:302/328][400:0/0]\n",
      "[Total testing images: 1600 ] [2 class accuracy 92.1875%] [40:563/598][100:565/624][200:347/378][400:0/0]\n",
      "[Total testing images: 1650 ] [2 class accuracy 92.18181818181819%] [40:563/598][100:565/624][200:393/428][400:0/0]\n",
      "[Total testing images: 1700 ] [2 class accuracy 92.17647058823529%] [40:563/598][100:565/624][200:439/478][400:0/0]\n",
      "[Total testing images: 1750 ] [2 class accuracy 92.05714285714286%] [40:563/598][100:565/624][200:483/528][400:0/0]\n",
      "[Total testing images: 1800 ] [2 class accuracy 92.11111111111111%] [40:563/598][100:565/624][200:530/578][400:0/0]\n",
      "[Total testing images: 1850 ] [2 class accuracy 92.05405405405406%] [40:563/598][100:565/624][200:554/603][400:21/25]\n",
      "[Total testing images: 1900 ] [2 class accuracy 91.84210526315789%] [40:563/598][100:565/624][200:554/603][400:63/75]\n",
      "[Total testing images: 1950 ] [2 class accuracy 91.7948717948718%] [40:563/598][100:565/624][200:554/603][400:108/125]\n",
      "[Total testing images: 2000 ] [2 class accuracy 91.8%] [40:563/598][100:565/624][200:554/603][400:154/175]\n",
      "[Total testing images: 2050 ] [2 class accuracy 91.70731707317074%] [40:563/598][100:565/624][200:554/603][400:198/225]\n",
      "[Total testing images: 2100 ] [2 class accuracy 91.47619047619048%] [40:563/598][100:565/624][200:554/603][400:239/275]\n",
      "[Total testing images: 2150 ] [2 class accuracy 91.44186046511628%] [40:563/598][100:565/624][200:554/603][400:284/325]\n",
      "[Total testing images: 2200 ] [2 class accuracy 91.31818181818183%] [40:563/598][100:565/624][200:554/603][400:327/375]\n",
      "[Total testing images: 2250 ] [2 class accuracy 91.06666666666666%] [40:563/598][100:565/624][200:554/603][400:367/425]\n",
      "[Total testing images: 2300 ] [2 class accuracy 91.04347826086958%] [40:563/598][100:565/624][200:554/603][400:412/475]\n",
      "[Total testing images: 2350 ] [2 class accuracy 90.97872340425532%] [40:563/598][100:565/624][200:554/603][400:456/525]\n",
      "[Epoch 3/5] [Batch 0/1384] [T loss: 0.439932, acc:  75%] time: 0:34:43.588860\n",
      "[Epoch 3/5] [Batch 20/1384] [T loss: 0.002747, acc: 100%] time: 0:34:51.317249\n",
      "[Epoch 3/5] [Batch 40/1384] [T loss: 0.054136, acc: 100%] time: 0:34:58.983647\n",
      "[Epoch 3/5] [Batch 60/1384] [T loss: 0.389894, acc:  75%] time: 0:35:06.620972\n",
      "[Epoch 3/5] [Batch 80/1384] [T loss: 0.002917, acc: 100%] time: 0:35:14.240607\n",
      "[Epoch 3/5] [Batch 100/1384] [T loss: 0.003707, acc: 100%] time: 0:35:21.929752\n",
      "[Epoch 3/5] [Batch 120/1384] [T loss: 0.623703, acc:  50%] time: 0:35:29.538104\n",
      "[Epoch 3/5] [Batch 140/1384] [T loss: 0.329015, acc:  75%] time: 0:35:37.249389\n",
      "[Epoch 3/5] [Batch 160/1384] [T loss: 0.306447, acc: 100%] time: 0:35:45.001431\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 3/5] [Batch 180/1384] [T loss: 0.002815, acc: 100%] time: 0:35:52.693679\n",
      "[Epoch 3/5] [Batch 200/1384] [T loss: 0.191834, acc: 100%] time: 0:36:00.359481\n",
      "[Epoch 3/5] [Batch 220/1384] [T loss: 0.006721, acc: 100%] time: 0:36:08.022003\n",
      "[Epoch 3/5] [Batch 240/1384] [T loss: 0.002710, acc: 100%] time: 0:36:15.703637\n",
      "[Epoch 3/5] [Batch 260/1384] [T loss: 0.024113, acc: 100%] time: 0:36:23.448205\n",
      "[Epoch 3/5] [Batch 280/1384] [T loss: 0.157863, acc:  75%] time: 0:36:31.160962\n",
      "[Epoch 3/5] [Batch 300/1384] [T loss: 0.309326, acc:  75%] time: 0:36:38.725483\n",
      "[Epoch 3/5] [Batch 320/1384] [T loss: 0.238022, acc: 100%] time: 0:36:46.465970\n",
      "[Epoch 3/5] [Batch 340/1384] [T loss: 1.387471, acc:  25%] time: 0:36:54.039110\n",
      "[Epoch 3/5] [Batch 360/1384] [T loss: 0.380498, acc:  75%] time: 0:37:01.649674\n",
      "[Epoch 3/5] [Batch 380/1384] [T loss: 0.002391, acc: 100%] time: 0:37:09.258351\n",
      "[Epoch 3/5] [Batch 400/1384] [T loss: 0.115750, acc: 100%] time: 0:37:16.838197\n",
      "[Epoch 3/5] [Batch 420/1384] [T loss: 0.498885, acc:  75%] time: 0:37:24.398082\n",
      "[Epoch 3/5] [Batch 440/1384] [T loss: 0.002381, acc: 100%] time: 0:37:31.959524\n",
      "[Epoch 3/5] [Batch 460/1384] [T loss: 0.135048, acc: 100%] time: 0:37:39.511067\n",
      "[Epoch 3/5] [Batch 480/1384] [T loss: 0.028373, acc: 100%] time: 0:37:47.136884\n",
      "[Epoch 3/5] [Batch 500/1384] [T loss: 0.324343, acc: 100%] time: 0:37:54.840808\n",
      "[Epoch 3/5] [Batch 520/1384] [T loss: 0.144252, acc:  75%] time: 0:38:02.364669\n",
      "[Epoch 3/5] [Batch 540/1384] [T loss: 0.002496, acc: 100%] time: 0:38:10.076549\n",
      "[Epoch 3/5] [Batch 560/1384] [T loss: 0.397758, acc:  75%] time: 0:38:17.836319\n",
      "[Epoch 3/5] [Batch 580/1384] [T loss: 0.053527, acc: 100%] time: 0:38:25.458721\n",
      "[Epoch 3/5] [Batch 600/1384] [T loss: 0.543387, acc:  75%] time: 0:38:33.150413\n",
      "[Epoch 3/5] [Batch 620/1384] [T loss: 0.002632, acc: 100%] time: 0:38:40.844299\n",
      "[Epoch 3/5] [Batch 640/1384] [T loss: 0.073408, acc: 100%] time: 0:38:48.548594\n",
      "[Epoch 3/5] [Batch 660/1384] [T loss: 0.035471, acc: 100%] time: 0:38:56.208900\n",
      "[Epoch 3/5] [Batch 680/1384] [T loss: 0.002706, acc: 100%] time: 0:39:03.769996\n",
      "[Epoch 3/5] [Batch 700/1384] [T loss: 0.002820, acc: 100%] time: 0:39:11.327950\n",
      "[Epoch 3/5] [Batch 720/1384] [T loss: 0.174163, acc: 100%] time: 0:39:18.848684\n",
      "[Epoch 3/5] [Batch 740/1384] [T loss: 0.002818, acc: 100%] time: 0:39:32.342563\n",
      "[Epoch 3/5] [Batch 760/1384] [T loss: 0.447925, acc:  75%] time: 0:39:40.019329\n",
      "[Epoch 3/5] [Batch 780/1384] [T loss: 0.650798, acc:  75%] time: 0:39:47.687174\n",
      "[Epoch 3/5] [Batch 800/1384] [T loss: 0.055936, acc: 100%] time: 0:39:55.302204\n",
      "[Epoch 3/5] [Batch 820/1384] [T loss: 0.002637, acc: 100%] time: 0:40:02.876329\n",
      "[Epoch 3/5] [Batch 840/1384] [T loss: 0.002599, acc: 100%] time: 0:40:10.418963\n",
      "[Epoch 3/5] [Batch 860/1384] [T loss: 0.002572, acc: 100%] time: 0:40:18.050583\n",
      "[Epoch 3/5] [Batch 880/1384] [T loss: 0.002777, acc: 100%] time: 0:40:25.606568\n",
      "[Epoch 3/5] [Batch 900/1384] [T loss: 0.765394, acc:  75%] time: 0:40:33.150568\n",
      "[Epoch 3/5] [Batch 920/1384] [T loss: 0.002752, acc: 100%] time: 0:40:40.801473\n",
      "[Epoch 3/5] [Batch 940/1384] [T loss: 0.027067, acc: 100%] time: 0:40:48.471043\n",
      "[Epoch 3/5] [Batch 960/1384] [T loss: 0.002593, acc: 100%] time: 0:40:56.057380\n",
      "[Epoch 3/5] [Batch 980/1384] [T loss: 0.040453, acc: 100%] time: 0:41:03.588610\n",
      "[Epoch 3/5] [Batch 1000/1384] [T loss: 0.768208, acc:  50%] time: 0:41:11.260622\n",
      "[Epoch 3/5] [Batch 1020/1384] [T loss: 0.195196, acc:  75%] time: 0:41:18.843180\n",
      "[Epoch 3/5] [Batch 1040/1384] [T loss: 0.002526, acc: 100%] time: 0:41:26.516587\n",
      "[Epoch 3/5] [Batch 1060/1384] [T loss: 0.002481, acc: 100%] time: 0:41:34.123876\n",
      "[Epoch 3/5] [Batch 1080/1384] [T loss: 0.157778, acc: 100%] time: 0:41:41.632225\n",
      "[Epoch 3/5] [Batch 1100/1384] [T loss: 0.002850, acc: 100%] time: 0:41:49.226269\n",
      "[Epoch 3/5] [Batch 1120/1384] [T loss: 0.215310, acc: 100%] time: 0:41:56.779280\n",
      "[Epoch 3/5] [Batch 1140/1384] [T loss: 0.002525, acc: 100%] time: 0:42:04.502522\n",
      "[Epoch 3/5] [Batch 1160/1384] [T loss: 0.008486, acc: 100%] time: 0:42:12.088353\n",
      "[Epoch 3/5] [Batch 1180/1384] [T loss: 0.078916, acc: 100%] time: 0:42:19.698702\n",
      "[Epoch 3/5] [Batch 1200/1384] [T loss: 0.002616, acc: 100%] time: 0:42:27.241988\n",
      "[Epoch 3/5] [Batch 1220/1384] [T loss: 0.228259, acc: 100%] time: 0:42:34.853350\n",
      "[Epoch 3/5] [Batch 1240/1384] [T loss: 1.128764, acc:  50%] time: 0:42:42.429556\n",
      "[Epoch 3/5] [Batch 1260/1384] [T loss: 0.736863, acc:  75%] time: 0:42:50.138963\n",
      "[Epoch 3/5] [Batch 1280/1384] [T loss: 0.541559, acc:  75%] time: 0:42:57.777838\n",
      "[Epoch 3/5] [Batch 1300/1384] [T loss: 0.216814, acc: 100%] time: 0:43:05.355932\n",
      "[Epoch 3/5] [Batch 1320/1384] [T loss: 0.002796, acc: 100%] time: 0:43:13.068058\n",
      "[Epoch 3/5] [Batch 1340/1384] [T loss: 0.002806, acc: 100%] time: 0:43:20.761710\n",
      "[Epoch 3/5] [Batch 1360/1384] [T loss: 0.166794, acc: 100%] time: 0:43:28.409802\n",
      "[Epoch 3/5] [Batch 1380/1384] [T loss: 0.002642, acc: 100%] time: 0:43:36.010339\n",
      "[Total testing images: 50 ] [2 class accuracy 86.0%] [40:43/50][100:0/0][200:0/0][400:0/0]\n",
      "[Total testing images: 100 ] [2 class accuracy 89.0%] [40:89/100][100:0/0][200:0/0][400:0/0]\n",
      "[Total testing images: 150 ] [2 class accuracy 86.0%] [40:129/150][100:0/0][200:0/0][400:0/0]\n",
      "[Total testing images: 200 ] [2 class accuracy 88.5%] [40:177/200][100:0/0][200:0/0][400:0/0]\n",
      "[Total testing images: 250 ] [2 class accuracy 88.4%] [40:221/250][100:0/0][200:0/0][400:0/0]\n",
      "[Total testing images: 300 ] [2 class accuracy 88.0%] [40:264/300][100:0/0][200:0/0][400:0/0]\n",
      "[Total testing images: 350 ] [2 class accuracy 87.71428571428571%] [40:307/350][100:0/0][200:0/0][400:0/0]\n",
      "[Total testing images: 400 ] [2 class accuracy 88.75%] [40:355/400][100:0/0][200:0/0][400:0/0]\n",
      "[Total testing images: 450 ] [2 class accuracy 89.33333333333333%] [40:402/450][100:0/0][200:0/0][400:0/0]\n",
      "[Total testing images: 500 ] [2 class accuracy 89.0%] [40:445/500][100:0/0][200:0/0][400:0/0]\n",
      "[Total testing images: 550 ] [2 class accuracy 89.0909090909091%] [40:490/550][100:0/0][200:0/0][400:0/0]\n",
      "[Total testing images: 600 ] [2 class accuracy 89.66666666666666%] [40:536/598][100:2/2][200:0/0][400:0/0]\n",
      "[Total testing images: 650 ] [2 class accuracy 89.23076923076924%] [40:536/598][100:44/52][200:0/0][400:0/0]\n",
      "[Total testing images: 700 ] [2 class accuracy 89.14285714285714%] [40:536/598][100:88/102][200:0/0][400:0/0]\n",
      "[Total testing images: 750 ] [2 class accuracy 88.66666666666667%] [40:536/598][100:129/152][200:0/0][400:0/0]\n",
      "[Total testing images: 800 ] [2 class accuracy 88.5%] [40:536/598][100:172/202][200:0/0][400:0/0]\n",
      "[Total testing images: 850 ] [2 class accuracy 88.47058823529412%] [40:536/598][100:216/252][200:0/0][400:0/0]\n",
      "[Total testing images: 900 ] [2 class accuracy 88.33333333333333%] [40:536/598][100:259/302][200:0/0][400:0/0]\n",
      "[Total testing images: 950 ] [2 class accuracy 88.0%] [40:536/598][100:300/352][200:0/0][400:0/0]\n",
      "[Total testing images: 1000 ] [2 class accuracy 88.0%] [40:536/598][100:344/402][200:0/0][400:0/0]\n",
      "[Total testing images: 1050 ] [2 class accuracy 88.28571428571429%] [40:536/598][100:391/452][200:0/0][400:0/0]\n",
      "[Total testing images: 1100 ] [2 class accuracy 88.36363636363636%] [40:536/598][100:436/502][200:0/0][400:0/0]\n",
      "[Total testing images: 1150 ] [2 class accuracy 88.34782608695653%] [40:536/598][100:480/552][200:0/0][400:0/0]\n",
      "[Total testing images: 1200 ] [2 class accuracy 88.33333333333333%] [40:536/598][100:524/602][200:0/0][400:0/0]\n",
      "[Total testing images: 1250 ] [2 class accuracy 88.4%] [40:536/598][100:543/624][200:26/28][400:0/0]\n",
      "[Total testing images: 1300 ] [2 class accuracy 88.53846153846155%] [40:536/598][100:543/624][200:72/78][400:0/0]\n",
      "[Total testing images: 1350 ] [2 class accuracy 88.37037037037037%] [40:536/598][100:543/624][200:114/128][400:0/0]\n",
      "[Total testing images: 1400 ] [2 class accuracy 88.28571428571429%] [40:536/598][100:543/624][200:157/178][400:0/0]\n",
      "[Total testing images: 1450 ] [2 class accuracy 88.27586206896552%] [40:536/598][100:543/624][200:201/228][400:0/0]\n",
      "[Total testing images: 1500 ] [2 class accuracy 88.33333333333333%] [40:536/598][100:543/624][200:246/278][400:0/0]\n",
      "[Total testing images: 1550 ] [2 class accuracy 88.38709677419355%] [40:536/598][100:543/624][200:291/328][400:0/0]\n",
      "[Total testing images: 1600 ] [2 class accuracy 88.25%] [40:536/598][100:543/624][200:333/378][400:0/0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Total testing images: 1650 ] [2 class accuracy 88.36363636363636%] [40:536/598][100:543/624][200:379/428][400:0/0]\n",
      "[Total testing images: 1700 ] [2 class accuracy 88.41176470588236%] [40:536/598][100:543/624][200:424/478][400:0/0]\n",
      "[Total testing images: 1750 ] [2 class accuracy 88.4%] [40:536/598][100:543/624][200:468/528][400:0/0]\n",
      "[Total testing images: 1800 ] [2 class accuracy 88.44444444444444%] [40:536/598][100:543/624][200:513/578][400:0/0]\n",
      "[Total testing images: 1850 ] [2 class accuracy 88.37837837837837%] [40:536/598][100:543/624][200:537/603][400:19/25]\n",
      "[Total testing images: 1900 ] [2 class accuracy 88.21052631578948%] [40:536/598][100:543/624][200:537/603][400:60/75]\n",
      "[Total testing images: 1950 ] [2 class accuracy 88.25641025641026%] [40:536/598][100:543/624][200:537/603][400:105/125]\n",
      "[Total testing images: 2000 ] [2 class accuracy 88.35%] [40:536/598][100:543/624][200:537/603][400:151/175]\n",
      "[Total testing images: 2050 ] [2 class accuracy 88.29268292682927%] [40:536/598][100:543/624][200:537/603][400:194/225]\n",
      "[Total testing images: 2100 ] [2 class accuracy 87.95238095238095%] [40:536/598][100:543/624][200:537/603][400:231/275]\n",
      "[Total testing images: 2150 ] [2 class accuracy 87.95348837209302%] [40:536/598][100:543/624][200:537/603][400:275/325]\n",
      "[Total testing images: 2200 ] [2 class accuracy 87.86363636363636%] [40:536/598][100:543/624][200:537/603][400:317/375]\n",
      "[Total testing images: 2250 ] [2 class accuracy 87.46666666666667%] [40:536/598][100:543/624][200:537/603][400:352/425]\n",
      "[Total testing images: 2300 ] [2 class accuracy 87.47826086956522%] [40:536/598][100:543/624][200:537/603][400:396/475]\n",
      "[Total testing images: 2350 ] [2 class accuracy 87.40425531914894%] [40:536/598][100:543/624][200:537/603][400:438/525]\n",
      "[Epoch 4/5] [Batch 0/1384] [T loss: 0.002624, acc: 100%] time: 0:46:19.431662\n",
      "[Epoch 4/5] [Batch 20/1384] [T loss: 0.585496, acc:  75%] time: 0:46:27.019950\n",
      "[Epoch 4/5] [Batch 40/1384] [T loss: 0.527459, acc:  75%] time: 0:46:34.619937\n",
      "[Epoch 4/5] [Batch 60/1384] [T loss: 0.348621, acc:  75%] time: 0:46:42.204798\n",
      "[Epoch 4/5] [Batch 80/1384] [T loss: 0.462348, acc:  75%] time: 0:46:49.810691\n",
      "[Epoch 4/5] [Batch 100/1384] [T loss: 0.002403, acc: 100%] time: 0:46:57.447248\n",
      "[Epoch 4/5] [Batch 120/1384] [T loss: 0.002452, acc: 100%] time: 0:47:05.042597\n",
      "[Epoch 4/5] [Batch 140/1384] [T loss: 0.002660, acc: 100%] time: 0:47:12.605490\n",
      "[Epoch 4/5] [Batch 160/1384] [T loss: 0.002619, acc: 100%] time: 0:47:20.268665\n",
      "[Epoch 4/5] [Batch 180/1384] [T loss: 0.002606, acc: 100%] time: 0:47:27.877689\n",
      "[Epoch 4/5] [Batch 200/1384] [T loss: 0.259666, acc: 100%] time: 0:47:35.536140\n",
      "[Epoch 4/5] [Batch 220/1384] [T loss: 0.080152, acc: 100%] time: 0:47:43.180463\n",
      "[Epoch 4/5] [Batch 240/1384] [T loss: 0.020149, acc: 100%] time: 0:47:50.831238\n",
      "[Epoch 4/5] [Batch 260/1384] [T loss: 0.026974, acc: 100%] time: 0:47:58.441344\n",
      "[Epoch 4/5] [Batch 280/1384] [T loss: 0.002712, acc: 100%] time: 0:48:06.027586\n",
      "[Epoch 4/5] [Batch 300/1384] [T loss: 0.369103, acc: 100%] time: 0:48:13.539507\n",
      "[Epoch 4/5] [Batch 320/1384] [T loss: 0.002719, acc: 100%] time: 0:48:21.062979\n",
      "[Epoch 4/5] [Batch 340/1384] [T loss: 0.002763, acc: 100%] time: 0:48:28.695675\n",
      "[Epoch 4/5] [Batch 360/1384] [T loss: 0.155600, acc: 100%] time: 0:48:36.426905\n",
      "[Epoch 4/5] [Batch 380/1384] [T loss: 0.002889, acc: 100%] time: 0:48:44.092476\n",
      "[Epoch 4/5] [Batch 400/1384] [T loss: 0.002797, acc: 100%] time: 0:48:51.739613\n",
      "[Epoch 4/5] [Batch 420/1384] [T loss: 0.187797, acc:  75%] time: 0:48:59.358852\n",
      "[Epoch 4/5] [Batch 440/1384] [T loss: 0.501666, acc:  75%] time: 0:49:06.968615\n",
      "[Epoch 4/5] [Batch 460/1384] [T loss: 0.002756, acc: 100%] time: 0:49:14.604240\n",
      "[Epoch 4/5] [Batch 480/1384] [T loss: 0.548949, acc:  75%] time: 0:49:22.211187\n",
      "[Epoch 4/5] [Batch 500/1384] [T loss: 0.002709, acc: 100%] time: 0:49:29.802709\n",
      "[Epoch 4/5] [Batch 520/1384] [T loss: 0.308744, acc:  75%] time: 0:49:37.386998\n",
      "[Epoch 4/5] [Batch 540/1384] [T loss: 0.002729, acc: 100%] time: 0:49:45.038265\n",
      "[Epoch 4/5] [Batch 560/1384] [T loss: 0.002714, acc: 100%] time: 0:49:52.684271\n",
      "[Epoch 4/5] [Batch 580/1384] [T loss: 0.100340, acc: 100%] time: 0:50:00.299540\n",
      "[Epoch 4/5] [Batch 600/1384] [T loss: 0.109978, acc: 100%] time: 0:50:07.936182\n",
      "[Epoch 4/5] [Batch 620/1384] [T loss: 0.568346, acc:  75%] time: 0:50:15.572985\n",
      "[Epoch 4/5] [Batch 640/1384] [T loss: 0.246453, acc:  75%] time: 0:50:23.156423\n",
      "[Epoch 4/5] [Batch 660/1384] [T loss: 0.002823, acc: 100%] time: 0:50:30.756378\n",
      "[Epoch 4/5] [Batch 680/1384] [T loss: 0.002780, acc: 100%] time: 0:50:38.471406\n",
      "[Epoch 4/5] [Batch 700/1384] [T loss: 0.002747, acc: 100%] time: 0:50:46.124541\n",
      "[Epoch 4/5] [Batch 720/1384] [T loss: 0.315834, acc:  75%] time: 0:50:53.796448\n",
      "[Epoch 4/5] [Batch 740/1384] [T loss: 0.104500, acc: 100%] time: 0:51:01.417226\n",
      "[Epoch 4/5] [Batch 760/1384] [T loss: 0.002682, acc: 100%] time: 0:51:09.019436\n",
      "[Epoch 4/5] [Batch 780/1384] [T loss: 0.097078, acc: 100%] time: 0:51:16.754088\n",
      "[Epoch 4/5] [Batch 800/1384] [T loss: 0.635323, acc:  75%] time: 0:51:24.400758\n",
      "[Epoch 4/5] [Batch 820/1384] [T loss: 0.444989, acc:  75%] time: 0:51:31.995985\n",
      "[Epoch 4/5] [Batch 840/1384] [T loss: 0.002717, acc: 100%] time: 0:51:39.634197\n",
      "[Epoch 4/5] [Batch 860/1384] [T loss: 0.002725, acc: 100%] time: 0:51:47.311517\n",
      "[Epoch 4/5] [Batch 880/1384] [T loss: 0.002647, acc: 100%] time: 0:51:54.969871\n",
      "[Epoch 4/5] [Batch 900/1384] [T loss: 0.002721, acc: 100%] time: 0:52:02.548800\n",
      "[Epoch 4/5] [Batch 920/1384] [T loss: 0.002597, acc: 100%] time: 0:52:10.203843\n",
      "[Epoch 4/5] [Batch 940/1384] [T loss: 0.578514, acc:  75%] time: 0:52:17.789450\n",
      "[Epoch 4/5] [Batch 960/1384] [T loss: 0.609820, acc:  75%] time: 0:52:25.402656\n",
      "[Epoch 4/5] [Batch 980/1384] [T loss: 0.002568, acc: 100%] time: 0:52:33.018755\n",
      "[Epoch 4/5] [Batch 1000/1384] [T loss: 0.002546, acc: 100%] time: 0:52:40.668911\n",
      "[Epoch 4/5] [Batch 1020/1384] [T loss: 0.002567, acc: 100%] time: 0:52:48.298597\n",
      "[Epoch 4/5] [Batch 1040/1384] [T loss: 0.002582, acc: 100%] time: 0:52:55.871679\n",
      "[Epoch 4/5] [Batch 1060/1384] [T loss: 0.400931, acc: 100%] time: 0:53:03.469525\n",
      "[Epoch 4/5] [Batch 1080/1384] [T loss: 0.559346, acc:  50%] time: 0:53:11.122496\n",
      "[Epoch 4/5] [Batch 1100/1384] [T loss: 0.357207, acc: 100%] time: 0:53:18.700503\n",
      "[Epoch 4/5] [Batch 1120/1384] [T loss: 0.002551, acc: 100%] time: 0:53:26.339345\n",
      "[Epoch 4/5] [Batch 1140/1384] [T loss: 0.002459, acc: 100%] time: 0:53:33.936612\n",
      "[Epoch 4/5] [Batch 1160/1384] [T loss: 0.519266, acc:  75%] time: 0:53:41.739257\n",
      "[Epoch 4/5] [Batch 1180/1384] [T loss: 0.122110, acc: 100%] time: 0:53:56.075587\n",
      "[Epoch 4/5] [Batch 1200/1384] [T loss: 0.002559, acc: 100%] time: 0:54:03.687048\n",
      "[Epoch 4/5] [Batch 1220/1384] [T loss: 0.315675, acc:  75%] time: 0:54:11.265969\n",
      "[Epoch 4/5] [Batch 1240/1384] [T loss: 0.002635, acc: 100%] time: 0:54:18.913877\n",
      "[Epoch 4/5] [Batch 1260/1384] [T loss: 0.002724, acc: 100%] time: 0:54:26.472972\n",
      "[Epoch 4/5] [Batch 1280/1384] [T loss: 0.145915, acc:  75%] time: 0:54:34.099990\n",
      "[Epoch 4/5] [Batch 1300/1384] [T loss: 0.012430, acc: 100%] time: 0:54:41.768045\n",
      "[Epoch 4/5] [Batch 1320/1384] [T loss: 0.002588, acc: 100%] time: 0:54:49.417271\n",
      "[Epoch 4/5] [Batch 1340/1384] [T loss: 0.002596, acc: 100%] time: 0:54:57.037940\n",
      "[Epoch 4/5] [Batch 1360/1384] [T loss: 0.538504, acc:  75%] time: 0:55:04.695489\n",
      "[Epoch 4/5] [Batch 1380/1384] [T loss: 0.098372, acc: 100%] time: 0:55:12.308926\n",
      "[Total testing images: 50 ] [2 class accuracy 90.0%] [40:45/50][100:0/0][200:0/0][400:0/0]\n",
      "[Total testing images: 100 ] [2 class accuracy 92.0%] [40:92/100][100:0/0][200:0/0][400:0/0]\n",
      "[Total testing images: 150 ] [2 class accuracy 93.33333333333333%] [40:140/150][100:0/0][200:0/0][400:0/0]\n",
      "[Total testing images: 200 ] [2 class accuracy 95.0%] [40:190/200][100:0/0][200:0/0][400:0/0]\n",
      "[Total testing images: 250 ] [2 class accuracy 92.80000000000001%] [40:232/250][100:0/0][200:0/0][400:0/0]\n",
      "[Total testing images: 300 ] [2 class accuracy 93.0%] [40:279/300][100:0/0][200:0/0][400:0/0]\n",
      "[Total testing images: 350 ] [2 class accuracy 92.57142857142857%] [40:324/350][100:0/0][200:0/0][400:0/0]\n",
      "[Total testing images: 400 ] [2 class accuracy 93.25%] [40:373/400][100:0/0][200:0/0][400:0/0]\n",
      "[Total testing images: 450 ] [2 class accuracy 93.11111111111111%] [40:419/450][100:0/0][200:0/0][400:0/0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Total testing images: 500 ] [2 class accuracy 93.60000000000001%] [40:468/500][100:0/0][200:0/0][400:0/0]\n",
      "[Total testing images: 550 ] [2 class accuracy 93.63636363636364%] [40:515/550][100:0/0][200:0/0][400:0/0]\n",
      "[Total testing images: 600 ] [2 class accuracy 94.16666666666667%] [40:563/598][100:2/2][200:0/0][400:0/0]\n",
      "[Total testing images: 650 ] [2 class accuracy 94.0%] [40:563/598][100:48/52][200:0/0][400:0/0]\n",
      "[Total testing images: 700 ] [2 class accuracy 94.0%] [40:563/598][100:95/102][200:0/0][400:0/0]\n",
      "[Total testing images: 750 ] [2 class accuracy 94.0%] [40:563/598][100:142/152][200:0/0][400:0/0]\n",
      "[Total testing images: 800 ] [2 class accuracy 93.875%] [40:563/598][100:188/202][200:0/0][400:0/0]\n",
      "[Total testing images: 850 ] [2 class accuracy 93.88235294117648%] [40:563/598][100:235/252][200:0/0][400:0/0]\n",
      "[Total testing images: 900 ] [2 class accuracy 93.77777777777779%] [40:563/598][100:281/302][200:0/0][400:0/0]\n",
      "[Total testing images: 950 ] [2 class accuracy 93.47368421052632%] [40:563/598][100:325/352][200:0/0][400:0/0]\n",
      "[Total testing images: 1000 ] [2 class accuracy 93.5%] [40:563/598][100:372/402][200:0/0][400:0/0]\n",
      "[Total testing images: 1050 ] [2 class accuracy 93.33333333333333%] [40:563/598][100:417/452][200:0/0][400:0/0]\n",
      "[Total testing images: 1100 ] [2 class accuracy 93.45454545454545%] [40:563/598][100:465/502][200:0/0][400:0/0]\n",
      "[Total testing images: 1150 ] [2 class accuracy 93.30434782608695%] [40:563/598][100:510/552][200:0/0][400:0/0]\n",
      "[Total testing images: 1200 ] [2 class accuracy 93.33333333333333%] [40:563/598][100:557/602][200:0/0][400:0/0]\n",
      "[Total testing images: 1250 ] [2 class accuracy 93.44%] [40:563/598][100:578/624][200:27/28][400:0/0]\n",
      "[Total testing images: 1300 ] [2 class accuracy 93.46153846153847%] [40:563/598][100:578/624][200:74/78][400:0/0]\n",
      "[Total testing images: 1350 ] [2 class accuracy 93.33333333333333%] [40:563/598][100:578/624][200:119/128][400:0/0]\n",
      "[Total testing images: 1400 ] [2 class accuracy 93.21428571428572%] [40:563/598][100:578/624][200:164/178][400:0/0]\n",
      "[Total testing images: 1450 ] [2 class accuracy 93.3103448275862%] [40:563/598][100:578/624][200:212/228][400:0/0]\n",
      "[Total testing images: 1500 ] [2 class accuracy 93.33333333333333%] [40:563/598][100:578/624][200:259/278][400:0/0]\n",
      "[Total testing images: 1550 ] [2 class accuracy 93.41935483870968%] [40:563/598][100:578/624][200:307/328][400:0/0]\n",
      "[Total testing images: 1600 ] [2 class accuracy 93.4375%] [40:563/598][100:578/624][200:354/378][400:0/0]\n",
      "[Total testing images: 1650 ] [2 class accuracy 93.51515151515152%] [40:563/598][100:578/624][200:402/428][400:0/0]\n",
      "[Total testing images: 1700 ] [2 class accuracy 93.58823529411765%] [40:563/598][100:578/624][200:450/478][400:0/0]\n",
      "[Total testing images: 1750 ] [2 class accuracy 93.60000000000001%] [40:563/598][100:578/624][200:497/528][400:0/0]\n",
      "[Total testing images: 1800 ] [2 class accuracy 93.66666666666667%] [40:563/598][100:578/624][200:545/578][400:0/0]\n",
      "[Total testing images: 1850 ] [2 class accuracy 93.78378378378378%] [40:563/598][100:578/624][200:570/603][400:24/25]\n",
      "[Total testing images: 1900 ] [2 class accuracy 93.78947368421052%] [40:563/598][100:578/624][200:570/603][400:71/75]\n",
      "[Total testing images: 1950 ] [2 class accuracy 93.94871794871796%] [40:563/598][100:578/624][200:570/603][400:121/125]\n",
      "[Total testing images: 2000 ] [2 class accuracy 94.05%] [40:563/598][100:578/624][200:570/603][400:170/175]\n",
      "[Total testing images: 2050 ] [2 class accuracy 94.04878048780488%] [40:563/598][100:578/624][200:570/603][400:217/225]\n",
      "[Total testing images: 2100 ] [2 class accuracy 94.0%] [40:563/598][100:578/624][200:570/603][400:263/275]\n",
      "[Total testing images: 2150 ] [2 class accuracy 94.0%] [40:563/598][100:578/624][200:570/603][400:310/325]\n",
      "[Total testing images: 2200 ] [2 class accuracy 93.95454545454545%] [40:563/598][100:578/624][200:570/603][400:356/375]\n",
      "[Total testing images: 2250 ] [2 class accuracy 93.86666666666666%] [40:563/598][100:578/624][200:570/603][400:401/425]\n",
      "[Total testing images: 2300 ] [2 class accuracy 93.91304347826087%] [40:563/598][100:578/624][200:570/603][400:449/475]\n",
      "[Total testing images: 2350 ] [2 class accuracy 93.95744680851064%] [40:563/598][100:578/624][200:570/603][400:497/525]\n",
      "Model saved\n",
      "40x:92.475 +/- 2.0\n",
      "100x:90.513 +/- 2.0\n",
      "200x:92.04 +/- 2.0\n",
      "400x:88.242 +/- 4.0\n",
      "Average:90.873 +/- 2.0\n"
     ]
    }
   ],
   "source": [
    "input_ds_filename =\"/tf/dataset/classes\" \n",
    "bs = 4\n",
    "train_log, test_log = train_and_test_model(model, input_ds_filename,ratio=0.7, dataset_volume=7909, epochs=5,batch_size=bs, print_interval=20 , output_filename=\"/tf/experiments/resnet16_299x299_16.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 299, 299, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 149, 149, 32) 864         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1 (BatchNo (None, 149, 149, 32) 96          conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 149, 149, 32) 0           batch_normalization_v1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 147, 147, 32) 9216        activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_1 (Batch (None, 147, 147, 32) 96          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 147, 147, 32) 0           batch_normalization_v1_1[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 147, 147, 64) 18432       activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_2 (Batch (None, 147, 147, 64) 192         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 147, 147, 64) 0           batch_normalization_v1_2[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 73, 73, 64)   0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 73, 73, 80)   5120        max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_3 (Batch (None, 73, 73, 80)   240         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 73, 73, 80)   0           batch_normalization_v1_3[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 71, 71, 192)  138240      activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_4 (Batch (None, 71, 71, 192)  576         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 71, 71, 192)  0           batch_normalization_v1_4[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 35, 35, 192)  0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 35, 35, 64)   12288       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_8 (Batch (None, 35, 35, 64)   192         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 35, 35, 64)   0           batch_normalization_v1_8[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 35, 35, 48)   9216        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 35, 35, 96)   55296       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_6 (Batch (None, 35, 35, 48)   144         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_9 (Batch (None, 35, 35, 96)   288         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 35, 35, 48)   0           batch_normalization_v1_6[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 35, 35, 96)   0           batch_normalization_v1_9[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d (AveragePooli (None, 35, 35, 192)  0           max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 35, 35, 96)   18432       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 35, 35, 64)   76800       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 35, 35, 96)   82944       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 35, 35, 64)   12288       average_pooling2d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_5 (Batch (None, 35, 35, 96)   288         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_7 (Batch (None, 35, 35, 64)   192         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_10 (Batc (None, 35, 35, 96)   288         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_11 (Batc (None, 35, 35, 64)   192         conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 35, 35, 96)   0           batch_normalization_v1_5[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 35, 35, 64)   0           batch_normalization_v1_7[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 35, 35, 96)   0           batch_normalization_v1_10[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 35, 35, 64)   0           batch_normalization_v1_11[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "mixed_5b (Concatenate)          (None, 35, 35, 320)  0           activation_5[0][0]               \n",
      "                                                                 activation_7[0][0]               \n",
      "                                                                 activation_10[0][0]              \n",
      "                                                                 activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 35, 35, 32)   10240       mixed_5b[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_15 (Batc (None, 35, 35, 32)   96          conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 35, 35, 32)   0           batch_normalization_v1_15[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 35, 35, 32)   10240       mixed_5b[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 35, 35, 48)   13824       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_13 (Batc (None, 35, 35, 32)   96          conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_16 (Batc (None, 35, 35, 48)   144         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 35, 35, 32)   0           batch_normalization_v1_13[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 35, 35, 48)   0           batch_normalization_v1_16[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 35, 35, 32)   10240       mixed_5b[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 35, 35, 32)   9216        activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 35, 35, 64)   27648       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_12 (Batc (None, 35, 35, 32)   96          conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_14 (Batc (None, 35, 35, 32)   96          conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_17 (Batc (None, 35, 35, 64)   192         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 35, 35, 32)   0           batch_normalization_v1_12[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 35, 35, 32)   0           batch_normalization_v1_14[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 35, 35, 64)   0           batch_normalization_v1_17[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block35_1_mixed (Concatenate)   (None, 35, 35, 128)  0           activation_12[0][0]              \n",
      "                                                                 activation_14[0][0]              \n",
      "                                                                 activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block35_1_conv (Conv2D)         (None, 35, 35, 320)  41280       block35_1_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_1 (Lambda)              (None, 35, 35, 320)  0           mixed_5b[0][0]                   \n",
      "                                                                 block35_1_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_1_ac (Activation)       (None, 35, 35, 320)  0           block35_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 35, 35, 32)   10240       block35_1_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_21 (Batc (None, 35, 35, 32)   96          conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 35, 35, 32)   0           batch_normalization_v1_21[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 35, 35, 32)   10240       block35_1_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 35, 35, 48)   13824       activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_19 (Batc (None, 35, 35, 32)   96          conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_22 (Batc (None, 35, 35, 48)   144         conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 35, 35, 32)   0           batch_normalization_v1_19[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 35, 35, 48)   0           batch_normalization_v1_22[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 35, 35, 32)   10240       block35_1_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 35, 35, 32)   9216        activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 35, 35, 64)   27648       activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_18 (Batc (None, 35, 35, 32)   96          conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_20 (Batc (None, 35, 35, 32)   96          conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_23 (Batc (None, 35, 35, 64)   192         conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 35, 35, 32)   0           batch_normalization_v1_18[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 35, 35, 32)   0           batch_normalization_v1_20[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 35, 35, 64)   0           batch_normalization_v1_23[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block35_2_mixed (Concatenate)   (None, 35, 35, 128)  0           activation_18[0][0]              \n",
      "                                                                 activation_20[0][0]              \n",
      "                                                                 activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block35_2_conv (Conv2D)         (None, 35, 35, 320)  41280       block35_2_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_2 (Lambda)              (None, 35, 35, 320)  0           block35_1_ac[0][0]               \n",
      "                                                                 block35_2_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_2_ac (Activation)       (None, 35, 35, 320)  0           block35_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 35, 35, 32)   10240       block35_2_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_27 (Batc (None, 35, 35, 32)   96          conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 35, 35, 32)   0           batch_normalization_v1_27[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 35, 35, 32)   10240       block35_2_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 35, 35, 48)   13824       activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_25 (Batc (None, 35, 35, 32)   96          conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_28 (Batc (None, 35, 35, 48)   144         conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 35, 35, 32)   0           batch_normalization_v1_25[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 35, 35, 48)   0           batch_normalization_v1_28[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 35, 35, 32)   10240       block35_2_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 35, 35, 32)   9216        activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 35, 35, 64)   27648       activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_24 (Batc (None, 35, 35, 32)   96          conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_26 (Batc (None, 35, 35, 32)   96          conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_29 (Batc (None, 35, 35, 64)   192         conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 35, 35, 32)   0           batch_normalization_v1_24[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 35, 35, 32)   0           batch_normalization_v1_26[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 35, 35, 64)   0           batch_normalization_v1_29[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block35_3_mixed (Concatenate)   (None, 35, 35, 128)  0           activation_24[0][0]              \n",
      "                                                                 activation_26[0][0]              \n",
      "                                                                 activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block35_3_conv (Conv2D)         (None, 35, 35, 320)  41280       block35_3_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_3 (Lambda)              (None, 35, 35, 320)  0           block35_2_ac[0][0]               \n",
      "                                                                 block35_3_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_3_ac (Activation)       (None, 35, 35, 320)  0           block35_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 35, 35, 32)   10240       block35_3_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_33 (Batc (None, 35, 35, 32)   96          conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 35, 35, 32)   0           batch_normalization_v1_33[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 35, 35, 32)   10240       block35_3_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 35, 35, 48)   13824       activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_31 (Batc (None, 35, 35, 32)   96          conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_34 (Batc (None, 35, 35, 48)   144         conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 35, 35, 32)   0           batch_normalization_v1_31[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 35, 35, 48)   0           batch_normalization_v1_34[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 35, 35, 32)   10240       block35_3_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 35, 35, 32)   9216        activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 35, 35, 64)   27648       activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_30 (Batc (None, 35, 35, 32)   96          conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_32 (Batc (None, 35, 35, 32)   96          conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_35 (Batc (None, 35, 35, 64)   192         conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 35, 35, 32)   0           batch_normalization_v1_30[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 35, 35, 32)   0           batch_normalization_v1_32[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 35, 35, 64)   0           batch_normalization_v1_35[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block35_4_mixed (Concatenate)   (None, 35, 35, 128)  0           activation_30[0][0]              \n",
      "                                                                 activation_32[0][0]              \n",
      "                                                                 activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block35_4_conv (Conv2D)         (None, 35, 35, 320)  41280       block35_4_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_4 (Lambda)              (None, 35, 35, 320)  0           block35_3_ac[0][0]               \n",
      "                                                                 block35_4_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_4_ac (Activation)       (None, 35, 35, 320)  0           block35_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 35, 35, 32)   10240       block35_4_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_39 (Batc (None, 35, 35, 32)   96          conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 35, 35, 32)   0           batch_normalization_v1_39[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 35, 35, 32)   10240       block35_4_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 35, 35, 48)   13824       activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_37 (Batc (None, 35, 35, 32)   96          conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_40 (Batc (None, 35, 35, 48)   144         conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 35, 35, 32)   0           batch_normalization_v1_37[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 35, 35, 48)   0           batch_normalization_v1_40[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 35, 35, 32)   10240       block35_4_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 35, 35, 32)   9216        activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 35, 35, 64)   27648       activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_36 (Batc (None, 35, 35, 32)   96          conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_38 (Batc (None, 35, 35, 32)   96          conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_41 (Batc (None, 35, 35, 64)   192         conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 35, 35, 32)   0           batch_normalization_v1_36[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 35, 35, 32)   0           batch_normalization_v1_38[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 35, 35, 64)   0           batch_normalization_v1_41[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block35_5_mixed (Concatenate)   (None, 35, 35, 128)  0           activation_36[0][0]              \n",
      "                                                                 activation_38[0][0]              \n",
      "                                                                 activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block35_5_conv (Conv2D)         (None, 35, 35, 320)  41280       block35_5_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_5 (Lambda)              (None, 35, 35, 320)  0           block35_4_ac[0][0]               \n",
      "                                                                 block35_5_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_5_ac (Activation)       (None, 35, 35, 320)  0           block35_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 35, 35, 32)   10240       block35_5_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_45 (Batc (None, 35, 35, 32)   96          conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 35, 35, 32)   0           batch_normalization_v1_45[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 35, 35, 32)   10240       block35_5_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 35, 35, 48)   13824       activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_43 (Batc (None, 35, 35, 32)   96          conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_46 (Batc (None, 35, 35, 48)   144         conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 35, 35, 32)   0           batch_normalization_v1_43[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 35, 35, 48)   0           batch_normalization_v1_46[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 35, 35, 32)   10240       block35_5_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 35, 35, 32)   9216        activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 35, 35, 64)   27648       activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_42 (Batc (None, 35, 35, 32)   96          conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_44 (Batc (None, 35, 35, 32)   96          conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_47 (Batc (None, 35, 35, 64)   192         conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 35, 35, 32)   0           batch_normalization_v1_42[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 35, 35, 32)   0           batch_normalization_v1_44[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 35, 35, 64)   0           batch_normalization_v1_47[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block35_6_mixed (Concatenate)   (None, 35, 35, 128)  0           activation_42[0][0]              \n",
      "                                                                 activation_44[0][0]              \n",
      "                                                                 activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block35_6_conv (Conv2D)         (None, 35, 35, 320)  41280       block35_6_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_6 (Lambda)              (None, 35, 35, 320)  0           block35_5_ac[0][0]               \n",
      "                                                                 block35_6_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_6_ac (Activation)       (None, 35, 35, 320)  0           block35_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 35, 35, 32)   10240       block35_6_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_51 (Batc (None, 35, 35, 32)   96          conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 35, 35, 32)   0           batch_normalization_v1_51[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 35, 35, 32)   10240       block35_6_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 35, 35, 48)   13824       activation_51[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_49 (Batc (None, 35, 35, 32)   96          conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_52 (Batc (None, 35, 35, 48)   144         conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 35, 35, 32)   0           batch_normalization_v1_49[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 35, 35, 48)   0           batch_normalization_v1_52[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 35, 35, 32)   10240       block35_6_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 35, 35, 32)   9216        activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 35, 35, 64)   27648       activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_48 (Batc (None, 35, 35, 32)   96          conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_50 (Batc (None, 35, 35, 32)   96          conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_53 (Batc (None, 35, 35, 64)   192         conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 35, 35, 32)   0           batch_normalization_v1_48[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 35, 35, 32)   0           batch_normalization_v1_50[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 35, 35, 64)   0           batch_normalization_v1_53[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block35_7_mixed (Concatenate)   (None, 35, 35, 128)  0           activation_48[0][0]              \n",
      "                                                                 activation_50[0][0]              \n",
      "                                                                 activation_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block35_7_conv (Conv2D)         (None, 35, 35, 320)  41280       block35_7_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_7 (Lambda)              (None, 35, 35, 320)  0           block35_6_ac[0][0]               \n",
      "                                                                 block35_7_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_7_ac (Activation)       (None, 35, 35, 320)  0           block35_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 35, 35, 32)   10240       block35_7_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_57 (Batc (None, 35, 35, 32)   96          conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 35, 35, 32)   0           batch_normalization_v1_57[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 35, 35, 32)   10240       block35_7_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 35, 35, 48)   13824       activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_55 (Batc (None, 35, 35, 32)   96          conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_58 (Batc (None, 35, 35, 48)   144         conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 35, 35, 32)   0           batch_normalization_v1_55[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 35, 35, 48)   0           batch_normalization_v1_58[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 35, 35, 32)   10240       block35_7_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 35, 35, 32)   9216        activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 35, 35, 64)   27648       activation_58[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_54 (Batc (None, 35, 35, 32)   96          conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_56 (Batc (None, 35, 35, 32)   96          conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_59 (Batc (None, 35, 35, 64)   192         conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 35, 35, 32)   0           batch_normalization_v1_54[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 35, 35, 32)   0           batch_normalization_v1_56[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 35, 35, 64)   0           batch_normalization_v1_59[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block35_8_mixed (Concatenate)   (None, 35, 35, 128)  0           activation_54[0][0]              \n",
      "                                                                 activation_56[0][0]              \n",
      "                                                                 activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block35_8_conv (Conv2D)         (None, 35, 35, 320)  41280       block35_8_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_8 (Lambda)              (None, 35, 35, 320)  0           block35_7_ac[0][0]               \n",
      "                                                                 block35_8_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_8_ac (Activation)       (None, 35, 35, 320)  0           block35_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 35, 35, 32)   10240       block35_8_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_63 (Batc (None, 35, 35, 32)   96          conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 35, 35, 32)   0           batch_normalization_v1_63[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 35, 35, 32)   10240       block35_8_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 35, 35, 48)   13824       activation_63[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_61 (Batc (None, 35, 35, 32)   96          conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_64 (Batc (None, 35, 35, 48)   144         conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 35, 35, 32)   0           batch_normalization_v1_61[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, 35, 35, 48)   0           batch_normalization_v1_64[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 35, 35, 32)   10240       block35_8_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 35, 35, 32)   9216        activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 35, 35, 64)   27648       activation_64[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_60 (Batc (None, 35, 35, 32)   96          conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_62 (Batc (None, 35, 35, 32)   96          conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_65 (Batc (None, 35, 35, 64)   192         conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 35, 35, 32)   0           batch_normalization_v1_60[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 35, 35, 32)   0           batch_normalization_v1_62[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, 35, 35, 64)   0           batch_normalization_v1_65[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block35_9_mixed (Concatenate)   (None, 35, 35, 128)  0           activation_60[0][0]              \n",
      "                                                                 activation_62[0][0]              \n",
      "                                                                 activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block35_9_conv (Conv2D)         (None, 35, 35, 320)  41280       block35_9_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_9 (Lambda)              (None, 35, 35, 320)  0           block35_8_ac[0][0]               \n",
      "                                                                 block35_9_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_9_ac (Activation)       (None, 35, 35, 320)  0           block35_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 35, 35, 32)   10240       block35_9_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_69 (Batc (None, 35, 35, 32)   96          conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, 35, 35, 32)   0           batch_normalization_v1_69[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 35, 35, 32)   10240       block35_9_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, 35, 35, 48)   13824       activation_69[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_67 (Batc (None, 35, 35, 32)   96          conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_70 (Batc (None, 35, 35, 48)   144         conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, 35, 35, 32)   0           batch_normalization_v1_67[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_70 (Activation)      (None, 35, 35, 48)   0           batch_normalization_v1_70[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 35, 35, 32)   10240       block35_9_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 35, 35, 32)   9216        activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, 35, 35, 64)   27648       activation_70[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_66 (Batc (None, 35, 35, 32)   96          conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_68 (Batc (None, 35, 35, 32)   96          conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_71 (Batc (None, 35, 35, 64)   192         conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, 35, 35, 32)   0           batch_normalization_v1_66[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, 35, 35, 32)   0           batch_normalization_v1_68[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_71 (Activation)      (None, 35, 35, 64)   0           batch_normalization_v1_71[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block35_10_mixed (Concatenate)  (None, 35, 35, 128)  0           activation_66[0][0]              \n",
      "                                                                 activation_68[0][0]              \n",
      "                                                                 activation_71[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block35_10_conv (Conv2D)        (None, 35, 35, 320)  41280       block35_10_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block35_10 (Lambda)             (None, 35, 35, 320)  0           block35_9_ac[0][0]               \n",
      "                                                                 block35_10_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_10_ac (Activation)      (None, 35, 35, 320)  0           block35_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, 35, 35, 256)  81920       block35_10_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_73 (Batc (None, 35, 35, 256)  768         conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_73 (Activation)      (None, 35, 35, 256)  0           batch_normalization_v1_73[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, 35, 35, 256)  589824      activation_73[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_74 (Batc (None, 35, 35, 256)  768         conv2d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_74 (Activation)      (None, 35, 35, 256)  0           batch_normalization_v1_74[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, 17, 17, 384)  1105920     block35_10_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, 17, 17, 384)  884736      activation_74[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_72 (Batc (None, 17, 17, 384)  1152        conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_75 (Batc (None, 17, 17, 384)  1152        conv2d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_72 (Activation)      (None, 17, 17, 384)  0           batch_normalization_v1_72[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_75 (Activation)      (None, 17, 17, 384)  0           batch_normalization_v1_75[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 17, 17, 320)  0           block35_10_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "mixed_6a (Concatenate)          (None, 17, 17, 1088) 0           activation_72[0][0]              \n",
      "                                                                 activation_75[0][0]              \n",
      "                                                                 max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, 17, 17, 128)  139264      mixed_6a[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_77 (Batc (None, 17, 17, 128)  384         conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_77 (Activation)      (None, 17, 17, 128)  0           batch_normalization_v1_77[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, 17, 17, 160)  143360      activation_77[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_78 (Batc (None, 17, 17, 160)  480         conv2d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_78 (Activation)      (None, 17, 17, 160)  0           batch_normalization_v1_78[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, 17, 17, 192)  208896      mixed_6a[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, 17, 17, 192)  215040      activation_78[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_76 (Batc (None, 17, 17, 192)  576         conv2d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_79 (Batc (None, 17, 17, 192)  576         conv2d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_76 (Activation)      (None, 17, 17, 192)  0           batch_normalization_v1_76[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_79 (Activation)      (None, 17, 17, 192)  0           batch_normalization_v1_79[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block17_1_mixed (Concatenate)   (None, 17, 17, 384)  0           activation_76[0][0]              \n",
      "                                                                 activation_79[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block17_1_conv (Conv2D)         (None, 17, 17, 1088) 418880      block17_1_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_1 (Lambda)              (None, 17, 17, 1088) 0           mixed_6a[0][0]                   \n",
      "                                                                 block17_1_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_1_ac (Activation)       (None, 17, 17, 1088) 0           block17_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, 17, 17, 128)  139264      block17_1_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_81 (Batc (None, 17, 17, 128)  384         conv2d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_81 (Activation)      (None, 17, 17, 128)  0           batch_normalization_v1_81[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (None, 17, 17, 160)  143360      activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_82 (Batc (None, 17, 17, 160)  480         conv2d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_82 (Activation)      (None, 17, 17, 160)  0           batch_normalization_v1_82[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, 17, 17, 192)  208896      block17_1_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)              (None, 17, 17, 192)  215040      activation_82[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_80 (Batc (None, 17, 17, 192)  576         conv2d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_83 (Batc (None, 17, 17, 192)  576         conv2d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_80 (Activation)      (None, 17, 17, 192)  0           batch_normalization_v1_80[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_83 (Activation)      (None, 17, 17, 192)  0           batch_normalization_v1_83[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block17_2_mixed (Concatenate)   (None, 17, 17, 384)  0           activation_80[0][0]              \n",
      "                                                                 activation_83[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block17_2_conv (Conv2D)         (None, 17, 17, 1088) 418880      block17_2_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_2 (Lambda)              (None, 17, 17, 1088) 0           block17_1_ac[0][0]               \n",
      "                                                                 block17_2_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_2_ac (Activation)       (None, 17, 17, 1088) 0           block17_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)              (None, 17, 17, 128)  139264      block17_2_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_85 (Batc (None, 17, 17, 128)  384         conv2d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_85 (Activation)      (None, 17, 17, 128)  0           batch_normalization_v1_85[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)              (None, 17, 17, 160)  143360      activation_85[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_86 (Batc (None, 17, 17, 160)  480         conv2d_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_86 (Activation)      (None, 17, 17, 160)  0           batch_normalization_v1_86[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)              (None, 17, 17, 192)  208896      block17_2_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)              (None, 17, 17, 192)  215040      activation_86[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_84 (Batc (None, 17, 17, 192)  576         conv2d_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_87 (Batc (None, 17, 17, 192)  576         conv2d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_84 (Activation)      (None, 17, 17, 192)  0           batch_normalization_v1_84[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_87 (Activation)      (None, 17, 17, 192)  0           batch_normalization_v1_87[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block17_3_mixed (Concatenate)   (None, 17, 17, 384)  0           activation_84[0][0]              \n",
      "                                                                 activation_87[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block17_3_conv (Conv2D)         (None, 17, 17, 1088) 418880      block17_3_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_3 (Lambda)              (None, 17, 17, 1088) 0           block17_2_ac[0][0]               \n",
      "                                                                 block17_3_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_3_ac (Activation)       (None, 17, 17, 1088) 0           block17_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)              (None, 17, 17, 128)  139264      block17_3_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_89 (Batc (None, 17, 17, 128)  384         conv2d_89[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_89 (Activation)      (None, 17, 17, 128)  0           batch_normalization_v1_89[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)              (None, 17, 17, 160)  143360      activation_89[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_90 (Batc (None, 17, 17, 160)  480         conv2d_90[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_90 (Activation)      (None, 17, 17, 160)  0           batch_normalization_v1_90[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)              (None, 17, 17, 192)  208896      block17_3_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_91 (Conv2D)              (None, 17, 17, 192)  215040      activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_88 (Batc (None, 17, 17, 192)  576         conv2d_88[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_91 (Batc (None, 17, 17, 192)  576         conv2d_91[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_88 (Activation)      (None, 17, 17, 192)  0           batch_normalization_v1_88[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_91 (Activation)      (None, 17, 17, 192)  0           batch_normalization_v1_91[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block17_4_mixed (Concatenate)   (None, 17, 17, 384)  0           activation_88[0][0]              \n",
      "                                                                 activation_91[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block17_4_conv (Conv2D)         (None, 17, 17, 1088) 418880      block17_4_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_4 (Lambda)              (None, 17, 17, 1088) 0           block17_3_ac[0][0]               \n",
      "                                                                 block17_4_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_4_ac (Activation)       (None, 17, 17, 1088) 0           block17_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_93 (Conv2D)              (None, 17, 17, 128)  139264      block17_4_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_93 (Batc (None, 17, 17, 128)  384         conv2d_93[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_93 (Activation)      (None, 17, 17, 128)  0           batch_normalization_v1_93[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_94 (Conv2D)              (None, 17, 17, 160)  143360      activation_93[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_94 (Batc (None, 17, 17, 160)  480         conv2d_94[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_94 (Activation)      (None, 17, 17, 160)  0           batch_normalization_v1_94[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_92 (Conv2D)              (None, 17, 17, 192)  208896      block17_4_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_95 (Conv2D)              (None, 17, 17, 192)  215040      activation_94[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_92 (Batc (None, 17, 17, 192)  576         conv2d_92[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_95 (Batc (None, 17, 17, 192)  576         conv2d_95[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_92 (Activation)      (None, 17, 17, 192)  0           batch_normalization_v1_92[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_95 (Activation)      (None, 17, 17, 192)  0           batch_normalization_v1_95[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block17_5_mixed (Concatenate)   (None, 17, 17, 384)  0           activation_92[0][0]              \n",
      "                                                                 activation_95[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block17_5_conv (Conv2D)         (None, 17, 17, 1088) 418880      block17_5_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_5 (Lambda)              (None, 17, 17, 1088) 0           block17_4_ac[0][0]               \n",
      "                                                                 block17_5_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_5_ac (Activation)       (None, 17, 17, 1088) 0           block17_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_97 (Conv2D)              (None, 17, 17, 128)  139264      block17_5_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_97 (Batc (None, 17, 17, 128)  384         conv2d_97[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_97 (Activation)      (None, 17, 17, 128)  0           batch_normalization_v1_97[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_98 (Conv2D)              (None, 17, 17, 160)  143360      activation_97[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_98 (Batc (None, 17, 17, 160)  480         conv2d_98[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_98 (Activation)      (None, 17, 17, 160)  0           batch_normalization_v1_98[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_96 (Conv2D)              (None, 17, 17, 192)  208896      block17_5_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_99 (Conv2D)              (None, 17, 17, 192)  215040      activation_98[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_96 (Batc (None, 17, 17, 192)  576         conv2d_96[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_99 (Batc (None, 17, 17, 192)  576         conv2d_99[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_96 (Activation)      (None, 17, 17, 192)  0           batch_normalization_v1_96[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_99 (Activation)      (None, 17, 17, 192)  0           batch_normalization_v1_99[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block17_6_mixed (Concatenate)   (None, 17, 17, 384)  0           activation_96[0][0]              \n",
      "                                                                 activation_99[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block17_6_conv (Conv2D)         (None, 17, 17, 1088) 418880      block17_6_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_6 (Lambda)              (None, 17, 17, 1088) 0           block17_5_ac[0][0]               \n",
      "                                                                 block17_6_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_6_ac (Activation)       (None, 17, 17, 1088) 0           block17_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_101 (Conv2D)             (None, 17, 17, 128)  139264      block17_6_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_101 (Bat (None, 17, 17, 128)  384         conv2d_101[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_101 (Activation)     (None, 17, 17, 128)  0           batch_normalization_v1_101[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_102 (Conv2D)             (None, 17, 17, 160)  143360      activation_101[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_102 (Bat (None, 17, 17, 160)  480         conv2d_102[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_102 (Activation)     (None, 17, 17, 160)  0           batch_normalization_v1_102[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_100 (Conv2D)             (None, 17, 17, 192)  208896      block17_6_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_103 (Conv2D)             (None, 17, 17, 192)  215040      activation_102[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_100 (Bat (None, 17, 17, 192)  576         conv2d_100[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_103 (Bat (None, 17, 17, 192)  576         conv2d_103[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_100 (Activation)     (None, 17, 17, 192)  0           batch_normalization_v1_100[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_103 (Activation)     (None, 17, 17, 192)  0           batch_normalization_v1_103[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "block17_7_mixed (Concatenate)   (None, 17, 17, 384)  0           activation_100[0][0]             \n",
      "                                                                 activation_103[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_7_conv (Conv2D)         (None, 17, 17, 1088) 418880      block17_7_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_7 (Lambda)              (None, 17, 17, 1088) 0           block17_6_ac[0][0]               \n",
      "                                                                 block17_7_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_7_ac (Activation)       (None, 17, 17, 1088) 0           block17_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_105 (Conv2D)             (None, 17, 17, 128)  139264      block17_7_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_105 (Bat (None, 17, 17, 128)  384         conv2d_105[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_105 (Activation)     (None, 17, 17, 128)  0           batch_normalization_v1_105[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_106 (Conv2D)             (None, 17, 17, 160)  143360      activation_105[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_106 (Bat (None, 17, 17, 160)  480         conv2d_106[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_106 (Activation)     (None, 17, 17, 160)  0           batch_normalization_v1_106[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_104 (Conv2D)             (None, 17, 17, 192)  208896      block17_7_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_107 (Conv2D)             (None, 17, 17, 192)  215040      activation_106[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_104 (Bat (None, 17, 17, 192)  576         conv2d_104[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_107 (Bat (None, 17, 17, 192)  576         conv2d_107[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_104 (Activation)     (None, 17, 17, 192)  0           batch_normalization_v1_104[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_107 (Activation)     (None, 17, 17, 192)  0           batch_normalization_v1_107[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "block17_8_mixed (Concatenate)   (None, 17, 17, 384)  0           activation_104[0][0]             \n",
      "                                                                 activation_107[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_8_conv (Conv2D)         (None, 17, 17, 1088) 418880      block17_8_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_8 (Lambda)              (None, 17, 17, 1088) 0           block17_7_ac[0][0]               \n",
      "                                                                 block17_8_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_8_ac (Activation)       (None, 17, 17, 1088) 0           block17_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_109 (Conv2D)             (None, 17, 17, 128)  139264      block17_8_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_109 (Bat (None, 17, 17, 128)  384         conv2d_109[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_109 (Activation)     (None, 17, 17, 128)  0           batch_normalization_v1_109[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_110 (Conv2D)             (None, 17, 17, 160)  143360      activation_109[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_110 (Bat (None, 17, 17, 160)  480         conv2d_110[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_110 (Activation)     (None, 17, 17, 160)  0           batch_normalization_v1_110[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_108 (Conv2D)             (None, 17, 17, 192)  208896      block17_8_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_111 (Conv2D)             (None, 17, 17, 192)  215040      activation_110[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_108 (Bat (None, 17, 17, 192)  576         conv2d_108[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_111 (Bat (None, 17, 17, 192)  576         conv2d_111[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_108 (Activation)     (None, 17, 17, 192)  0           batch_normalization_v1_108[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_111 (Activation)     (None, 17, 17, 192)  0           batch_normalization_v1_111[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "block17_9_mixed (Concatenate)   (None, 17, 17, 384)  0           activation_108[0][0]             \n",
      "                                                                 activation_111[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_9_conv (Conv2D)         (None, 17, 17, 1088) 418880      block17_9_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_9 (Lambda)              (None, 17, 17, 1088) 0           block17_8_ac[0][0]               \n",
      "                                                                 block17_9_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_9_ac (Activation)       (None, 17, 17, 1088) 0           block17_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_113 (Conv2D)             (None, 17, 17, 128)  139264      block17_9_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_113 (Bat (None, 17, 17, 128)  384         conv2d_113[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_113 (Activation)     (None, 17, 17, 128)  0           batch_normalization_v1_113[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_114 (Conv2D)             (None, 17, 17, 160)  143360      activation_113[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_114 (Bat (None, 17, 17, 160)  480         conv2d_114[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_114 (Activation)     (None, 17, 17, 160)  0           batch_normalization_v1_114[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_112 (Conv2D)             (None, 17, 17, 192)  208896      block17_9_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_115 (Conv2D)             (None, 17, 17, 192)  215040      activation_114[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_112 (Bat (None, 17, 17, 192)  576         conv2d_112[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_115 (Bat (None, 17, 17, 192)  576         conv2d_115[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_112 (Activation)     (None, 17, 17, 192)  0           batch_normalization_v1_112[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_115 (Activation)     (None, 17, 17, 192)  0           batch_normalization_v1_115[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "block17_10_mixed (Concatenate)  (None, 17, 17, 384)  0           activation_112[0][0]             \n",
      "                                                                 activation_115[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_10_conv (Conv2D)        (None, 17, 17, 1088) 418880      block17_10_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_10 (Lambda)             (None, 17, 17, 1088) 0           block17_9_ac[0][0]               \n",
      "                                                                 block17_10_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_10_ac (Activation)      (None, 17, 17, 1088) 0           block17_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_117 (Conv2D)             (None, 17, 17, 128)  139264      block17_10_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_117 (Bat (None, 17, 17, 128)  384         conv2d_117[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_117 (Activation)     (None, 17, 17, 128)  0           batch_normalization_v1_117[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_118 (Conv2D)             (None, 17, 17, 160)  143360      activation_117[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_118 (Bat (None, 17, 17, 160)  480         conv2d_118[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_118 (Activation)     (None, 17, 17, 160)  0           batch_normalization_v1_118[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_116 (Conv2D)             (None, 17, 17, 192)  208896      block17_10_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_119 (Conv2D)             (None, 17, 17, 192)  215040      activation_118[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_116 (Bat (None, 17, 17, 192)  576         conv2d_116[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_119 (Bat (None, 17, 17, 192)  576         conv2d_119[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_116 (Activation)     (None, 17, 17, 192)  0           batch_normalization_v1_116[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_119 (Activation)     (None, 17, 17, 192)  0           batch_normalization_v1_119[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "block17_11_mixed (Concatenate)  (None, 17, 17, 384)  0           activation_116[0][0]             \n",
      "                                                                 activation_119[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_11_conv (Conv2D)        (None, 17, 17, 1088) 418880      block17_11_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_11 (Lambda)             (None, 17, 17, 1088) 0           block17_10_ac[0][0]              \n",
      "                                                                 block17_11_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_11_ac (Activation)      (None, 17, 17, 1088) 0           block17_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_121 (Conv2D)             (None, 17, 17, 128)  139264      block17_11_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_121 (Bat (None, 17, 17, 128)  384         conv2d_121[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_121 (Activation)     (None, 17, 17, 128)  0           batch_normalization_v1_121[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_122 (Conv2D)             (None, 17, 17, 160)  143360      activation_121[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_122 (Bat (None, 17, 17, 160)  480         conv2d_122[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_122 (Activation)     (None, 17, 17, 160)  0           batch_normalization_v1_122[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_120 (Conv2D)             (None, 17, 17, 192)  208896      block17_11_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_123 (Conv2D)             (None, 17, 17, 192)  215040      activation_122[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_120 (Bat (None, 17, 17, 192)  576         conv2d_120[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_123 (Bat (None, 17, 17, 192)  576         conv2d_123[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_120 (Activation)     (None, 17, 17, 192)  0           batch_normalization_v1_120[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_123 (Activation)     (None, 17, 17, 192)  0           batch_normalization_v1_123[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "block17_12_mixed (Concatenate)  (None, 17, 17, 384)  0           activation_120[0][0]             \n",
      "                                                                 activation_123[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_12_conv (Conv2D)        (None, 17, 17, 1088) 418880      block17_12_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_12 (Lambda)             (None, 17, 17, 1088) 0           block17_11_ac[0][0]              \n",
      "                                                                 block17_12_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_12_ac (Activation)      (None, 17, 17, 1088) 0           block17_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_125 (Conv2D)             (None, 17, 17, 128)  139264      block17_12_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_125 (Bat (None, 17, 17, 128)  384         conv2d_125[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_125 (Activation)     (None, 17, 17, 128)  0           batch_normalization_v1_125[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_126 (Conv2D)             (None, 17, 17, 160)  143360      activation_125[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_126 (Bat (None, 17, 17, 160)  480         conv2d_126[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_126 (Activation)     (None, 17, 17, 160)  0           batch_normalization_v1_126[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_124 (Conv2D)             (None, 17, 17, 192)  208896      block17_12_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_127 (Conv2D)             (None, 17, 17, 192)  215040      activation_126[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_124 (Bat (None, 17, 17, 192)  576         conv2d_124[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_127 (Bat (None, 17, 17, 192)  576         conv2d_127[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_124 (Activation)     (None, 17, 17, 192)  0           batch_normalization_v1_124[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_127 (Activation)     (None, 17, 17, 192)  0           batch_normalization_v1_127[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "block17_13_mixed (Concatenate)  (None, 17, 17, 384)  0           activation_124[0][0]             \n",
      "                                                                 activation_127[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_13_conv (Conv2D)        (None, 17, 17, 1088) 418880      block17_13_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_13 (Lambda)             (None, 17, 17, 1088) 0           block17_12_ac[0][0]              \n",
      "                                                                 block17_13_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_13_ac (Activation)      (None, 17, 17, 1088) 0           block17_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_129 (Conv2D)             (None, 17, 17, 128)  139264      block17_13_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_129 (Bat (None, 17, 17, 128)  384         conv2d_129[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_129 (Activation)     (None, 17, 17, 128)  0           batch_normalization_v1_129[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_130 (Conv2D)             (None, 17, 17, 160)  143360      activation_129[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_130 (Bat (None, 17, 17, 160)  480         conv2d_130[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_130 (Activation)     (None, 17, 17, 160)  0           batch_normalization_v1_130[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_128 (Conv2D)             (None, 17, 17, 192)  208896      block17_13_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_131 (Conv2D)             (None, 17, 17, 192)  215040      activation_130[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_128 (Bat (None, 17, 17, 192)  576         conv2d_128[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_131 (Bat (None, 17, 17, 192)  576         conv2d_131[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_128 (Activation)     (None, 17, 17, 192)  0           batch_normalization_v1_128[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_131 (Activation)     (None, 17, 17, 192)  0           batch_normalization_v1_131[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "block17_14_mixed (Concatenate)  (None, 17, 17, 384)  0           activation_128[0][0]             \n",
      "                                                                 activation_131[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_14_conv (Conv2D)        (None, 17, 17, 1088) 418880      block17_14_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_14 (Lambda)             (None, 17, 17, 1088) 0           block17_13_ac[0][0]              \n",
      "                                                                 block17_14_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_14_ac (Activation)      (None, 17, 17, 1088) 0           block17_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_133 (Conv2D)             (None, 17, 17, 128)  139264      block17_14_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_133 (Bat (None, 17, 17, 128)  384         conv2d_133[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_133 (Activation)     (None, 17, 17, 128)  0           batch_normalization_v1_133[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_134 (Conv2D)             (None, 17, 17, 160)  143360      activation_133[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_134 (Bat (None, 17, 17, 160)  480         conv2d_134[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_134 (Activation)     (None, 17, 17, 160)  0           batch_normalization_v1_134[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_132 (Conv2D)             (None, 17, 17, 192)  208896      block17_14_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_135 (Conv2D)             (None, 17, 17, 192)  215040      activation_134[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_132 (Bat (None, 17, 17, 192)  576         conv2d_132[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_135 (Bat (None, 17, 17, 192)  576         conv2d_135[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_132 (Activation)     (None, 17, 17, 192)  0           batch_normalization_v1_132[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_135 (Activation)     (None, 17, 17, 192)  0           batch_normalization_v1_135[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "block17_15_mixed (Concatenate)  (None, 17, 17, 384)  0           activation_132[0][0]             \n",
      "                                                                 activation_135[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_15_conv (Conv2D)        (None, 17, 17, 1088) 418880      block17_15_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_15 (Lambda)             (None, 17, 17, 1088) 0           block17_14_ac[0][0]              \n",
      "                                                                 block17_15_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_15_ac (Activation)      (None, 17, 17, 1088) 0           block17_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_137 (Conv2D)             (None, 17, 17, 128)  139264      block17_15_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_137 (Bat (None, 17, 17, 128)  384         conv2d_137[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_137 (Activation)     (None, 17, 17, 128)  0           batch_normalization_v1_137[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_138 (Conv2D)             (None, 17, 17, 160)  143360      activation_137[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_138 (Bat (None, 17, 17, 160)  480         conv2d_138[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_138 (Activation)     (None, 17, 17, 160)  0           batch_normalization_v1_138[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_136 (Conv2D)             (None, 17, 17, 192)  208896      block17_15_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_139 (Conv2D)             (None, 17, 17, 192)  215040      activation_138[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_136 (Bat (None, 17, 17, 192)  576         conv2d_136[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_139 (Bat (None, 17, 17, 192)  576         conv2d_139[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_136 (Activation)     (None, 17, 17, 192)  0           batch_normalization_v1_136[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_139 (Activation)     (None, 17, 17, 192)  0           batch_normalization_v1_139[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "block17_16_mixed (Concatenate)  (None, 17, 17, 384)  0           activation_136[0][0]             \n",
      "                                                                 activation_139[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_16_conv (Conv2D)        (None, 17, 17, 1088) 418880      block17_16_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_16 (Lambda)             (None, 17, 17, 1088) 0           block17_15_ac[0][0]              \n",
      "                                                                 block17_16_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_16_ac (Activation)      (None, 17, 17, 1088) 0           block17_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_141 (Conv2D)             (None, 17, 17, 128)  139264      block17_16_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_141 (Bat (None, 17, 17, 128)  384         conv2d_141[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_141 (Activation)     (None, 17, 17, 128)  0           batch_normalization_v1_141[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_142 (Conv2D)             (None, 17, 17, 160)  143360      activation_141[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_142 (Bat (None, 17, 17, 160)  480         conv2d_142[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_142 (Activation)     (None, 17, 17, 160)  0           batch_normalization_v1_142[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_140 (Conv2D)             (None, 17, 17, 192)  208896      block17_16_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_143 (Conv2D)             (None, 17, 17, 192)  215040      activation_142[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_140 (Bat (None, 17, 17, 192)  576         conv2d_140[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_143 (Bat (None, 17, 17, 192)  576         conv2d_143[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_140 (Activation)     (None, 17, 17, 192)  0           batch_normalization_v1_140[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_143 (Activation)     (None, 17, 17, 192)  0           batch_normalization_v1_143[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "block17_17_mixed (Concatenate)  (None, 17, 17, 384)  0           activation_140[0][0]             \n",
      "                                                                 activation_143[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_17_conv (Conv2D)        (None, 17, 17, 1088) 418880      block17_17_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_17 (Lambda)             (None, 17, 17, 1088) 0           block17_16_ac[0][0]              \n",
      "                                                                 block17_17_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_17_ac (Activation)      (None, 17, 17, 1088) 0           block17_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_145 (Conv2D)             (None, 17, 17, 128)  139264      block17_17_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_145 (Bat (None, 17, 17, 128)  384         conv2d_145[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_145 (Activation)     (None, 17, 17, 128)  0           batch_normalization_v1_145[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_146 (Conv2D)             (None, 17, 17, 160)  143360      activation_145[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_146 (Bat (None, 17, 17, 160)  480         conv2d_146[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_146 (Activation)     (None, 17, 17, 160)  0           batch_normalization_v1_146[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_144 (Conv2D)             (None, 17, 17, 192)  208896      block17_17_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_147 (Conv2D)             (None, 17, 17, 192)  215040      activation_146[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_144 (Bat (None, 17, 17, 192)  576         conv2d_144[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_147 (Bat (None, 17, 17, 192)  576         conv2d_147[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_144 (Activation)     (None, 17, 17, 192)  0           batch_normalization_v1_144[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_147 (Activation)     (None, 17, 17, 192)  0           batch_normalization_v1_147[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "block17_18_mixed (Concatenate)  (None, 17, 17, 384)  0           activation_144[0][0]             \n",
      "                                                                 activation_147[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_18_conv (Conv2D)        (None, 17, 17, 1088) 418880      block17_18_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_18 (Lambda)             (None, 17, 17, 1088) 0           block17_17_ac[0][0]              \n",
      "                                                                 block17_18_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_18_ac (Activation)      (None, 17, 17, 1088) 0           block17_18[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_149 (Conv2D)             (None, 17, 17, 128)  139264      block17_18_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_149 (Bat (None, 17, 17, 128)  384         conv2d_149[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_149 (Activation)     (None, 17, 17, 128)  0           batch_normalization_v1_149[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_150 (Conv2D)             (None, 17, 17, 160)  143360      activation_149[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_150 (Bat (None, 17, 17, 160)  480         conv2d_150[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_150 (Activation)     (None, 17, 17, 160)  0           batch_normalization_v1_150[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_148 (Conv2D)             (None, 17, 17, 192)  208896      block17_18_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_151 (Conv2D)             (None, 17, 17, 192)  215040      activation_150[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_148 (Bat (None, 17, 17, 192)  576         conv2d_148[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_151 (Bat (None, 17, 17, 192)  576         conv2d_151[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_148 (Activation)     (None, 17, 17, 192)  0           batch_normalization_v1_148[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_151 (Activation)     (None, 17, 17, 192)  0           batch_normalization_v1_151[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "block17_19_mixed (Concatenate)  (None, 17, 17, 384)  0           activation_148[0][0]             \n",
      "                                                                 activation_151[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_19_conv (Conv2D)        (None, 17, 17, 1088) 418880      block17_19_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_19 (Lambda)             (None, 17, 17, 1088) 0           block17_18_ac[0][0]              \n",
      "                                                                 block17_19_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_19_ac (Activation)      (None, 17, 17, 1088) 0           block17_19[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_153 (Conv2D)             (None, 17, 17, 128)  139264      block17_19_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_153 (Bat (None, 17, 17, 128)  384         conv2d_153[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_153 (Activation)     (None, 17, 17, 128)  0           batch_normalization_v1_153[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_154 (Conv2D)             (None, 17, 17, 160)  143360      activation_153[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_154 (Bat (None, 17, 17, 160)  480         conv2d_154[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_154 (Activation)     (None, 17, 17, 160)  0           batch_normalization_v1_154[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_152 (Conv2D)             (None, 17, 17, 192)  208896      block17_19_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_155 (Conv2D)             (None, 17, 17, 192)  215040      activation_154[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_152 (Bat (None, 17, 17, 192)  576         conv2d_152[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_155 (Bat (None, 17, 17, 192)  576         conv2d_155[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_152 (Activation)     (None, 17, 17, 192)  0           batch_normalization_v1_152[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_155 (Activation)     (None, 17, 17, 192)  0           batch_normalization_v1_155[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "block17_20_mixed (Concatenate)  (None, 17, 17, 384)  0           activation_152[0][0]             \n",
      "                                                                 activation_155[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_20_conv (Conv2D)        (None, 17, 17, 1088) 418880      block17_20_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_20 (Lambda)             (None, 17, 17, 1088) 0           block17_19_ac[0][0]              \n",
      "                                                                 block17_20_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_20_ac (Activation)      (None, 17, 17, 1088) 0           block17_20[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_160 (Conv2D)             (None, 17, 17, 256)  278528      block17_20_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_160 (Bat (None, 17, 17, 256)  768         conv2d_160[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_160 (Activation)     (None, 17, 17, 256)  0           batch_normalization_v1_160[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_156 (Conv2D)             (None, 17, 17, 256)  278528      block17_20_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_158 (Conv2D)             (None, 17, 17, 256)  278528      block17_20_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_161 (Conv2D)             (None, 17, 17, 288)  663552      activation_160[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_156 (Bat (None, 17, 17, 256)  768         conv2d_156[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_158 (Bat (None, 17, 17, 256)  768         conv2d_158[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_161 (Bat (None, 17, 17, 288)  864         conv2d_161[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_156 (Activation)     (None, 17, 17, 256)  0           batch_normalization_v1_156[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_158 (Activation)     (None, 17, 17, 256)  0           batch_normalization_v1_158[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_161 (Activation)     (None, 17, 17, 288)  0           batch_normalization_v1_161[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_157 (Conv2D)             (None, 8, 8, 384)    884736      activation_156[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_159 (Conv2D)             (None, 8, 8, 288)    663552      activation_158[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_162 (Conv2D)             (None, 8, 8, 320)    829440      activation_161[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_157 (Bat (None, 8, 8, 384)    1152        conv2d_157[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_159 (Bat (None, 8, 8, 288)    864         conv2d_159[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_162 (Bat (None, 8, 8, 320)    960         conv2d_162[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_157 (Activation)     (None, 8, 8, 384)    0           batch_normalization_v1_157[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_159 (Activation)     (None, 8, 8, 288)    0           batch_normalization_v1_159[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_162 (Activation)     (None, 8, 8, 320)    0           batch_normalization_v1_162[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 8, 8, 1088)   0           block17_20_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "mixed_7a (Concatenate)          (None, 8, 8, 2080)   0           activation_157[0][0]             \n",
      "                                                                 activation_159[0][0]             \n",
      "                                                                 activation_162[0][0]             \n",
      "                                                                 max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_164 (Conv2D)             (None, 8, 8, 192)    399360      mixed_7a[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_164 (Bat (None, 8, 8, 192)    576         conv2d_164[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_164 (Activation)     (None, 8, 8, 192)    0           batch_normalization_v1_164[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_165 (Conv2D)             (None, 8, 8, 224)    129024      activation_164[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_165 (Bat (None, 8, 8, 224)    672         conv2d_165[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_165 (Activation)     (None, 8, 8, 224)    0           batch_normalization_v1_165[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_163 (Conv2D)             (None, 8, 8, 192)    399360      mixed_7a[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_166 (Conv2D)             (None, 8, 8, 256)    172032      activation_165[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_163 (Bat (None, 8, 8, 192)    576         conv2d_163[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_166 (Bat (None, 8, 8, 256)    768         conv2d_166[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_163 (Activation)     (None, 8, 8, 192)    0           batch_normalization_v1_163[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_166 (Activation)     (None, 8, 8, 256)    0           batch_normalization_v1_166[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "block8_1_mixed (Concatenate)    (None, 8, 8, 448)    0           activation_163[0][0]             \n",
      "                                                                 activation_166[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_1_conv (Conv2D)          (None, 8, 8, 2080)   933920      block8_1_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_1 (Lambda)               (None, 8, 8, 2080)   0           mixed_7a[0][0]                   \n",
      "                                                                 block8_1_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_1_ac (Activation)        (None, 8, 8, 2080)   0           block8_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_168 (Conv2D)             (None, 8, 8, 192)    399360      block8_1_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_168 (Bat (None, 8, 8, 192)    576         conv2d_168[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_168 (Activation)     (None, 8, 8, 192)    0           batch_normalization_v1_168[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_169 (Conv2D)             (None, 8, 8, 224)    129024      activation_168[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_169 (Bat (None, 8, 8, 224)    672         conv2d_169[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_169 (Activation)     (None, 8, 8, 224)    0           batch_normalization_v1_169[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_167 (Conv2D)             (None, 8, 8, 192)    399360      block8_1_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_170 (Conv2D)             (None, 8, 8, 256)    172032      activation_169[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_167 (Bat (None, 8, 8, 192)    576         conv2d_167[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_170 (Bat (None, 8, 8, 256)    768         conv2d_170[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_167 (Activation)     (None, 8, 8, 192)    0           batch_normalization_v1_167[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_170 (Activation)     (None, 8, 8, 256)    0           batch_normalization_v1_170[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "block8_2_mixed (Concatenate)    (None, 8, 8, 448)    0           activation_167[0][0]             \n",
      "                                                                 activation_170[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_2_conv (Conv2D)          (None, 8, 8, 2080)   933920      block8_2_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_2 (Lambda)               (None, 8, 8, 2080)   0           block8_1_ac[0][0]                \n",
      "                                                                 block8_2_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_2_ac (Activation)        (None, 8, 8, 2080)   0           block8_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_172 (Conv2D)             (None, 8, 8, 192)    399360      block8_2_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_172 (Bat (None, 8, 8, 192)    576         conv2d_172[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_172 (Activation)     (None, 8, 8, 192)    0           batch_normalization_v1_172[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_173 (Conv2D)             (None, 8, 8, 224)    129024      activation_172[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_173 (Bat (None, 8, 8, 224)    672         conv2d_173[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_173 (Activation)     (None, 8, 8, 224)    0           batch_normalization_v1_173[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_171 (Conv2D)             (None, 8, 8, 192)    399360      block8_2_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_174 (Conv2D)             (None, 8, 8, 256)    172032      activation_173[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_171 (Bat (None, 8, 8, 192)    576         conv2d_171[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_174 (Bat (None, 8, 8, 256)    768         conv2d_174[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_171 (Activation)     (None, 8, 8, 192)    0           batch_normalization_v1_171[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_174 (Activation)     (None, 8, 8, 256)    0           batch_normalization_v1_174[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "block8_3_mixed (Concatenate)    (None, 8, 8, 448)    0           activation_171[0][0]             \n",
      "                                                                 activation_174[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_3_conv (Conv2D)          (None, 8, 8, 2080)   933920      block8_3_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_3 (Lambda)               (None, 8, 8, 2080)   0           block8_2_ac[0][0]                \n",
      "                                                                 block8_3_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_3_ac (Activation)        (None, 8, 8, 2080)   0           block8_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_176 (Conv2D)             (None, 8, 8, 192)    399360      block8_3_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_176 (Bat (None, 8, 8, 192)    576         conv2d_176[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_176 (Activation)     (None, 8, 8, 192)    0           batch_normalization_v1_176[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_177 (Conv2D)             (None, 8, 8, 224)    129024      activation_176[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_177 (Bat (None, 8, 8, 224)    672         conv2d_177[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_177 (Activation)     (None, 8, 8, 224)    0           batch_normalization_v1_177[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_175 (Conv2D)             (None, 8, 8, 192)    399360      block8_3_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_178 (Conv2D)             (None, 8, 8, 256)    172032      activation_177[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_175 (Bat (None, 8, 8, 192)    576         conv2d_175[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_178 (Bat (None, 8, 8, 256)    768         conv2d_178[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_175 (Activation)     (None, 8, 8, 192)    0           batch_normalization_v1_175[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_178 (Activation)     (None, 8, 8, 256)    0           batch_normalization_v1_178[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "block8_4_mixed (Concatenate)    (None, 8, 8, 448)    0           activation_175[0][0]             \n",
      "                                                                 activation_178[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_4_conv (Conv2D)          (None, 8, 8, 2080)   933920      block8_4_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_4 (Lambda)               (None, 8, 8, 2080)   0           block8_3_ac[0][0]                \n",
      "                                                                 block8_4_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_4_ac (Activation)        (None, 8, 8, 2080)   0           block8_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_180 (Conv2D)             (None, 8, 8, 192)    399360      block8_4_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_180 (Bat (None, 8, 8, 192)    576         conv2d_180[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_180 (Activation)     (None, 8, 8, 192)    0           batch_normalization_v1_180[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_181 (Conv2D)             (None, 8, 8, 224)    129024      activation_180[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_181 (Bat (None, 8, 8, 224)    672         conv2d_181[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_181 (Activation)     (None, 8, 8, 224)    0           batch_normalization_v1_181[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_179 (Conv2D)             (None, 8, 8, 192)    399360      block8_4_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_182 (Conv2D)             (None, 8, 8, 256)    172032      activation_181[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_179 (Bat (None, 8, 8, 192)    576         conv2d_179[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_182 (Bat (None, 8, 8, 256)    768         conv2d_182[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_179 (Activation)     (None, 8, 8, 192)    0           batch_normalization_v1_179[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_182 (Activation)     (None, 8, 8, 256)    0           batch_normalization_v1_182[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "block8_5_mixed (Concatenate)    (None, 8, 8, 448)    0           activation_179[0][0]             \n",
      "                                                                 activation_182[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_5_conv (Conv2D)          (None, 8, 8, 2080)   933920      block8_5_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_5 (Lambda)               (None, 8, 8, 2080)   0           block8_4_ac[0][0]                \n",
      "                                                                 block8_5_conv[0][0]              \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "block8_5_ac (Activation)        (None, 8, 8, 2080)   0           block8_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_184 (Conv2D)             (None, 8, 8, 192)    399360      block8_5_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_184 (Bat (None, 8, 8, 192)    576         conv2d_184[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_184 (Activation)     (None, 8, 8, 192)    0           batch_normalization_v1_184[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_185 (Conv2D)             (None, 8, 8, 224)    129024      activation_184[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_185 (Bat (None, 8, 8, 224)    672         conv2d_185[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_185 (Activation)     (None, 8, 8, 224)    0           batch_normalization_v1_185[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_183 (Conv2D)             (None, 8, 8, 192)    399360      block8_5_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_186 (Conv2D)             (None, 8, 8, 256)    172032      activation_185[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_183 (Bat (None, 8, 8, 192)    576         conv2d_183[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_186 (Bat (None, 8, 8, 256)    768         conv2d_186[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_183 (Activation)     (None, 8, 8, 192)    0           batch_normalization_v1_183[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_186 (Activation)     (None, 8, 8, 256)    0           batch_normalization_v1_186[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "block8_6_mixed (Concatenate)    (None, 8, 8, 448)    0           activation_183[0][0]             \n",
      "                                                                 activation_186[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_6_conv (Conv2D)          (None, 8, 8, 2080)   933920      block8_6_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_6 (Lambda)               (None, 8, 8, 2080)   0           block8_5_ac[0][0]                \n",
      "                                                                 block8_6_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_6_ac (Activation)        (None, 8, 8, 2080)   0           block8_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_188 (Conv2D)             (None, 8, 8, 192)    399360      block8_6_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_188 (Bat (None, 8, 8, 192)    576         conv2d_188[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_188 (Activation)     (None, 8, 8, 192)    0           batch_normalization_v1_188[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_189 (Conv2D)             (None, 8, 8, 224)    129024      activation_188[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_189 (Bat (None, 8, 8, 224)    672         conv2d_189[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_189 (Activation)     (None, 8, 8, 224)    0           batch_normalization_v1_189[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_187 (Conv2D)             (None, 8, 8, 192)    399360      block8_6_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_190 (Conv2D)             (None, 8, 8, 256)    172032      activation_189[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_187 (Bat (None, 8, 8, 192)    576         conv2d_187[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_190 (Bat (None, 8, 8, 256)    768         conv2d_190[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_187 (Activation)     (None, 8, 8, 192)    0           batch_normalization_v1_187[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_190 (Activation)     (None, 8, 8, 256)    0           batch_normalization_v1_190[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "block8_7_mixed (Concatenate)    (None, 8, 8, 448)    0           activation_187[0][0]             \n",
      "                                                                 activation_190[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_7_conv (Conv2D)          (None, 8, 8, 2080)   933920      block8_7_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_7 (Lambda)               (None, 8, 8, 2080)   0           block8_6_ac[0][0]                \n",
      "                                                                 block8_7_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_7_ac (Activation)        (None, 8, 8, 2080)   0           block8_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_192 (Conv2D)             (None, 8, 8, 192)    399360      block8_7_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_192 (Bat (None, 8, 8, 192)    576         conv2d_192[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_192 (Activation)     (None, 8, 8, 192)    0           batch_normalization_v1_192[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_193 (Conv2D)             (None, 8, 8, 224)    129024      activation_192[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_193 (Bat (None, 8, 8, 224)    672         conv2d_193[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_193 (Activation)     (None, 8, 8, 224)    0           batch_normalization_v1_193[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_191 (Conv2D)             (None, 8, 8, 192)    399360      block8_7_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_194 (Conv2D)             (None, 8, 8, 256)    172032      activation_193[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_191 (Bat (None, 8, 8, 192)    576         conv2d_191[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_194 (Bat (None, 8, 8, 256)    768         conv2d_194[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_191 (Activation)     (None, 8, 8, 192)    0           batch_normalization_v1_191[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_194 (Activation)     (None, 8, 8, 256)    0           batch_normalization_v1_194[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "block8_8_mixed (Concatenate)    (None, 8, 8, 448)    0           activation_191[0][0]             \n",
      "                                                                 activation_194[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_8_conv (Conv2D)          (None, 8, 8, 2080)   933920      block8_8_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_8 (Lambda)               (None, 8, 8, 2080)   0           block8_7_ac[0][0]                \n",
      "                                                                 block8_8_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_8_ac (Activation)        (None, 8, 8, 2080)   0           block8_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_196 (Conv2D)             (None, 8, 8, 192)    399360      block8_8_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_196 (Bat (None, 8, 8, 192)    576         conv2d_196[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_196 (Activation)     (None, 8, 8, 192)    0           batch_normalization_v1_196[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_197 (Conv2D)             (None, 8, 8, 224)    129024      activation_196[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_197 (Bat (None, 8, 8, 224)    672         conv2d_197[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_197 (Activation)     (None, 8, 8, 224)    0           batch_normalization_v1_197[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_195 (Conv2D)             (None, 8, 8, 192)    399360      block8_8_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_198 (Conv2D)             (None, 8, 8, 256)    172032      activation_197[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_195 (Bat (None, 8, 8, 192)    576         conv2d_195[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_198 (Bat (None, 8, 8, 256)    768         conv2d_198[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_195 (Activation)     (None, 8, 8, 192)    0           batch_normalization_v1_195[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_198 (Activation)     (None, 8, 8, 256)    0           batch_normalization_v1_198[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "block8_9_mixed (Concatenate)    (None, 8, 8, 448)    0           activation_195[0][0]             \n",
      "                                                                 activation_198[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_9_conv (Conv2D)          (None, 8, 8, 2080)   933920      block8_9_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_9 (Lambda)               (None, 8, 8, 2080)   0           block8_8_ac[0][0]                \n",
      "                                                                 block8_9_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_9_ac (Activation)        (None, 8, 8, 2080)   0           block8_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_200 (Conv2D)             (None, 8, 8, 192)    399360      block8_9_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_200 (Bat (None, 8, 8, 192)    576         conv2d_200[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_200 (Activation)     (None, 8, 8, 192)    0           batch_normalization_v1_200[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_201 (Conv2D)             (None, 8, 8, 224)    129024      activation_200[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_201 (Bat (None, 8, 8, 224)    672         conv2d_201[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_201 (Activation)     (None, 8, 8, 224)    0           batch_normalization_v1_201[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_199 (Conv2D)             (None, 8, 8, 192)    399360      block8_9_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_202 (Conv2D)             (None, 8, 8, 256)    172032      activation_201[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_199 (Bat (None, 8, 8, 192)    576         conv2d_199[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_202 (Bat (None, 8, 8, 256)    768         conv2d_202[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_199 (Activation)     (None, 8, 8, 192)    0           batch_normalization_v1_199[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_202 (Activation)     (None, 8, 8, 256)    0           batch_normalization_v1_202[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "block8_10_mixed (Concatenate)   (None, 8, 8, 448)    0           activation_199[0][0]             \n",
      "                                                                 activation_202[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_10_conv (Conv2D)         (None, 8, 8, 2080)   933920      block8_10_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block8_10 (Lambda)              (None, 8, 8, 2080)   0           block8_9_ac[0][0]                \n",
      "                                                                 block8_10_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d (Globa (None, 2080)         0           block8_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            2081        global_average_pooling2d[0][0]   \n",
      "==================================================================================================\n",
      "Total params: 51,139,329\n",
      "Trainable params: 51,081,857\n",
      "Non-trainable params: 57,472\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "train_and_test_model_by_load_data() got an unexpected keyword argument 'fake_volumn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-e7ed92e8f731>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m                                                         \u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_interval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m                                                         \u001b[0;34m,\u001b[0m \u001b[0moutput_filename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"/tf/experiments/resnet16_299x299_16.h5\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m                                                         \u001b[0;34m,\u001b[0m \u001b[0mfake_volumn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m                                                        )\n",
      "\u001b[0;31mTypeError\u001b[0m: train_and_test_model_by_load_data() got an unexpected keyword argument 'fake_volumn'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# without FAKE images + Mobilenet pretrain\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from codes.data.train_model import train_and_test_model,train_and_test_model_by_load_data\n",
    "from codes.data.create_dataset_01 import create_dataset,load_dataset\n",
    "\n",
    "from codes.model.resnetv2 import build_InceptionResNetV2_pretrain\n",
    "\n",
    " \n",
    "model = build_InceptionResNetV2_pretrain()\n",
    "\n",
    "\n",
    "input_ds_filename =\"/tf/dataset/classes\" \n",
    "\n",
    "train_log, test_log = train_and_test_model(model, input_ds_filename,ratio=0.7\n",
    "                                                        , dataset_volume=7909, epochs=5\n",
    "                                                        ,batch_size=4, print_interval=20 \n",
    "                                                        , output_filename=\"/tf/experiments/resnet16_299x299_16.h5\"\n",
    "                                                        , fake_volumn = 0\n",
    "                                                       )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
