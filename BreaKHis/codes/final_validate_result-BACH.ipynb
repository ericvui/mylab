{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remove a /tf/dataset/BACH_validate_log_vgg16_256x256.csv file because of existed\n",
      "Preparing BACH dataset....\n",
      "Training model....\n",
      "[Epoch 0/5] [Batch 0/25] [T loss: 0.775916, acc:  51%] time: 0:00:09.908431\n",
      "[Epoch 0/5] [Batch 5/25] [T loss: 0.613247, acc:  73%] time: 0:00:26.523774\n",
      "[Epoch 0/5] [Batch 10/25] [T loss: 0.659862, acc:  59%] time: 0:00:46.955329\n",
      "[Epoch 0/5] [Batch 15/25] [T loss: 0.598155, acc:  75%] time: 0:01:06.396766\n",
      "[TESTING: 100] [accuracy: 0.8700] [B accuracy: 87] [M accuracy: 0]\n",
      "[TESTING: 200] [accuracy: 0.8750] [B accuracy: 104] [M accuracy: 71]\n",
      "[TESTING: 300] [accuracy: 0.8200] [B accuracy: 104] [M accuracy: 142]\n",
      "[TESTING: 400] [accuracy: 0.8075] [B accuracy: 130] [M accuracy: 193]\n",
      "[Epoch 1/5] [Batch 0/25] [T loss: 0.440832, acc:  82%] time: 0:01:48.668378\n",
      "[Epoch 1/5] [Batch 5/25] [T loss: 0.560886, acc:  78%] time: 0:02:08.337728\n",
      "[Epoch 1/5] [Batch 10/25] [T loss: 0.590427, acc:  65%] time: 0:02:28.586121\n",
      "[Epoch 1/5] [Batch 15/25] [T loss: 0.365513, acc:  85%] time: 0:02:48.740029\n",
      "[TESTING: 100] [accuracy: 0.7900] [B accuracy: 79] [M accuracy: 0]\n",
      "[TESTING: 200] [accuracy: 0.8550] [B accuracy: 93] [M accuracy: 78]\n",
      "[TESTING: 300] [accuracy: 0.8667] [B accuracy: 93] [M accuracy: 167]\n",
      "[TESTING: 400] [accuracy: 0.8475] [B accuracy: 115] [M accuracy: 224]\n",
      "[Epoch 2/5] [Batch 0/25] [T loss: 0.394201, acc:  78%] time: 0:03:29.851785\n",
      "[Epoch 2/5] [Batch 5/25] [T loss: 0.393223, acc:  81%] time: 0:03:50.073881\n",
      "[Epoch 2/5] [Batch 10/25] [T loss: 0.573175, acc:  79%] time: 0:04:10.223031\n",
      "[Epoch 2/5] [Batch 15/25] [T loss: 0.385620, acc:  84%] time: 0:04:29.777120\n",
      "[TESTING: 100] [accuracy: 0.8300] [B accuracy: 83] [M accuracy: 0]\n",
      "[TESTING: 200] [accuracy: 0.8450] [B accuracy: 95] [M accuracy: 74]\n",
      "[TESTING: 300] [accuracy: 0.8767] [B accuracy: 95] [M accuracy: 168]\n",
      "[TESTING: 400] [accuracy: 0.8600] [B accuracy: 118] [M accuracy: 226]\n",
      "[Epoch 3/5] [Batch 0/25] [T loss: 0.331971, acc:  82%] time: 0:05:10.727751\n",
      "[Epoch 3/5] [Batch 5/25] [T loss: 0.320497, acc:  89%] time: 0:05:30.540802\n",
      "[Epoch 3/5] [Batch 10/25] [T loss: 0.240501, acc:  89%] time: 0:05:51.244753\n",
      "[Epoch 3/5] [Batch 15/25] [T loss: 0.347510, acc:  84%] time: 0:06:11.485198\n",
      "[TESTING: 100] [accuracy: 1.0000] [B accuracy: 100] [M accuracy: 0]\n",
      "[TESTING: 200] [accuracy: 0.8200] [B accuracy: 120] [M accuracy: 44]\n",
      "[TESTING: 300] [accuracy: 0.7267] [B accuracy: 120] [M accuracy: 98]\n",
      "[TESTING: 400] [accuracy: 0.7375] [B accuracy: 160] [M accuracy: 135]\n",
      "[Epoch 4/5] [Batch 0/25] [T loss: 0.404036, acc:  82%] time: 0:06:51.701205\n",
      "[Epoch 4/5] [Batch 5/25] [T loss: 0.288064, acc:  90%] time: 0:07:11.376111\n",
      "[Epoch 4/5] [Batch 10/25] [T loss: 0.284756, acc:  92%] time: 0:07:31.899246\n",
      "[Epoch 4/5] [Batch 15/25] [T loss: 0.198956, acc:  92%] time: 0:07:52.090438\n",
      "[TESTING: 100] [accuracy: 0.9600] [B accuracy: 96] [M accuracy: 0]\n",
      "[TESTING: 200] [accuracy: 0.9550] [B accuracy: 115] [M accuracy: 76]\n",
      "[TESTING: 300] [accuracy: 0.9600] [B accuracy: 115] [M accuracy: 173]\n",
      "[TESTING: 400] [accuracy: 0.9475] [B accuracy: 151] [M accuracy: 228]\n",
      "Model saved\n",
      "B accuracy:79.083 +/- 15.0\n",
      "M accuracy:83.833 +/- 15.0\n",
      "Average:81.458 +/- 7.0\n"
     ]
    }
   ],
   "source": [
    "#===============================================Experiment 01:training BACH ds================================================\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from codes.data.train_model import train_and_test_model_by_load_data_for_BACH\n",
    "from codes.model.vgg_network import VGG\n",
    "\n",
    "vgg = VGG(rows=256, cols=256, channels=3,num_classes=1, pretrained=0,is_svm=1)\n",
    "\n",
    "\n",
    "input_ds_filename =\"/tf/dataset/BACH/\"\n",
    "bs = 64\n",
    "vol_size = 1600\n",
    "epochs = 5\n",
    "fake_amount = 0 #4800\n",
    "mode = 'split'   #[split: 70/30] [cv: 5cross-validation]\n",
    "train_log, test_log = train_and_test_model_by_load_data_for_BACH(vgg.vgg, input_ds_filename,ratio=0.7, dataset_volume=vol_size\n",
    "                                           , epochs=epochs,batch_size=bs, print_interval=5 \n",
    "                                           , output_filename=\"/tf/experiments/BACH_train_vgg16_256x256_mode1.h5\"                                       \n",
    "                                           , fake_amount = fake_amount\n",
    "                                           , output_predict_file = \"/tf/dataset/BACH_validate_log_vgg16_256x256.csv\"\n",
    "                                           , mode = 'split' # 'split' vs. 'cv'\n",
    "                                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0 - Total 120 images is 0.708 acuracy - Belgnin accuracy: 0.650 - Malgnin accuracy: 0.767\n",
      "Epoch:1 - Total 120 images is 0.758 acuracy - Belgnin accuracy: 0.567 - Malgnin accuracy: 0.950\n",
      "Epoch:2 - Total 120 images is 0.792 acuracy - Belgnin accuracy: 0.633 - Malgnin accuracy: 0.950\n",
      "Epoch:3 - Total 120 images is 0.742 acuracy - Belgnin accuracy: 1.000 - Malgnin accuracy: 0.483\n",
      "Epoch:4 - Total 120 images is 0.958 acuracy - Belgnin accuracy: 0.950 - Malgnin accuracy: 0.967\n",
      "------------------VOTING: [method_A] by file [/tf/dataset/BACH_validate_log_vgg16_256x256.csv]  -----------------\n",
      "TOTAL: 0.792 +/- 0.088\n",
      "M accuracy : 0.823 +/- 0.185\n",
      "B accuracy : 0.760 +/- 0.178\n"
     ]
    }
   ],
   "source": [
    "#===============================================Experiment 01:calculate accuracy====================================================\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from codes.data.calculate_accuracy import get_calculate_accuracy_BACH\n",
    "\n",
    "csv_file = '/tf/dataset/BACH_validate_log_vgg16_256x256.csv'\n",
    "epoches=5\n",
    "get_calculate_accuracy_BACH(csv_file,epoches,'method_A')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#===============================================Experiment 02:training====================================================\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from codes.data.train_model import train_and_test_model_by_load_data\n",
    "from codes.model.vgg_network import VGG\n",
    "\n",
    "vgg = VGG(rows=256, cols=256, channels=3,num_classes=1, pretrained=0,is_svm=1)\n",
    "\n",
    "\n",
    "input_ds_filename =\"/tf/dataset/classes/\"\n",
    "bs = 64\n",
    "vol_size = 31636\n",
    "epochs = 5\n",
    "fake_amount = 4800\n",
    "mode = 'split'   #[split: 70/30] [cv: 5cross-validation]\n",
    "train_log, test_log = train_and_test_model_by_load_data(vgg.vgg, input_ds_filename,ratio=0.7, dataset_volume=vol_size\n",
    "                                           , epochs=epochs,batch_size=bs, print_interval=30 \n",
    "                                           , output_filename=\"/tf/experiments/validate_vgg16_256x256_mode1_fake.h5\"                                       \n",
    "                                           , fake_amount = fake_amount\n",
    "                                           , output_predict_file = \"/tf/dataset/validate_log_vgg16_256x256_fake.csv\"\n",
    "                                           , mode = 'split' # 'split' vs. 'cv'\n",
    "                                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#===============================================Experiment 02:calculate accuracy====================================================\n",
    "\n",
    "from codes.data.calculate_accuracy import get_calculate_accuracy\n",
    "\n",
    "csv_file = '/tf/dataset/validate_log_vgg16_256x256_fake.csv'\n",
    "epoches=5\n",
    "get_calculate_accuracy(csv_file,epoches,'method_C')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing BACH dataset....\n",
      "Training model....\n",
      "[Epoch 0/5] [Batch 0/50] [T loss: 0.815738, acc:  34%] time: 0:00:27.180880\n",
      "[Epoch 0/5] [Batch 5/50] [T loss: 3.754223, acc:  62%] time: 0:00:45.407615\n",
      "[Epoch 0/5] [Batch 10/50] [T loss: 3.572187, acc:  56%] time: 0:01:07.995537\n",
      "[Epoch 0/5] [Batch 15/50] [T loss: 0.660763, acc:  81%] time: 0:01:30.383042\n",
      "[Epoch 0/5] [Batch 20/50] [T loss: 1.655101, acc:  59%] time: 0:01:53.341841\n",
      "[Epoch 0/5] [Batch 25/50] [T loss: 0.565965, acc:  75%] time: 0:02:15.507384\n",
      "[Epoch 0/5] [Batch 30/50] [T loss: 1.593678, acc:  56%] time: 0:02:37.018837\n",
      "[TESTING: 100] [accuracy: 0.6000] [B accuracy: 60] [M accuracy: 0]\n",
      "[TESTING: 200] [accuracy: 0.6500] [B accuracy: 75] [M accuracy: 55]\n",
      "[TESTING: 300] [accuracy: 0.6667] [B accuracy: 75] [M accuracy: 125]\n",
      "[TESTING: 400] [accuracy: 0.6675] [B accuracy: 97] [M accuracy: 170]\n",
      "[Epoch 1/5] [Batch 0/50] [T loss: 0.559521, acc:  65%] time: 0:03:48.807914\n",
      "[Epoch 1/5] [Batch 5/50] [T loss: 0.598908, acc:  68%] time: 0:03:58.902571\n",
      "[Epoch 1/5] [Batch 10/50] [T loss: 0.817382, acc:  71%] time: 0:04:08.485396\n",
      "[Epoch 1/5] [Batch 15/50] [T loss: 0.309128, acc:  90%] time: 0:04:18.477959\n",
      "[Epoch 1/5] [Batch 20/50] [T loss: 0.493259, acc:  78%] time: 0:04:28.212020\n",
      "[Epoch 1/5] [Batch 25/50] [T loss: 0.331033, acc:  90%] time: 0:04:38.172690\n",
      "[Epoch 1/5] [Batch 30/50] [T loss: 0.395378, acc:  75%] time: 0:04:48.474293\n",
      "[TESTING: 100] [accuracy: 0.5600] [B accuracy: 56] [M accuracy: 0]\n",
      "[TESTING: 200] [accuracy: 0.7200] [B accuracy: 68] [M accuracy: 76]\n",
      "[TESTING: 300] [accuracy: 0.8100] [B accuracy: 68] [M accuracy: 175]\n",
      "[TESTING: 400] [accuracy: 0.7750] [B accuracy: 77] [M accuracy: 233]\n",
      "[Epoch 2/5] [Batch 0/50] [T loss: 0.357420, acc:  87%] time: 0:05:29.523406\n",
      "[Epoch 2/5] [Batch 5/50] [T loss: 0.303802, acc:  78%] time: 0:05:39.602596\n",
      "[Epoch 2/5] [Batch 10/50] [T loss: 0.277508, acc:  84%] time: 0:05:49.151241\n",
      "[Epoch 2/5] [Batch 15/50] [T loss: 0.161791, acc:  90%] time: 0:05:59.322504\n",
      "[Epoch 2/5] [Batch 20/50] [T loss: 0.243577, acc:  90%] time: 0:06:09.532485\n",
      "[Epoch 2/5] [Batch 25/50] [T loss: 0.177579, acc:  93%] time: 0:06:19.448611\n",
      "[Epoch 2/5] [Batch 30/50] [T loss: 0.292010, acc:  84%] time: 0:06:29.789360\n",
      "[TESTING: 100] [accuracy: 0.9900] [B accuracy: 99] [M accuracy: 0]\n",
      "[TESTING: 200] [accuracy: 0.8200] [B accuracy: 119] [M accuracy: 45]\n",
      "[TESTING: 300] [accuracy: 0.7800] [B accuracy: 119] [M accuracy: 115]\n",
      "[TESTING: 400] [accuracy: 0.7950] [B accuracy: 157] [M accuracy: 161]\n",
      "[Epoch 3/5] [Batch 0/50] [T loss: 0.250690, acc:  90%] time: 0:07:10.730292\n",
      "[Epoch 3/5] [Batch 5/50] [T loss: 0.313621, acc:  93%] time: 0:07:21.112491\n",
      "[Epoch 3/5] [Batch 10/50] [T loss: 0.216907, acc:  93%] time: 0:07:31.196721\n",
      "[Epoch 3/5] [Batch 15/50] [T loss: 0.100705, acc: 100%] time: 0:07:40.938302\n",
      "[Epoch 3/5] [Batch 20/50] [T loss: 0.203617, acc:  90%] time: 0:07:50.721282\n",
      "[Epoch 3/5] [Batch 25/50] [T loss: 0.328218, acc:  81%] time: 0:08:00.227611\n",
      "[Epoch 3/5] [Batch 30/50] [T loss: 0.341622, acc:  87%] time: 0:08:10.212307\n",
      "[TESTING: 100] [accuracy: 0.9900] [B accuracy: 99] [M accuracy: 0]\n",
      "[TESTING: 200] [accuracy: 0.9250] [B accuracy: 119] [M accuracy: 66]\n",
      "[TESTING: 300] [accuracy: 0.9000] [B accuracy: 119] [M accuracy: 151]\n",
      "[TESTING: 400] [accuracy: 0.8950] [B accuracy: 157] [M accuracy: 201]\n",
      "[Epoch 4/5] [Batch 0/50] [T loss: 0.102867, acc:  93%] time: 0:08:51.686859\n",
      "[Epoch 4/5] [Batch 5/50] [T loss: 0.034086, acc: 100%] time: 0:09:01.613997\n",
      "[Epoch 4/5] [Batch 10/50] [T loss: 0.174658, acc:  90%] time: 0:09:11.618973\n",
      "[Epoch 4/5] [Batch 15/50] [T loss: 0.160654, acc:  93%] time: 0:09:21.647048\n",
      "[Epoch 4/5] [Batch 20/50] [T loss: 0.104417, acc:  93%] time: 0:09:31.310482\n",
      "[Epoch 4/5] [Batch 25/50] [T loss: 0.162382, acc:  93%] time: 0:09:41.431061\n",
      "[Epoch 4/5] [Batch 30/50] [T loss: 0.049306, acc: 100%] time: 0:09:51.427453\n",
      "[TESTING: 100] [accuracy: 1.0000] [B accuracy: 100] [M accuracy: 0]\n",
      "[TESTING: 200] [accuracy: 0.9550] [B accuracy: 120] [M accuracy: 71]\n",
      "[TESTING: 300] [accuracy: 0.9333] [B accuracy: 120] [M accuracy: 160]\n",
      "[TESTING: 400] [accuracy: 0.9425] [B accuracy: 160] [M accuracy: 217]\n",
      "Model saved\n",
      "B accuracy:77.667 +/- 23.0\n",
      "M accuracy:81.833 +/- 11.0\n",
      "Average:79.75 +/- 11.0\n"
     ]
    }
   ],
   "source": [
    "#===============================================Experiment 03:training====================================================\n",
    "\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from codes.data.train_model import train_and_test_model_by_load_data_for_BACH\n",
    "from codes.model.combined import build_combine_VGG16_VGG19\n",
    "\n",
    "combined_model = build_combine_VGG16_VGG19(img_shape=(256,256,3),num_classes=1)\n",
    "\n",
    "input_ds_filename =\"/tf/dataset/BACH/\"\n",
    "bs = 32\n",
    "vol_size = 1600\n",
    "epochs = 5\n",
    "fake_amount = 0 #4800\n",
    "mode = 'split'   #[split: 70/30] [cv: 5cross-validation]\n",
    "train_log, test_log = train_and_test_model_by_load_data_for_BACH(combined_model, input_ds_filename,ratio=0.7, dataset_volume=vol_size\n",
    "                                           , epochs=epochs,batch_size=bs, print_interval=5 \n",
    "                                           , output_filename=\"/tf/experiments/BACH_train_combined_256x256_mode1.h5\"                                       \n",
    "                                           , fake_amount = fake_amount\n",
    "                                           , output_predict_file = \"/tf/dataset/BACH_validate_log_combined_256x256.csv\"\n",
    "                                           , mode = 'split' # 'split' vs. 'cv'\n",
    "                                          )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0 - Total 120 images is 0.483 acuracy - Belgnin accuracy: 0.367 - Malgnin accuracy: 0.600\n",
      "Epoch:1 - Total 120 images is 0.667 acuracy - Belgnin accuracy: 0.333 - Malgnin accuracy: 1.000\n",
      "Epoch:2 - Total 120 images is 0.800 acuracy - Belgnin accuracy: 0.967 - Malgnin accuracy: 0.633\n",
      "Epoch:3 - Total 120 images is 0.867 acuracy - Belgnin accuracy: 0.917 - Malgnin accuracy: 0.817\n",
      "Epoch:4 - Total 120 images is 0.950 acuracy - Belgnin accuracy: 1.000 - Malgnin accuracy: 0.900\n",
      "------------------VOTING: [method_A] by file [/tf/dataset/BACH_validate_log_combined_256x256.csv]  -----------------\n",
      "TOTAL: 0.753 +/- 0.164\n",
      "M accuracy : 0.790 +/- 0.153\n",
      "B accuracy : 0.717 +/- 0.301\n"
     ]
    }
   ],
   "source": [
    "#===============================================Experiment 03:calculate accuracy====================================================\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from codes.data.calculate_accuracy import get_calculate_accuracy_BACH\n",
    "\n",
    "csv_file = '/tf/dataset/BACH_validate_log_combined_256x256.csv'\n",
    "epoches=5\n",
    "get_calculate_accuracy_BACH(csv_file,epoches,'method_A')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#===============================================Experiment 04:training====================================================\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from codes.model.combined import build_combine_VGG16_VGG19\n",
    "\n",
    "combined_model = build_combine_VGG16_VGG19(img_shape=(256,256,3),num_classes=1)\n",
    "\n",
    "#layer 17 + 17\n",
    "from codes.data.train_model import train_and_test_model,train_and_test_model_by_load_data\n",
    "\n",
    "input_ds_filename =\"/tf/dataset/classes/\"\n",
    "bs = 32\n",
    "vol_size = 31636\n",
    "epochs = 5\n",
    "fake_amount = 4800\n",
    "train_log, test_log = train_and_test_model_by_load_data(combined_model, input_ds_filename,ratio=0.7, dataset_volume=vol_size\n",
    "                                           , epochs=epochs,batch_size=bs, print_interval=30 \n",
    "                                           , output_filename=\"/tf/experiments/validate_combined_256x256_fake.h5\"\n",
    "                                           , fake_amount = fake_amount\n",
    "                                           , output_predict_file = \"/tf/dataset/validate_log_combined_256x256_fake.csv\"\n",
    "                                           , mode = 'split' # 'split' vs. 'cv'\n",
    "                                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#===============================================Experiment 04:calculate accuracy====================================================\n",
    "\n",
    "from codes.data.calculate_accuracy import get_calculate_accuracy_BACH\n",
    "\n",
    "csv_file = '/tf/dataset/validate_log_combined_256x256_fake.csv'\n",
    "epoches=5\n",
    "get_calculate_accuracy_BACH(csv_file,epoches,'method_C')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n003-3 B 3 n003\n"
     ]
    }
   ],
   "source": [
    "a = \"[b'/tf/dataset/BACH/Normal_png/n003-3.png']\"\n",
    "filename = a.split('/')[-1].split('.')[0]\n",
    "filename\n",
    "if filename[0] == 'b' or filename[0] == 'n':\n",
    "    typ = 'B'\n",
    "else:\n",
    "    typ = 'M'\n",
    "idx =  filename.split('-')[1]\n",
    "instance = filename.split('-')[0]\n",
    "print(filename, typ, idx, instance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
